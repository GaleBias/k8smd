# 项目简介

- 项目地址[vertical-pod-autoscaler](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler)
- 纵向容器自动缩放器（VPA）使用户无需设置最新的资源限制和对容器中容器的要求。
- 配置后，它将根据使用情况自动设置请求，从而允许在节点上进行适当的调度，以便为每个Pod提供适当的资源量
  - 它还将保持限制和初始容器配置中指定的请求之间的比率。
  - 它既可以根据资源的使用情况来缩减对资源过度使用的Pod，也可以对资源需求不足的向上扩展Pod。

## Kubernetes VPA 包含以下组件：

> 架构图
> ![vpaarchitecture20200901140235706.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1636076372000/5e9d1fc61cba4844b3cc2c219a470508.png)

- Recommender：用于根据监控指标结合内置机制给出资源建议值
- Updater：用于实时更新 pod resource requests
- History Storage：用于采集和存储监控数据
- Admission Controller: 用于在 pod 创建时修改 resource requests

> 工作流程说明

- 主要流程是：Recommender在启动时从History Storage获取历史数据，根据内置机制修改VPA API object资源建议值
  - Updater监听VPA API object，依据建议值动态修改 pod resource requests
  - VPA Admission Controller则是用于 pod 创建时修改 pod resource requests
  - History Storage则是通过Kubernetes Metrics API采集和存储监控数据。

> VPA工作流程示意图
> ![vpa02.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1636076372000/afbaef2e5aa5439fa080b7688a2baa29.png)

- VPA连续检查您在设置过程中配置的指标值，默认间隔为10秒
- 如果达到阈值，VPA会尝试更改分配的内存和/或CPU
- VPA主要更新部署或复制控制器规范中的资源
- 重新启动Pod后，新资源将全部应用于创建的实例。

### 使用VPA时需要考虑以下几点：

- 如果不重新启动Pod，将无法更改资源。到目前为止，主要的合理性在于，这样的变化可能会导致很多不稳定。因此，考虑重新启动Pod并根据新分配的资源对其进行调度。
- VPA和HPA尚不兼容，不能在同一pod上使用。如果要在同一群集中同时使用它们，请确保在设置中分开它们的作用域。
- VPA仅根据观察到的过去和当前资源使用情况来调整容器的资源请求
  - 它没有设置资源限制。对于行为不当的应用程序可能会出现问题，这些应用程序开始使用越来越多的资源，导致pod被Kubernetes杀死。

# 安装部署vpa

## 01 部署metrics-server提供 pod的资源监控数据

- [metrics-server项目地址](https://github.com/kubernetes-sigs/metrics-server)
- 安装步骤 ，直接使用项目提供的 components.yaml

```shell
wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.5.0/components.yaml
```

- 修改 metrics-server 启动参数
  - metrics-server 会请求每台节点的 kubelet 接口来获取监控数据，接口通过 HTTPS 暴露
  - 但kubeadm安装节点的 kubelet 使用的是自签证书，若 metrics-server 直接请求 kubelet 接口，将产生证书校验失败的错误
  - 因此需要在 components.yaml 文件中加上 --kubelet-insecure-tls 启动参数。
- 并且默认的k8s.gcr.io ，国内可能无法直接拉取，需要修改为国内缓存
- 修改后的容器段如下

```yaml
containers:
      - args:
        - --cert-dir=/tmp
        - --secure-port=443
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s
        - --kubelet-insecure-tls # 加上该启动参数
        image: ccr.ccs.tencentyun.com/mirrors/metrics-server:v0.5.0 # 国内集群，请替换成这个镜像
```

- 部署后检查 pod

```shell
[root@k8s-master01 hpa]# kubectl get pod -n kube-system | grep metrics-server
metrics-server-c44f75469-sf27q                1/1     Running   0          4m24s
```

- 使用kubelet get这个restapi的path 可以看到内部的resources kind有两个 NodeMetrics和PodMetrics

```shell
[root@k8s-master01 hpa]# kubectl get --raw /apis/metrics.k8s.io/v1beta1   |python -m json.tool
{
    "apiVersion": "v1",
    "groupVersion": "metrics.k8s.io/v1beta1",
    "kind": "APIResourceList",
    "resources": [
        {
            "kind": "NodeMetrics",
            "name": "nodes",
            "namespaced": false,
            "singularName": "",
            "verbs": [
                "get",
                "list"
            ]
        },
        {
            "kind": "PodMetrics",
            "name": "pods",
            "namespaced": true,
            "singularName": "",
            "verbs": [
                "get",
                "list"
            ]
        }
    ]
}
```

- 比如我们可以使用下面的get 获取一个ns下面一个pod 的指标

```shell
[root@k8s-master01 hpa]# kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/kube-state-metrics-647444dd74-rwwqk |python -m json.tool
{
    "apiVersion": "metrics.k8s.io/v1beta1",
    "containers": [
        {
            "name": "kube-state-metrics",
            "usage": {
                "cpu": "1398820n",
                "memory": "29556Ki"
            }
        }
    ],
    "kind": "PodMetrics",
    "metadata": {
        "creationTimestamp": "2021-11-01T11:47:11Z",
        "labels": {
            "app.kubernetes.io/name": "kube-state-metrics",
            "app.kubernetes.io/version": "v1.9.7",
            "pod-template-hash": "647444dd74"
        },
        "name": "kube-state-metrics-647444dd74-rwwqk",
        "namespace": "kube-system"
    },
    "timestamp": "2021-11-01T11:47:07Z",
    "window": "15s"
}
```

- 或者获取node级别的指标

```shell
[root@k8s-master01 hpa]# kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes |python -m json.tool
{
    "apiVersion": "metrics.k8s.io/v1beta1",
    "items": [
        {
            "metadata": {
                "creationTimestamp": "2021-11-01T11:48:37Z",
                "labels": {
                    "beta.kubernetes.io/arch": "amd64",
                    "beta.kubernetes.io/os": "linux",
                    "kubernetes.io/arch": "amd64",
                    "kubernetes.io/hostname": "k8s-master01",
                    "kubernetes.io/os": "linux",
                    "node-role.kubernetes.io/control-plane": "",
                    "node-role.kubernetes.io/master": "",
                    "node.kubernetes.io/exclude-from-external-load-balancers": ""
                },
                "name": "k8s-master01"
            },
            "timestamp": "2021-11-01T11:48:21Z",
            "usage": {
                "cpu": "492230133n",
                "memory": "8151448Ki"
            },
            "window": "20s"
        },
        {
            "metadata": {
                "creationTimestamp": "2021-11-01T11:48:37Z",
                "labels": {
                    "beta.kubernetes.io/arch": "amd64",
                    "beta.kubernetes.io/os": "linux",
                    "kubernetes.io/arch": "amd64",
                    "kubernetes.io/hostname": "k8s-node01",
                    "kubernetes.io/os": "linux"
                },
                "name": "k8s-node01"
            },
            "timestamp": "2021-11-01T11:48:17Z",
            "usage": {
                "cpu": "1227180417n",
                "memory": "6272672Ki"
            },
            "window": "11s"
        }
    ],
    "kind": "NodeMetricsList",
    "metadata": {}
}
```

- 或者我们使用 top 查看 node和pod

```shell
[root@k8s-master01 hpa]# kubectl top pod -n kube-system
W1101 19:49:53.180979   14600 top_pod.go:140] Using json format to get metrics. Next release will switch to protocol-buffers, switch early by passing --use-protocol-buffers flag
NAME                                          CPU(cores)   MEMORY(bytes)   
coredns-7d75679df-9vzm2                       4m           22Mi      
coredns-7d75679df-wf8wl                       4m           24Mi      
etcd-k8s-master01                             38m          332Mi     
kube-apiserver-k8s-master01                   141m         580Mi     
kube-controller-manager-k8s-master01          21m          80Mi      
kube-proxy-6czbx                              1m           24Mi      
kube-proxy-kq4m2                              1m           22Mi      
kube-scheduler-k8s-master01                   5m           29Mi      
kube-state-metrics-647444dd74-rwwqk           1m           29Mi      
metrics-server-c44f75469-sf27q                5m           18Mi      
nginx-svc09-5dfcb54f88-f94qq                  0m           1Mi       
nginx-svc09-5dfcb54f88-nnrqj                  0m           1Mi       
prometheus-0                                  10m          612Mi     
traefik-ingress-controller-54d6b8df8d-r858j   7m           18Mi      
[root@k8s-master01 hpa]# kubectl top node
W1101 19:49:55.802347   14691 top_node.go:119] Using json format to get metrics. Next release will switch to protocol-buffers, switch early by passing --use-protocol-buffers flag
NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
k8s-master01   449m         4%     7955Mi          50%   
k8s-node01     1203m        12%    6150Mi          38%   
[root@k8s-master01 hpa]# 
```

## 02 部署 Vertical Pod Autoscaler 0.9.2

- 下载代码切换到 默认的master版本就是0.9.2 这个分支

```shell
git clone https://github.com/kubernetes/autoscaler.git
cd autoscaler
git reset --hard 

```

### 直接部署

- 执行 ./hack/vpa-up.sh 部署

```shell
cd vertical-pod-autoscaler ;bash -x ./hack/vpa-up.sh 
```

- 部署完成之后发现3个镜像都没有拉起来

```shell
[root@k8s-master01 vertical-pod-autoscaler]# kubectl get pod -n kube-system |grep vpa
vpa-admission-controller-5f8bb8c868-4v4vn     0/1     ImagePullBackOff   0          6m2s
vpa-recommender-65bc4c87-gct8l                0/1     ImagePullBackOff   0          6m3s
vpa-updater-568c8bdd7-4v68b                   0/1     ErrImagePull       0          6m3s
```

- 原因是这三个镜像都是k8s.gcr.io仓库下面，不翻墙的话无法下载
- 升级openssl到1.11k

```shell

 yum install gcc gcc-c++ -y
wget --no-check-certificate https://www.openssl.org/source/openssl-1.1.1k.tar.gz && tar zxf openssl-1.1.1k.tar.gz && cd openssl-1.1.1k
./config
make && make install
# 默认安装到了  /usr/local/bin/openssl


mv /usr/local/bin/openssl /usr/local/bin/openssl.bak
mv apps/openssl /usr/local/bin
openssl version -a


```

### 替换镜像

- 这里使用FROM 国外镜像的手段 ，依据这个在阿里云上构建，[github地址](https://github.com/ning1875/k8s-autoscaling-mirror/blob/0.8.1/vpa-admission-controller.Dockerfile)

```shell
FROM k8s.gcr.io/autoscaling/vpa-admission-controller:0.8.1

```

- 替换镜像

```shell
vim deploy/admission-controller-deployment.yaml
registry.cn-beijing.aliyuncs.com/ning1875_haiwai_image/vpa-admission-controller:0.9.2
vim deploy/recommender-deployment.yaml
registry.cn-beijing.aliyuncs.com/ning1875_haiwai_image/vpa-recommender:0.9.2
vim deploy/updater-deployment.yaml
registry.cn-beijing.aliyuncs.com/ning1875_haiwai_image/vpa-updater:0.9.2

```

- 或者使用set image 替换

```shell
kubectl -n kube-system  set image deployment/vpa-admission-controller admission-controller=scofield/registry.cn-beijing.aliyuncs.com/ning1875_haiwai_image:0.8.1 --record
```

- 然后执行bash -x ./hack/vpa-down.sh 删除 vpa，再执行 bash -x ./hack/vpa-up.sh重新部署
- 启动之后 检查pod运行状况

```shell
[root@k8s-master01 vertical-pod-autoscaler]# kubectl get pod -n kube-system |grep vpa                                 
vpa-admission-controller-7d67559d6b-9m6kp     1/1     Running   0          12m
vpa-recommender-685f5c8d49-7sdtd              1/1     Running   0          12m
vpa-updater-554d4b749c-2zpkw                  1/1     Running   0          12m
```

# 使用vpa

## VPA 有以下四种更新策略：

- Initial：仅在 Pod 创建时修改资源请求，以后都不再修改。
- Auto：默认策略，在 Pod 创建时修改资源请求，并且在 Pod 更新时也会修改。
- Recreate：类似 Auto，在 Pod 的创建和更新时都会修改资源请求，不同的是，只要Pod 中的请求值与新的推荐值不同，VPA 都会驱逐该 Pod，然后使用新的推荐值重新启一个。因此，一般不使用该策略，而是使用 Auto，除非你真的需要保证请求值是最新的推荐值。
- Off：不改变 Pod 的资源请求，不过仍然会在 VPA 中设置资源的推荐值。

## 01 首先体验一下 updateMode: Off 代表仅获取资源推荐，但不更新Pod

- 首先部署一个nginx 的dep和svc，请求cpu为100m，250Mi内存
- 这里的副本数一定要设置大于1 ，不然驱逐的时候 只有一个pod了，不能驱逐，

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: vpa-nginx-off01
  name: vpa-nginx-off01
  namespace: vpa
spec:
  replicas: 2
  selector:
    matchLabels:
      app: vpa-nginx-off01
  template:
    metadata:
      labels:
        app: vpa-nginx-off01
    spec:
      containers:
      - image: nginx:1.8
        name: nginx
        resources:
          requests:
            cpu: 100m
            memory: 250Mi
---
apiVersion: v1
kind: Service
metadata:
  name: vpa-nginx-off01
  namespace: vpa
spec:
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: vpa-nginx-off01
```

- 新建一个ns vpa 然后部署后查看

```shell
[root@k8s-master01 app]# kubectl create ns vpa
namespace/vpa created

[root@k8s-master01 app]# kubectl get all -n vpa
NAME                                   READY   STATUS    RESTARTS   AGE
pod/vpa-nginx-off01-79f78f6797-qn4qf   1/1     Running   0          7s

NAME                      TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
service/vpa-nginx-off01   ClusterIP   10.96.12.138   <none>        80/TCP    7s

NAME                              READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/vpa-nginx-off01   1/1     1            1           7s

NAME                                         DESIRED   CURRENT   READY   AGE
replicaset.apps/vpa-nginx-off01-79f78f6797   1         1         1       7s
```

- 部署一个vpa ，minAllowed和maxAllowed分别代表资源的最小和最大值

```yaml
apiVersion: autoscaling.k8s.io/v1beta2
kind: VerticalPodAutoscaler
metadata:
  name: vpa-nginx-off01
  namespace: vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: vpa-nginx-off01
  updatePolicy:
    updateMode: "Off"
  resourcePolicy:
    containerPolicies:
    - containerName: "nginx"
      minAllowed:
        cpu: "250m"
        memory: "100Mi"
      maxAllowed:
        cpu: "2000m"
        memory: "2048Mi"
```

- 部署完之后查看这个vpa

```shell
[root@k8s-master01 app]# kubectl describe  vpa -n vpa
Name:         vpa-nginx-off01
Namespace:    vpa
Labels:       <none>
Annotations:  <none>
API Version:  autoscaling.k8s.io/v1
Kind:         VerticalPodAutoscaler
Metadata:
  Creation Timestamp:  2021-11-04T04:20:40Z
  Generation:          2
  Managed Fields:
    API Version:  autoscaling.k8s.io/v1beta2
    Fields Type:  FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .:
          f:kubectl.kubernetes.io/last-applied-configuration:
      f:spec:
        .:
        f:resourcePolicy:
          .:
          f:containerPolicies:
        f:targetRef:
          .:
          f:apiVersion:
          f:kind:
          f:name:
        f:updatePolicy:
          .:
          f:updateMode:
    Manager:      kubectl-client-side-apply
    Operation:    Update
    Time:         2021-11-04T04:20:40Z
    API Version:  autoscaling.k8s.io/v1
    Fields Type:  FieldsV1
    fieldsV1:
      f:status:
        .:
        f:conditions:
        f:recommendation:
          .:
          f:containerRecommendations:
    Manager:         recommender
    Operation:       Update
    Time:            2021-11-04T04:21:14Z
  Resource Version:  5834079
  UID:               69498c80-d515-4964-a762-23779707acdc
Spec:
  Resource Policy:
    Container Policies:
      Container Name:  nginx
      Max Allowed:
        Cpu:     2000m
        Memory:  2048Mi
      Min Allowed:
        Cpu:     250m
        Memory:  100Mi
  Target Ref:
    API Version:  apps/v1
    Kind:         Deployment
    Name:         vpa-nginx-off01
  Update Policy:
    Update Mode:  Off
Status:
  Conditions:
    Last Transition Time:  2021-11-04T04:21:14Z
    Status:                True
    Type:                  RecommendationProvided
  Recommendation:
    Container Recommendations:
      Container Name:  nginx
      Lower Bound:
        Cpu:     250m
        Memory:  262144k
      Target:
        Cpu:     250m
        Memory:  262144k
      Uncapped Target:
        Cpu:     25m
        Memory:  262144k
      Upper Bound:
        Cpu:     2
        Memory:  2Gi
Events:          <none>
```

- 解读一下Recommend推荐资源字段

```shell
Lower Bound:                 下限值
Target:                      推荐值
Upper Bound:                 上限值
Uncapped Target:             如果没有为VPA提供最小或最大边界，则表示目标利用率
上述结果表明，推荐的 Pod 的 CPU 请求为 25m，推荐的内存请求为 262144k 字节。

```

- 安装 ab压测工具对这个svc进行压测，ab -c 100 -n 10000000代表总数10000000并发100

```shell
yum -y install httpd-tools
# 获取 svc的cluster ip
[root@k8s-master01 app]# kubectl get svc  -n vpa
NAME              TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
vpa-nginx-off01   ClusterIP   10.96.12.138   <none>        80/TCP    11m
# ab 压测
ab -c 100 -n 10000000 http://10.96.12.138/
```

- 然后不断观察vpa的结果输出 ，VPA对Pod给出了推荐值：Cpu: 1038m，因为我们这里设置了updateMode: "Off"，所以不会更新Pod

```shell
[root@k8s-master01 autoscaler]# kubectl describe vpa -n vpa |tail -n 25
    Kind:         Deployment
    Name:         vpa-nginx-off01
  Update Policy:
    Update Mode:  Off
Status:
  Conditions:
    Last Transition Time:  2021-11-04T04:21:14Z
    Status:                True
    Type:                  RecommendationProvided
  Recommendation:
    Container Recommendations:
      Container Name:  nginx
      Lower Bound:
        Cpu:     250m
        Memory:  262144k
      Target:
        Cpu:     1038m
        Memory:  262144k
      Uncapped Target:
        Cpu:     1038m
        Memory:  262144k
      Upper Bound:
        Cpu:     2
        Memory:  1115500k
Events:          <none>
```

## 02 体验updateMode: "Auto"

- 把之前的vpa模式改为auto后再次部署vpa，然后执行压测

```shell
# ab 压测
ab -c 100 -n 10000000 http://10.96.12.138/
```

- 获取一下这个nginx的pod名字，同时可以观察 vpa 这个ns下的event

```shell
[root@k8s-master01 ~]# kubectl get pod -n vpa
NAME                               READY   STATUS    RESTARTS   AGE
vpa-nginx-off01-79f78f6797-qn4qf   1/1     Running   0          24m
[root@k8s-master01 ~]# 

kubectl get event  -n vpa -w

```

- 几分钟后，使用describe查看vpa详情，同样只关注Container Recommendations
- 观察到的驱逐pod事件，并且重新启动了新的pod

```shell
0s          Normal   EvictedByVPA        pod/vpa-nginx-off01-79f78f6797-7xnt5    Pod was evicted by VPA Updater to apply resource recommendation.
0s          Normal   Killing             pod/vpa-nginx-off01-79f78f6797-7xnt5    Stopping container nginx
0s          Normal   SuccessfulCreate    replicaset/vpa-nginx-off01-79f78f6797   Created pod: vpa-nginx-off01-79f78f6797-kgc2p
0s          Normal   Scheduled           pod/vpa-nginx-off01-79f78f6797-kgc2p    Successfully assigned vpa/vpa-nginx-off01-79f78f6797-kgc2p to k8s-node01
0s          Normal   Pulled              pod/vpa-nginx-off01-79f78f6797-kgc2p    Container image "nginx:1.8" already present on machine
0s          Normal   Created             pod/vpa-nginx-off01-79f78f6797-kgc2p    Created container nginx
0s          Normal   Started             pod/vpa-nginx-off01-79f78f6797-kgc2p    Started container nginx
```

- 看到新的pod被设置为新的request 新的pod request 值 cpu 被设置为250m，memory 被设置为262144k

```shell
[root@k8s-master01 ~]# kubectl get pod -n vpa
NAME                               READY   STATUS    RESTARTS   AGE
vpa-nginx-off01-79f78f6797-2r9qg   1/1     Running   0          72m
vpa-nginx-off01-79f78f6797-pfkcs   1/1     Running   0          71m
[root@k8s-master01 ~]# kubectl describe pod vpa-nginx-off01-79f78f6797-pfkcs -n vpa
Name:         vpa-nginx-off01-79f78f6797-pfkcs
Namespace:    vpa
Priority:     0
Node:         k8s-node01/172.20.70.215
Start Time:   Thu, 04 Nov 2021 15:49:12 +0800
Labels:       app=vpa-nginx-off01
              pod-template-hash=79f78f6797
Annotations:  cni.projectcalico.org/podIP: 10.100.85.220/32
              cni.projectcalico.org/podIPs: 10.100.85.220/32
              vpaObservedContainers: nginx
              vpaUpdates: Pod resources updated by vpa-nginx-off01: container 0: cpu request, memory request
Status:       Running
IP:           10.100.85.220
IPs:
  IP:           10.100.85.220
Controlled By:  ReplicaSet/vpa-nginx-off01-79f78f6797
Containers:
  nginx:
    Container ID:   containerd://92a0bc58798c046308da31078b2bcd1f83f3e44073293b19bdd388c419547f36
    Image:          nginx:1.8
    Image ID:       sha256:90251a12242eabcbaa3ffe1da13ae4095f8d53dbb8dc6894a7731818b802494c
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Thu, 04 Nov 2021 15:49:14 +0800
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:        250m
      memory:     262144k
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-rg8fx (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  kube-api-access-rg8fx:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>
```

# vpa的限制

- 不能与HPA（Horizontal Pod Autoscaler ）一起使用
- 在只有1个副本的时候不能驱逐，too less pod

# 本节重点总结

- 基于vpa的扩容