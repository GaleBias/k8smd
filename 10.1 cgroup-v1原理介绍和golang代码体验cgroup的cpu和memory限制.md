# 本节重点总结 :

- Cgroups全称Control Groups，是Linux内核提供的物理资源隔离机制，可以实现进程的资源隔离
- cgroup v1的子系统介绍
- golang代码体验 cgroup 的cpu和memory限制

# cgroup原理介绍

# cgroup的功能和定位

- Cgroups全称Control Groups，是Linux内核提供的物理资源隔离机制
- 通过这种机制，可以实现对Linux进程或者进程组的资源限制、隔离和统计功能

## 资源限制说明

- 比如可以通过cgroup限制特定进程的资源使用，比如使用特定数目的cpu核数和特定大小的内存，如果资源超限的情况下，会被暂停或者杀掉。

## 历史

- Cgroup是于2.6内核由Google公司主导引入的，它是Linux内核实现资源虚拟化的技术基石
- LXC(Linux Containers)和docker容器所用到的资源隔离技术，正是Cgroup

## v1 v2 版本说明

- 虽然cgroup v2早已在linux 4.5版本的时候就已经加入内核中了
- 而centos 8默认也已经用了4.18作为其内核版本，但是系统中仍然默认使用的是cgroup v1
- 当前 kernel 没有移除 Cgroups v1 版本，允许 Cgroups v1 和 v2 两个版本共存。但是相同的 controller 不能同时 mount 到这两个不同的 Cgroup 版本中。

# cgroup V1 原理介绍

## cgroup 相关的概念

- 任务(task): 在cgroup中，任务就是一个进程。
- 控制组(control group): cgroup的资源控制是以控制组的方式实现，控制组指明了资源的配额限制
  - 进程可以加入到某个控制组，也可以迁移到另一个控制组。
- 层级(hierarchy): 控制组有层级关系，类似树的结构，子节点的控制组继承父控制组的属性(资源配额、限制等)。
- 子系统(subsystem): 一个子系统其实就是一种资源的控制器，比如memory子系统可以控制进程内存的使用
  - 子系统需要加入到某个层级，然后该层级的所有控制组，均受到这个子系统的控制。

## 他们直接的关系

![cgroup01.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1634434321000/b15c1461674c4dee9c9d4e294849e8c7.png)

## cgroup 子系统

- cpu: 限制进程的 cpu 使用率。
- cpuacct：子系统，可以统计 cgroups 中的进程的 cpu 使用报告。
- cpuset: 为cgroups中的进程分配单独的cpu节点或者内存节点。
- memory: 限制进程的memory使用量。
- blkio: 限制进程的块设备io。
- devices: 控制进程能够访问某些设备。
- net_cls: 标记cgroups中进程的网络数据包，然后可以使用tc模块（traffic control）对数据包进行控制。
- net_prio: 限制进程网络流量的优先级。
- huge_tlb: 限制HugeTLB的使用。
- freezer:挂起或者恢复cgroups中的进程。
- ns: 控制cgroups中的进程使用不同的namespace。

## cgroup 文件系统

- Linux通过文件的方式，将cgroups的功能和配置暴露给用户，这得益于Linux的虚拟文件系统（VFS）
- VFS将具体文件系统的细节隐藏起来，给用户态提供一个统一的文件系统API接口，cgroups和VFS之间的链接部分，称之为cgroups文件系统

```shell
mount -t cgroup -o cpu,cpuset,memory cpu_mem /cgroups/cpu_mem

```

## cpu子系统

> cpu子系统限制对CPU的访问，每个参数独立存在于cgroups虚拟文件系统的伪文件中，参数解释如下：

- cpu.shares: cgroup对时间的分配。比如cgroup A设置的是1，cgroup B设置的是2，那么B中的任务获取cpu的时间，是A中任务的2倍。
- cpu.cfs_period_us: 完全公平调度器的调整时间配额的周期。
- cpu.cfs_quota_us: 完全公平调度器的周期当中可以占用的时间。
- cpu.stat 统计值
  - nr_periods 进入周期的次数
  - nr_throttled 运行时间被调整的次数
  - throttled_time 用于调整的时间

## cpuacct子系统

> 子系统生成cgroup任务所使用的CPU资源报告，不做资源限制功能。

- cpuacct.usage: 该cgroup中所有任务总共使用的CPU时间（ns纳秒）
- cpuacct.stat: 该cgroup中所有任务总共使用的CPU时间，区分user和system时间。
- cpuacct.usage_percpu: 该cgroup中所有任务使用各个CPU核数的时间。

> 可以使用 cpuacct.usage的rate计算cpu利用率

- 用cpuacct.usage的差值除以时间的差值 就是利用率了

```shell

(cpuacct.usage_t1 - cpuacct.usage_t0) / (t1 - t0) * 100
```

## cpuset子系统

> 适用于分配独立的CPU节点和Mem节点，比如将进程绑定在指定的CPU或者内存节点上运行，各参数解释如下：

- cpuset.cpus: 可以使用的cpu节点
- cpuset.mems: 可以使用的mem节点
- cpuset.memory_migrate: 内存节点改变是否要迁移？
- cpuset.cpu_exclusive: 此cgroup里的任务是否独享cpu？
- cpuset.mem_exclusive： 此cgroup里的任务是否独享mem节点？
- cpuset.mem_hardwall: 限制内核内存分配的节点（mems是用户态的分配）
- cpuset.memory_pressure: 计算换页的压力。
- cpuset.memory_spread_page: 将page cache分配到各个节点中，而不是当前内存节点。
- cpuset.memory_spread_slab: 将slab对象(inode和dentry)分散到节点中。
- cpuset.sched_load_balance: 打开cpu set中的cpu的负载均衡。
- cpuset.sched_relax_domain_level: the searching range when migrating tasks
- cpuset.memory_pressure_enabled: 是否需要计算 memory_pressure?

## memory子系统

> memory子系统主要涉及内存一些的限制和操作，主要有以下参数：

- memory.usage_in_bytes : 当前内存中的使用量
- memory.memsw.usage_in_bytes : 当前内存和交换空间中的使用量
- memory.limit_in_bytes : 设置or查看内存使用量
- memory.memsw.limit_in_bytes : 设置or查看 内存加交换空间使用量
- memory.failcnt : 查看内存使用量被限制的次数
- memory.memsw.failcnt : - 查看内存和交换空间使用量被限制的次数
- memory.max_usage_in_bytes : 查看内存最大使用量
- memory.memsw.max_usage_in_bytes : 查看最大内存和交换空间使用量
- memory.soft_limit_in_bytes : 设置or查看内存的soft limit
- memory.stat : 统计信息
- memory.use_hierarchy : 设置or查看层级统计的功能
- memory.force_empty : 触发强制page回收
- memory.pressure_level : 设置内存压力通知
- memory.swappiness : 设置or查看vmscan swappiness 参数
- memory.move_charge_at_immigrate : 设置or查看 controls of moving charges?
- memory.oom_control : 设置or查看内存超限控制信息(OOM killer)
- memory.numa_stat : 每个numa节点的内存使用数量
- memory.kmem.limit_in_bytes : 设置or查看 内核内存限制的硬限
- memory.kmem.usage_in_bytes : 读取当前内核内存的分配
- memory.kmem.failcnt : 读取当前内核内存分配受限的次数
- memory.kmem.max_usage_in_bytes : 读取最大内核内存使用量
- memory.kmem.tcp.limit_in_bytes : 设置tcp 缓存内存的hard limit
- memory.kmem.tcp.usage_in_bytes : 读取tcp 缓存内存的使用量
- memory.kmem.tcp.failcnt : tcp 缓存内存分配的受限次数
- memory.kmem.tcp.max_usage_in_bytes : tcp 缓存内存的最大使用量

## blkio子系统

> 主要用于控制设备IO的访问

- 有两种限制方式：权重和上限，权重是给不同的应用一个权重值，按百分比使用IO资源，上限是控制应用读写速率的最大值。

> 按权重分配IO资源：

- blkio.weight：填写 100-1000 的一个整数值，作为相对权重比率，作为通用的设备分配比。
- blkio.weight_device： 针对特定设备的权重比，写入格式为 device_types:node_numbers weight，空格前的参数段指定设备，weight参数与blkio.weight相同并覆盖原有的通用分配比。

> 按上限限制读写速度：

- blkio.throttle.read_bps_device：按每秒读取块设备的数据量设定上限，格式device_types:node_numbers bytes_per_second。
- blkio.throttle.write_bps_device：按每秒写入块设备的数据量设定上限，格式device_types:node_numbers bytes_per_second。
- blkio.throttle.read_iops_device：按每秒读操作次数设定上限，格式device_types:node_numbers operations_per_second。
- blkio.throttle.write_iops_device：按每秒写操作次数设定上限，格式device_types:node_numbers operations_per_second

> 针对特定操作 (read, write, sync, 或 async) 设定读写速度上限

- blkio.throttle.io_serviced：针对特定操作按每秒操作次数设定上限，格式device_types:node_numbers operation operations_per_second
- blkio.throttle.io_service_bytes：针对特定操作按每秒数据量设定上限，格式device_types:node_numbers operation bytes_per_second

# cgroups的安装使用

> 安装

```shell
yum -y install libcgroup-tools
```

## 准备cpu 子系统限制进程的cpu

```shell
mkdir /sys/fs/cgroup/cpu/my_cpu
```

- 然后可以看到，cgroups 的文件系统会在创建文件目录的时候自动创建这些配置文件

```shell
[root@k8s-master01 my_cpu]# ll /sys/fs/cgroup/cpu/my_cpu
total 0
-rw-r--r-- 1 root root 0 Sep 26 18:57 cgroup.clone_children
--w--w--w- 1 root root 0 Sep 26 18:57 cgroup.event_control
-rw-r--r-- 1 root root 0 Sep 26 18:57 cgroup.procs
-r--r--r-- 1 root root 0 Sep 26 18:57 cpuacct.stat
-rw-r--r-- 1 root root 0 Sep 26 18:57 cpuacct.usage
-r--r--r-- 1 root root 0 Sep 26 18:57 cpuacct.usage_percpu
-rw-r--r-- 1 root root 0 Sep 26 19:05 cpu.cfs_period_us
-rw-r--r-- 1 root root 0 Sep 26 19:05 cpu.cfs_quota_us
-rw-r--r-- 1 root root 0 Sep 26 18:57 cpu.rt_period_us
-rw-r--r-- 1 root root 0 Sep 26 18:57 cpu.rt_runtime_us
-rw-r--r-- 1 root root 0 Sep 26 18:57 cpu.shares
-r--r--r-- 1 root root 0 Sep 26 18:57 cpu.stat
-rw-r--r-- 1 root root 0 Sep 26 18:57 notify_on_release
-rw-r--r-- 1 root root 0 Sep 26 19:09 tasks
```

> 设置CPU 周期限制为总量的十分之一

```shell
echo 100000 > /sys/fs/cgroup/cpu/my_cpu/cpu.cfs_period_us
echo 10000 > /sys/fs/cgroup/cpu/my_cpu/cpu.cfs_quota_us

```

> 编写一个go的cpu密集型代码

```shell
cat <<EOF>cpu_use.go
package main

func cpuUse() {
	n := 1024 * 1024 * 1024 * 10
	for i := 0; i < n; i++ {
		i++
	}

}

func main() {
	cpuUse()
}

EOF
```

- 正常编译运行

```shell
go build cpu_use.go
time ./cpu_use 

real    0m2.130s
user    0m2.131s
sys     0m0.004s
```

- 可以看到耗时就在2秒多

> 使用 cgexec 加入my_cpu 的cgroup运行

```shell
time cgexec -g cpu:my_cpu ./cpu_use

real    0m21.538s
user    0m2.158s
sys     0m0.010s
```

- 可以看到耗时已经上涨到了21秒，但是真正在用户态运行就2秒，说明其他时间一直被限制
- 同时在运行过程中可以看到  /sys/fs/cgroup/cpu/my_cpu/tasks 中被写入 cpu_use的线程id

```shell
 ps -efT |grep cpu_use
root     13772 13772 26216  8 19:17 pts/1    00:00:00 ./cpu_use
root     13772 13773 26216  0 19:17 pts/1    00:00:00 ./cpu_use
root     13772 13774 26216  0 19:17 pts/1    00:00:00 ./cpu_use
root     13772 13775 26216  0 19:17 pts/1    00:00:00 ./cpu_use
root     13772 13776 26216  0 19:17 pts/1    00:00:00 ./cpu_use
root     13772 13777 26216  0 19:17 pts/1    00:00:00 ./cpu_use
root     13830 13830 19237  0 19:18 pts/0    00:00:00 grep --color=auto cpu_use
 cat /sys/fs/cgroup/cpu/my_cpu/tasks 
13772
13773
13774
13775
13776
13777
```

## 限制进程可用的内存

> 准备subsystem 目录

```shell
mkdir -pv  /sys/fs/cgroup/memory/my_mem

```

> 下面的设置把进程的可用内存限制在最大 300M，并且不使用 swap：

```shell
echo 314572800 > /sys/fs/cgroup/memory/my_mem/memory.limit_in_bytes
echo 0 > /sys/fs/cgroup/memory/my_mem/memory.swappiness

```

> 准备go代码

- 共申请5次内存，每次100MB
- arr代表100MB内存大小的arr，因为一个int64是8byte，128就是1024

```shell
cat <<EOF > mem_use.go
package main

import (
	"fmt"
	"unsafe"
)

func memUse() {
	for i := 0; i < 5; i++ {
		// arr代表100MB内存大小的arr，因为一个int64是8byte，128就是1024 
		arr := [128 * 1024 * 1024]int64{}
		fmt.Printf("[index:%v][size:%v]\n", i+1, unsafe.Sizeof(arr))
	}

}

func main() {
	memUse()
}

EOF
```

> 正常编译运行

```shell
go build mem_use.go 
./mem_use 
[index:1][size:1073741824]
[index:2][size:1073741824]
[index:3][size:1073741824]
[index:4][size:1073741824]
[index:5][size:1073741824]
```

> 添加memory cgroup 限制 后运行

```shell
cgexec -g memory:my_mem ./mem_use
[index:1][size:1073741824]
[index:2][size:1073741824]
Killed
```

- 程序中途被kill了，因为申请的总量已经超过cgroup的限制了
- 同时观察 /var/log/messages 中oom的信息

```shell
Sep 26 19:38:54 k8s-master01 kernel: mem_use invoked oom-killer: gfp_mask=0xd0, order=0, oom_score_adj=0
Sep 26 19:38:54 k8s-master01 kernel: mem_use cpuset=/ mems_allowed=0
Sep 26 19:38:54 k8s-master01 kernel: CPU: 2 PID: 5454 Comm: mem_use Kdump: loaded Tainted: G             L ------------ T 3.10.0-957.1.3.el7.x86_64 #1
Sep 26 19:38:54 k8s-master01 kernel: Hardware name: Red Hat KVM, BIOS 1.10.2-3.el7_4.1 04/01/2014
Sep 26 19:38:54 k8s-master01 kernel: Call Trace:
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa1761e41>] dump_stack+0x19/0x1b
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa175c86a>] dump_header+0x90/0x229
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa11ba036>] ? find_lock_task_mm+0x56/0xc0
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa11ba4e4>] oom_kill_process+0x254/0x3d0
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa1235186>] mem_cgroup_oom_synchronize+0x546/0x570
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa1234600>] ? mem_cgroup_charge_common+0xc0/0xc0
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa11bad74>] pagefault_out_of_memory+0x14/0x90
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa175ad72>] mm_fault_error+0x6a/0x157
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa176f7a8>] __do_page_fault+0x3c8/0x500
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa176f9c6>] trace_do_page_fault+0x56/0x150
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa176ef42>] do_async_page_fault+0x22/0xf0
Sep 26 19:38:54 k8s-master01 kernel: [<ffffffffa176b788>] async_page_fault+0x28/0x30
Sep 26 19:38:54 k8s-master01 kernel: Task in /my_mem killed as a result of limit of /my_mem
Sep 26 19:38:54 k8s-master01 kernel: memory: usage 307200kB, limit 307200kB, failcnt 567
Sep 26 19:38:54 k8s-master01 kernel: memory+swap: usage 307200kB, limit 9007199254740988kB, failcnt 0
Sep 26 19:38:54 k8s-master01 kernel: kmem: usage 0kB, limit 9007199254740988kB, failcnt 0
Sep 26 19:38:54 k8s-master01 kernel: Memory cgroup stats for /my_mem: cache:0KB rss:307200KB rss_huge:0KB mapped_file:0KB swap:0KB inactive_anon:0KB active_anon:307192KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 26 19:38:54 k8s-master01 kernel: [ pid ]   uid  tgid total_vm      rss nr_ptes swapents oom_score_adj name
Sep 26 19:38:54 k8s-master01 kernel: [ 5450]     0  5450   717445    76878     165        0             0 mem_use
Sep 26 19:38:54 k8s-master01 kernel: Memory cgroup out of memory: Kill process 5456 (mem_use) score 973 or sacrifice child
Sep 26 19:38:54 k8s-master01 kernel: Killed process 5450 (mem_use) total-vm:2869780kB, anon-rss:306836kB, file-rss:676kB, shmem-rss:0kB
```

# 本节重点总结 :

- Cgroups全称Control Groups，是Linux内核提供的物理资源隔离机制，可以实现进程的资源隔离
- cgroup v1的子系统介绍
- golang代码体验 cgroup 的cpu和memory限制