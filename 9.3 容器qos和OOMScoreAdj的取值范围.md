

#  本节重点总结 : 
- 不可压缩资源和节点稳定性
    - 不可压缩资源（内存、磁盘容量和inode、PID）不够使用时，会严重影响节点的稳定性
    - 为此，kubelet作为linux用户态进程和k8s集群的节点代理，应该有一定的机制来维持节点的稳定性
    - 本质是通过删除镜像和停止容器进程来达到目的

- 有两道防线来维持节点的稳定性
    - 第一道防线是用户进程kubelet
        - 优先清理停止的pod和不用的镜像
        - 其次根据pod 排行打分进行驱逐 ，根据Pod实际使用资源的状态、以及用户配置的资源阈值，驱逐
    - 第二道防线是Linux OOM KILLER
        - 第一道防线和第二道防线之间会有一种协作，就是oom_score_adj
        - kubelet在创建容器的时候，可设置oom_score_adj，从而影响Linux OOM KILLER杀死进程
        
- 根据yaml配置的容器内存request和limit决定容器的 qos，在启动容器的时候根据不同的qos设置OOMScoreAdj，供linux内核oom时决策


# 容器qos
> kubernetes 中有三种 Qos，分别为：
- Guaranteed：Pod中所有Container的所有Resource的limit和request都相等且不为0；
- Burstable：pod不满足Guaranteed条件，但是其中至少有一个container设置了requests或limits ；
- BestEffort：pod的 requests 与 limits 均没有设置；
 

# 容器启动时设置oom_score_adj
- 对应的代码在qos包中，位置 D:\go_path\src\github.com\kubernetes\kubernetes\pkg\kubelet\qos\policy.go
- 我们知道 OOMScoreAdj值越大越先被oom ，范围在-1000 到 1000
- 可以看到kubelet的和kube-proxy进程的 OOMScoreAdj被设置为-999 也就是最后被oom
- 而guaranteed被设置为 -997 也比较低
- besteffort被被设置为1000，最高也就是 没有设置容器内存的request 和limit
```go
const (
	// KubeletOOMScoreAdj is the OOM score adjustment for Kubelet
	KubeletOOMScoreAdj int = -999
	// KubeProxyOOMScoreAdj is the OOM score adjustment for kube-proxy
	KubeProxyOOMScoreAdj  int = -999
	guaranteedOOMScoreAdj int = -997
	besteffortOOMScoreAdj int = 1000
)


```


## GetContainerOOMScoreAdjust 根据qos获取容器进程的OOMScoreAdjust
- 如果是k8s系统的核心容器那么 OOMScoreAdj就是guaranteedOOMScoreAdj -997 
```go
	if types.IsNodeCriticalPod(pod) {
		// Only node critical pod should be the last to get killed.
		return guaranteedOOMScoreAdj
	}
```
- 如果容器的qos为 PodQOSGuaranteed 就设置为 -997
- 如果容器的qos为 PodQOSBestEffort 就设置为 1000

```go
	switch v1qos.GetPodQOS(pod) {
	case v1.PodQOSGuaranteed:
		// Guaranteed containers should be the last to get killed.
		return guaranteedOOMScoreAdj
	case v1.PodQOSBestEffort:
		return besteffortOOMScoreAdj
	}

```
- 如果容器的qos为 burstable 那么计算稍微复杂一点，先用下面的公式计算值 
```go
	oomScoreAdjust := 1000 - (1000*memoryRequest)/memoryCapacity
```
- 然后再判断一下边界 ，保证不能小于 1000 + guaranteedOOMScoreAdj 也就是3 
```go
	if int(oomScoreAdjust) < (1000 + guaranteedOOMScoreAdj) {
		return (1000 + guaranteedOOMScoreAdj)
	}
```
- 不能大于besteffortOOMScoreAdj 也就是 999
```go
	if int(oomScoreAdjust) == besteffortOOMScoreAdj {
		return int(oomScoreAdjust - 1)
	}
```


### 所以可以得到容器qos 和 OOMScoreAdj的取值范围
|  pod类型   |OOMScoreAdj的取值| 
|  ----  | ----  | 
| Guaranteed (设置了request和limit，两者相等)  | -997|
| BestEffort (没有request和limit)  | 1000|
| burstable (request和limit至少设置了一个)  | 3-999之间|
| Kubelet进程 | -999 | 
| Kube-proxy进程 | -999 | 
| 其他k8snode上关键容器 | -999 | 


## oomScoreAdj何时被设置
- 追踪 GetContainerOOMScoreAdjust可知一路追查到startContainer中，也就是启动容器的时候会根据 yaml中的配置被设置
```go
func (m *kubeGenericRuntimeManager) generateLinuxContainerConfig(container *v1.Container, pod *v1.Pod, uid *int64, username string, nsTarget *kubecontainer.ContainerID, enforceMemoryQoS bool) *runtimeapi.LinuxContainerConfig {
	
	oomScoreAdj := int64(qos.GetContainerOOMScoreAdjust(pod, container,
		int64(m.machineInfo.MemoryCapacity)))
}


// applyPlatformSpecificContainerConfig applies platform specific configurations to runtimeapi.ContainerConfig.
func (m *kubeGenericRuntimeManager) applyPlatformSpecificContainerConfig(config *runtimeapi.ContainerConfig, container *v1.Container, pod *v1.Pod, uid *int64, username string, nsTarget *kubecontainer.ContainerID) error {
	enforceMemoryQoS := false
	// Set memory.min and memory.high if MemoryQoS enabled with cgroups v2
	if utilfeature.DefaultFeatureGate.Enabled(kubefeatures.MemoryQoS) &&
		libcontainercgroups.IsCgroup2UnifiedMode() {
		enforceMemoryQoS = true
	}
	config.Linux = m.generateLinuxContainerConfig(container, pod, uid, username, nsTarget, enforceMemoryQoS)
	return nil
}

// generateContainerConfig generates container config for kubelet runtime v1.
func (m *kubeGenericRuntimeManager) generateContainerConfig(container *v1.Container, pod *v1.Pod, restartCount int, podIP, imageRef string, podIPs []string, nsTarget *kubecontainer.ContainerID) (*runtimeapi.ContainerConfig, func(), error) {
		// set platform specific configurations.
    	if err := m.applyPlatformSpecificContainerConfig(config, container, pod, uid, username, nsTarget); err != nil {
    		return nil, cleanupAction, err
    	}

}
// 位置 D:\go_path\src\github.com\kubernetes\kubernetes\pkg\kubelet\kuberuntime\kuberuntime_container.go
func (m *kubeGenericRuntimeManager) startContainer(podSandboxID string, podSandboxConfig *runtimeapi.PodSandboxConfig, spec *startSpec, pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, podIP string, podIPs []string) (string, error) {
		containerConfig, cleanupAction, err := m.generateContainerConfig(container, pod, restartCount, podIP, imageRef, podIPs, target)
    	if cleanupAction != nil {
    		defer cleanupAction()
    	}
}
```



#  本节重点总结 : 
- 不可压缩资源和节点稳定性
    - 不可压缩资源（内存、磁盘容量和inode、PID）不够使用时，会严重影响节点的稳定性
    - 为此，kubelet作为linux用户态进程和k8s集群的节点代理，应该有一定的机制来维持节点的稳定性
    - 本质是通过删除镜像和停止容器进程来达到目的

- 有两道防线来维持节点的稳定性
    - 第一道防线是用户进程kubelet
        - 优先清理停止的pod和不用的镜像
        - 其次根据pod 排行打分进行驱逐 ，根据Pod实际使用资源的状态、以及用户配置的资源阈值，驱逐
    - 第二道防线是Linux OOM KILLER
        - 第一道防线和第二道防线之间会有一种协作，就是oom_score_adj
        - kubelet在创建容器的时候，可设置oom_score_adj，从而影响Linux OOM KILLER杀死进程
        
- 根据yaml配置的容器内存request和limit决定容器的 qos，在启动容器的时候根据不同的qos设置OOMScoreAdj，供linux内核oom时决策
