
# 为什么讲istio之前要先学习envoy
- 因为核心的转发流量都在envoy上
- istio 可以理解为借助xds 更新envoy的配置

# envoy 简介
- Envoy 是一个面向服务架构的 L7 代理和通信总线而设计的，这个项目诞生是出于以下目标：
- 对于应用程序而言，网络应该是透明的，当发生网络和应用程序故障时，能够很容易定位出问题的根源。

> 中文文档地址
- https://cloudnative.to/envoy/intro/what_is_envoy.html



## Envoy 的核心功能：
- 非侵入的架构：Envoy 是和应用服务并行运行的，透明地代理应用服务发出/接收的流量。应用服务只需要和 Envoy 通信，无需知道其他微服务应用在哪里。
- 基于 Modern C++11 实现，性能优异。
- L3/L4 过滤器架构：Envoy 的核心是一个 L3/L4 代理，然后通过插件式的过滤器(network filters)链条来执行 TCP/UDP 的相关任务，例如 TCP 转发，TLS 认证等工作。
- HTTP L7 过滤器架构：HTTP 在现代应用体系里是地位非常特殊的应用层协议，所以 Envoy 内置了一个非常核心的过滤器: http_connection_manager。http_connection_manager 本身是如此特殊和复杂，支持丰富的配置，以及本身也是过滤器架构，可以通过一系列 http 过滤器来实现 http 协议层面的任务，例如：http 路由，重定向，CORS 支持等等。
- HTTP/2 作为第一公民：Envoy 支持 HTTP/1.1 和 HTTP/2，推荐使用 HTTP/2。
- gRPC 支持：因为对 HTTP/2 的良好支持，Envoy 可以方便的支持 gRPC，特别是在负载和代理上。
- 服务发现： 支持包括 DNS, EDS 在内的多种服务发现方案。
- 健康检查：内置健康检查子系统。
- 高级的负载均衡方案：除了一般的负载均衡，Envoy 还支持基于 rate limit 服务的多种高级负载均衡方案，包括： automatic retries、circuit breaking、global rate limiting 等。
- Tracing：方便集成 Open Tracing 系统，追踪请求
- 统计与监控：内置 stats 模块，方便集成诸如 prometheus/statsd 等监控方案
- 动态配置：通过“动态配置API”实现配置的动态调整，而无需重启 Envoy 服务的



## envoy 基础配置
- Envoy 使用 YAML 配置文件来控制代理的行为
- 在下面的步骤中，我们将使用静态配置接口来构建配置，也意味着所有设置都是预定义在配置文件中的
- 此外 Envoy 也支持动态配置，这样可以通过外部一些源来自动发现进行设置。

### 01 资源
- Envoy 配置的第一行定义了正在使用的接口配置，在这里我们将配置静态 API，因此第一行应为
```yaml
static_resources:
```

### 02 监听器
- 在配置的开始定义了监听器（Listeners）。监听器是 Envoy 监听请求的网络配置，例如 IP 地址和端口
- 我们这里的 Envoy 在 Docker 容器内运行，因此它需要监听 IP 地址 0.0.0.0，在这种情况下，Envoy 将在端口 10000 上进行监听
```yaml
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address: { address: 0.0.0.0, port_value: 10000 }
```

### 03 过滤器
- 通过 Envoy 监听传入的流量，下一步是定义如何处理这些请求。每个监听器都有一组过滤器，并且不同的监听器可以具有一组不同的过滤器。
- 在我们这个示例中，我们将所有流量代理到 baidu.com，配置完成后我们应该能够通过请求 Envoy 的端点就可以直接看到百度的主页了，而无需更改 URL 地址。
- 过滤器是通过 filter_chains 来定义的，每个过滤器的目的是找到传入请求的匹配项，以使其与目标地址进行匹配：
```yaml
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address: { address: 0.0.0.0, port_value: 10000 }

    filter_chains:
    - filters:
      # 该过滤器使用了 envoy.http_connection_manager，这是为 HTTP 连接设计的一个内置过滤器:
      - name: envoy.http_connection_manager 
        config:
          stat_prefix: ingress_http
          # route_config：路由配置，如果虚拟主机匹配上了则检查路由。在我们这里的配置中，无论请求的主机域名是什么，route_config 都匹配所有传入的 HTTP 请求。
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              # routes：如果 URL 前缀匹配，则一组路由规则定义了下一步将发生的状况。/ 表示匹配根路由。
              routes:
              - match: { prefix: "/" }
                # host_rewrite：更改 HTTP 请求的入站 Host 头信息。
                # cluster: 将要处理请求的集群名称，下面会有相应的实现。
                route: { host_rewrite: www.baidu.com, cluster: service_baidu }
          # http_filters: 该过滤器允许 Envoy 在处理请求时去适应和修改请求。
          http_filters:
          - name: envoy.router
```

### 04 集群
- 当请求于过滤器匹配时，该请求将会传递到集群，相当于nginx 的upstream
- 下面的配置就是将主机定义为访问 HTTPS 的 baidu.com 域名，如果定义了多个主机，则 Envoy 将执行轮询（Round Robin）策略。配置如下所示：
```yaml
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address: { address: 0.0.0.0, port_value: 10000 }

    filter_chains:
    - filters:
      - name: envoy.http_connection_manager
        config:
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match: { prefix: "/" }
                route: { host_rewrite: www.baidu.com, cluster: service_baidu }
          http_filters:
          - name: envoy.router

  clusters:
  - name: service_baidu
    connect_timeout: 0.25s
    type: LOGICAL_DNS
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    hosts: [{ socket_address: { address: www.baidu.com, port_value: 443 }}]
    tls_context: { sni: baidu.com }
```

  

### 05 管理
- 配置一个管理模块，监听在 10001端口上
```yaml
admin:
  access_log_path: /tmp/admin_access.log
  address:
    socket_address: { address: 0.0.0.0, port_value: 10001 }
```

### 06 编写完整的配置文件并启动envoy
- 上面的配置定义了 Envoy 的静态配置模板
    - 监听器定义了 Envoy 的端口和 IP 地址
    - 监听器具有一组过滤器来匹配传入的请求
    - 匹配请求后，将请求转发到集群。
- 通过 Docker 容器来启动 Envoy，将上面的配置文件通过 Volume 挂载到容器中的 /etc/envoy/envoy.yaml 文件。
- 编写配置文件
```shell script
cat <<"EOF" > envoy.yaml
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address: { address: 0.0.0.0, port_value: 10000 }

    filter_chains:
    - filters:
      - name: envoy.http_connection_manager
        config:
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match: { prefix: "/" }
                route: { host_rewrite: www.baidu.com, cluster: service_baidu }
          http_filters:
          - name: envoy.router

  clusters:
  - name: service_baidu
    connect_timeout: 0.25s
    type: LOGICAL_DNS
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    hosts: [{ socket_address: { address: www.baidu.com, port_value: 443 }}]
    tls_context: { sni: baidu.com }

admin:
  access_log_path: /tmp/admin_access.log
  address:
    socket_address: { address: 0.0.0.0, port_value: 9901 }
EOF
```
- docker run 命令启动
```shell script
 docker run --name=envoy -d \
  -p 80:10000 \
  -v `pwd`/envoy.yaml:/etc/envoy/envoy.yaml \
  envoyproxy/envoy:latest
```

- 然后访问localhost发现，请求被代理到了 baidu.com，而且应该也可以看到 URL 地址没有变化，还是 localhost。

### 07 管理视图
- Envoy 提供了一个管理视图，可以让我们去查看配置、统计信息、日志以及其他 Envoy 内部的一些数据。
- 我们可以通过添加其他的资源定义来配置 admin，其中也可以定义管理视图的端口，不过需要注意该端口不要和其他监听器配置冲突。
```shell script
docker run --name=envoy-with-admin -d \
    -p 15000:10000 \
    -p 15001:9901 \
    -v $(pwd)/envoy.yaml:/etc/envoy/envoy.yaml \
    envoyproxy/envoy:latest
```
- 然后访问节点的 15000端口就是代理到baidu.com 
- 访问节点的 15001端口就是admin管理后台 


## 迁移 NGINX 到 Envoy
- 大部分的应用可能还是使用的比较传统的 Nginx 来做服务代理，本文我们将介绍如何将 Nginx 的配置迁移到 Envoy 上来。
    - 如何设置 Envoy 代理配置
    - 配置 Envoy 代理转发请求到外部服务
    - 配置访问和错误日志
- 最后我们还会了解到 Envoy 代理的核心功能，以及如何将现有的 Nginx 配置迁移到 Envoy 上来。

### 01 Nginx 示例
- 这里我们使用 Nginx 官方 Wiki 的完整示例来进行说明，完整的 nginx.conf 配置如下所示：
```shell script
user  www www;
pid /var/run/nginx.pid;
worker_processes  2;

events {
  worker_connections   2000;
}

http {
  gzip on;
  gzip_min_length  1100;
  gzip_buffers     4 8k;
  gzip_types       text/plain;

  log_format main      '$remote_addr - $remote_user [$time_local]  '
    '"$request" $status $bytes_sent '
    '"$http_referer" "$http_user_agent" '
    '"$gzip_ratio"';

  log_format download  '$remote_addr - $remote_user [$time_local]  '
    '"$request" $status $bytes_sent '
    '"$http_referer" "$http_user_agent" '
    '"$http_range" "$sent_http_content_range"';

  upstream targetCluster {
    172.17.0.3:80;
    172.17.0.4:80;
  }

  server {
    listen        8080;
    server_name   one.example.com  www.one.example.com;

    access_log   /var/log/nginx.access_log  main;
    error_log  /var/log/nginx.error_log  info;

    location / {
      proxy_pass         http://targetCluster/;
      proxy_redirect     off;

      proxy_set_header   Host             $host;
      proxy_set_header   X-Real-IP        $remote_addr;
    }
  }
}
```
- 上面的 Nginx 配置有3个核心配置：
    - 配置 Nginx 服务、日志结构和 Gzip 功能
    - 配置 Nginx 在端口 8080 上接受对 one.example.com 域名的请求
    - 根据不同的路径配置将流量转发给目标服务
- 并不是所有的 Nginx 的配置都适用于 Envoy，有些方面的配置我们可以不用关心
- Envoy 代理主要有4中主要的配置类型，它们是支持 Nginx 提供的核心基础结构的:
    - Listeners（监听器）：他们定义 Envoy 代理如何接收传入的网络请求，建立连接后，它会传递到一组过滤器进行处理
    - Filters（过滤器）：过滤器是处理传入和传出请求的管道结构的一部分，比如可以开启类似于 Gzip 之类的过滤器，该过滤器就会在将数据发送到客户端之前进行压缩
    - Routers（路由器）：这些路由器负责将流量转发到定义的目的集群去
    - Clusters（集群）：集群定义了流量的目标端点和相关配置。
- 我们将使用这4个组件来创建 Envoy 代理配置，去匹配 Nginx 中的配置。Envoy 的重点一直是在 API 和动态配置上，但是我们这里需要使用静态配置。



### 02 nginx配置
#### 工作连接
- 首先是 Worker 连接数配置，主要是用于定义工作进程和连接的数量，用来配置 Nginx 扩展请求请求：
```shell script
worker_processes  2;

events {
  worker_connections   2000;
}

```
- Envoy 代理用另外一种不同的方式来管理工作进程和连接。Envoy 使用单进程-多线程的架构模型
- 一个 master 线程管理各种琐碎的任务，而一些 worker 线程则负责执行监听、过滤和转发。
- 所以这里并不需要显示的配置

#### HTTP 配置
- 然后 Nginx 配置的下一个部分是定义 HTTP 配置，比如：
    - 定义支持哪些 MIME 类型
    - 默认的超时时间
    - Gzip 配置
- 在 HTTP 配置部分，Nginx 配置指定了监听的端口 8080，并响应域名 one.example.com 和 www.one.example.com 的传入请求：
```shell script
server {
    listen        8080;
    server_name   one.example.com  www.one.example.com;
    ......
}
```
- 在 Envoy 中，这部分就是监听器来管理的。开始一个 Envoy 代理最重要的方面就是定义监听器，我们需要创建一个配置文件来描述我们如何去运行 Envoy 实例。
```yaml
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address: { address: 0.0.0.0, port_value: 8080 }
```

#### Location 配置
- 当请求进入 Nginx 时，location 部分定义了如何处理流量以及在什么地方转发流量
- 在下面的配置中，站点的所有传入流量都将被代理到一个名为 targetCluster 的上游（upstream）集群，上游集群定义了处理请求的节点。
```shell script
location / {
    proxy_pass         http://targetCluster/;
    proxy_redirect     off;

    proxy_set_header   Host             $host;
    proxy_set_header   X-Real-IP        $remote_addr;
}
```
- 在 Envoy 中，这部分将由过滤器来进行配置管理
- 在静态配置中，过滤器定义了如何处理传入的请求，在我们这里，将配置一个过滤器去匹配上一步中的 server_names，当接收到与定义的域名和路由匹配的传入请求时，流量将转发到集群，集群和 Nginx 配置中的 upstream 是一致的。
```yaml
filter_chains:
- filters:
  - name: envoy.http_connection_manager
    config:
      codec_type: auto
      stat_prefix: ingress_http
      route_config:
        name: local_route
        virtual_hosts:
        - name: backend
          domains:
          - "one.example.com"
          - "www.one.example.com"
          routes:
          - match:
              prefix: "/"
            route:
              cluster: targetCluster
      http_filters:
      - name: envoy.router
```
- 其中 envoy.http_connection_manager 是 Envoy 内置的一个过滤器，用于处理 HTTP 连接的，除此之外，还有其他的一些内置的过滤器，比如 Redis、Mongo、TCP。

#### upstream 配置
- 在 Nginx 中，upstream（上游）配置定义了处理请求的目标服务器集群，在我们这里的示例中，分配了两个后端server。
```shell script

upstream targetCluster {
  172.17.0.3:80;
  172.17.0.4:80;
}
```
- 在 Envoy 代理中，这部分是通过集群进行配置管理的。upstream 等同与 Envoy 中的 clusters 定义，我们这里通过集群定义了主机被访问的方式，还可以配置超时和负载均衡等方面更精细的控制。
```yaml
clusters:
- name: targetCluster
  connect_timeout: 0.25s
  type: STRICT_DNS
  dns_lookup_family: V4_ONLY
  lb_policy: ROUND_ROBIN
  hosts: [
    { socket_address: { address: 172.17.0.3, port_value: 80 }},
    { socket_address: { address: 172.17.0.4, port_value: 80 }}
  ]
```
- 上面我们配置了 STRICT_DNS 类型的服务发现，Envoy 会持续异步地解析指定的 DNS 目标
- DNS 解析结果返回的每个 IP 地址都将被视为上游集群的主机
- 所以如果产线返回两个 IP 地址，则 Envoy 将认为集群由两个主机，并且两个主机都应进行负载均衡，如果从结果中删除了一个主机，则 Envoy 会从现有的连接池中将其剔出掉。

#### 日志配置
- 最后需要配置的日志部分，Envoy 采用云原生的方式，将应用程序日志都输出到 stdout 和 stderr，而不是将错误日志输出到磁盘。
  
- 当用户发起一个请求时，访问日志默认是被禁用的，我们可以手动开启
- 要为 HTTP 请求开启访问日志，需要在 HTTP 连接管理器中包含一个 access_log 的配置，该路径可以是设备，比如 stdout，也可以是磁盘上的某个文件，这依赖于我们自己的实际情况。
  
- 下面过滤器中的配置就会将所有访问日志通过管理传输到 stdout：
```yaml
- name: envoy.http_connection_manager
  config:
    codec_type: auto
    stat_prefix: ingress_http
    access_log:
    - name: envoy.file_access_log
      config:
        path: "/dev/stdout"
    route_config:
```
- 我们可以通过设置 format 字段来自定义输出日志的格式，类比nginx 的log_format，例如：

```yaml
access_log:
- name: envoy.file_access_log
  config:
    path: "/dev/stdout"
    format: "[%START_TIME%] "%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%" %RESPONSE_CODE% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% "%REQ(X-REQUEST-ID)%" "%REQ(:AUTHORITY)%" "%UPSTREAM_HOST%"\n"
```
  

#### 测试
> 写入配置文件
```shell script
cat <<"EOF" > envoy-nginx.yaml
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address: { address: 0.0.0.0, port_value: 8080 }

    filter_chains:
    - filters:
      - name: envoy.http_connection_manager
        config:
          codec_type: auto
          stat_prefix: ingress_http
          access_log:
          - name: envoy.file_access_log
            config:
              path: "/dev/stdout"
          route_config:
            name: local_route
            virtual_hosts:
            - name: backend
              domains:
                - "one.example.com"
                - "www.one.example.com"
              routes:
              - match:
                  prefix: "/"
                route:
                  cluster: targetCluster
          http_filters:
          - name: envoy.router

  clusters:
  - name: targetCluster
    connect_timeout: 0.25s
    type: STRICT_DNS
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    hosts: [
      { socket_address: { address: 172.20.70.205, port_value: 81 }},
      { socket_address: { address: 172.20.70.205, port_value: 82 }}
    ]
EOF
```

- 在 Nginx 配置的顶部，有一行配置 user www www; 表示用非 root 用户来运行 Nginx 以提高安全性
- 而 Envoy 代理采用云原生的方法来管理使用这，我们通过容器启动 Envoy 代理的时候，可以指定一个低特权的用户。
- 下面的命令将通过 Docker 容器来启动一个 Envoy 实例，该命令使 Envoy 可以监听 80 端口上的流量请求，但是我们在 Envoy 的监听器配置中指定的是 8080 端口，所以我们用一个低特权用户身份来运行：

```shell script

docker run --name proxy1 -p 80:8080 --user 1000:1000 -v $(pwd)/envoy-nginx.yaml:/etc/envoy/envoy.yaml envoyproxy/envoy

```
- 启动之后我们以 one.example.com 作为Host去访问 envoy ，发现报503错误
```shell script
[root@k8s-master01 envoy]# curl -H "Host: one.example.com" localhost -i
HTTP/1.1 503 Service Unavailable
content-length: 91
content-type: text/plain
date: Wed, 17 Nov 2021 07:23:05 GMT
server: envoy

upstream connect error or disconnect/reset before headers. reset reason: connection failure
``` 
- 同时在envoy的前台日志中也可以看到相关的报错
```shell script
[2021-11-17T07:25:30.834Z] "GET / HTTP/1.1" 503 UF 0 91 1 - "-" "curl/7.29.0" "29350cde-81bd-4c73-9f5b-2e10868b33b2" "one.example.com" "172.20.70.205:81"
[2021-11-17T07:25:35.535Z] "GET / HTTP/1.1" 503 UF 0 91 0 - "-" "curl/7.29.0" "120b275c-c654-43ee-a197-7d1636f226ba" "one.example.com" "172.20.70.205:82"
```
- 然后呢我们启动两个 http-server 分别暴露81和82端口，匹配我们上面envoy的配置
```shell script
docker run -p 81:80 -d cnych/docker-http-server
docker run -p 82:80 -d cnych/docker-http-server
```
- 这个docker-http-server会打印自身的docker id 作为响应

```shell script
[root@k8s-master01 envoy]# curl localhost:81
<h1>This request was processed by host: c1c644026c8b</h1>
[root@k8s-master01 envoy]# curl localhost:82
<h1>This request was processed by host: a730d0b3a363</h1>
[root@k8s-master01 envoy]# docker ps  
CONTAINER ID   IMAGE                      COMMAND                  CREATED         STATUS         PORTS                                              NAMES
a730d0b3a363   cnych/docker-http-server   "/app"                   2 minutes ago   Up 2 minutes   0.0.0.0:82->80/tcp, :::82->80/tcp                  nice_thompson
c1c644026c8b   cnych/docker-http-server   "/app"                   2 minutes ago   Up 2 minutes   0.0.0.0:81->80/tcp, :::81->80/tcp                  gifted_merkle
f700bcbf3a29   envoyproxy/envoy           "/docker-entrypoint.…"   7 minutes ago   Up 7 minutes   10000/tcp, 0.0.0.0:80->8080/tcp, :::80->8080/tcp   proxy1
[root@k8s-master01 envoy]# 
```

- 然后再去访问发现可以
```shell script
[root@k8s-master01 envoy]# curl -H "Host: one.example.com" localhost 
<h1>This request was processed by host: c1c644026c8b</h1>
[root@k8s-master01 envoy]# curl -H "Host: one.example.com" localhost -i
HTTP/1.1 200 OK
date: Wed, 17 Nov 2021 07:28:08 GMT
content-length: 58
content-type: text/html; charset=utf-8
x-envoy-upstream-service-time: 1
server: envoy

<h1>This request was processed by host: a730d0b3a363</h1>
[root@k8s-master01 envoy]# 

```
- 同时在envoy的日志中也能看到200的日志
```shell script
[2021-11-17T07:28:06.779Z] "GET / HTTP/1.1" 200 - 0 58 0 0 "-" "curl/7.29.0" "9391d013-60f8-4b27-8d19-37bf82c789fc" "one.example.com" "172.20.70.205:81"
[2021-11-17T07:28:08.385Z] "GET / HTTP/1.1" 200 - 0 58 1 1 "-" "curl/7.29.0" "37c84c32-b0a2-4ef7-a888-b20beec66adb" "one.example.com" "172.20.70.205:82"
```





# 本节重点总结
- Envoy 代理主要有4中主要的配置类型，它们是支持 Nginx 提供的核心基础结构的:
    - Listeners（监听器）：他们定义 Envoy 代理如何接收传入的网络请求，建立连接后，它会传递到一组过滤器进行处理
    - Filters（过滤器）：过滤器是处理传入和传出请求的管道结构的一部分，比如可以开启类似于 Gzip 之类的过滤器，该过滤器就会在将数据发送到客户端之前进行压缩
    - Routers（路由器）：这些路由器负责将流量转发到定义的目的集群去
    - Clusters（集群）：集群定义了流量的目标端点和相关配置。




  
  
   
  