# 本节重点总结
- 监控 Pod 的负载3种metrics来源
    - 资源型的，来自metrics-server ，metrics.k8s.io这个group 
    - 自定义的，来自prometheus-adapter，custom.metrics.k8s.io这个group
    - 外部的的，来自？，external.metrics.k8s.io这个group

# hpa的本质
- HPA - Horizontal Pod Autoscaler 的缩写，Pod 水平自动伸缩。通过对 Pod 负载的监控，来自动增加或者减少 Pod 的副本数量。
- 从字面意思来看，其主要包含了两部分：
    - 监控 Pod 的负载
    - 控制 Pod 的副本数量
    
# 源码入口
- 在autoscaling 中，位置D:\go_path\src\github.com\kubernetes\kubernetes\cmd\kube-controller-manager\app\autoscaling.go
- 代码如下
```go
func startHPAController(ctx ControllerContext) (controller.Interface, bool, error) {
	if !ctx.AvailableResources[schema.GroupVersionResource{Group: "autoscaling", Version: "v1", Resource: "horizontalpodautoscalers"}] {
		return nil, false, nil
	}

	return startHPAControllerWithRESTClient(ctx)
}
```

  
##  startHPAControllerWithRESTClient解析
- 首先构造两个clientConfig对象
```go
func startHPAControllerWithRESTClient(ctx ControllerContext) (controller.Interface, bool, error) {
	clientConfig := ctx.ClientBuilder.ConfigOrDie("horizontal-pod-autoscaler")
	hpaClient := ctx.ClientBuilder.ClientOrDie("horizontal-pod-autoscaler")

```
- 使用hpaclient构造一个apiVersionsGetter对象，并且定时执行函数，重置apiVersionsFromDiscovery的prefVersion
- 这里apiVersionsGetter对象看起来是用来选择获取metrics的，后面我们再具体看
```go
	apiVersionsGetter := custom_metrics.NewAvailableAPIsGetter(hpaClient.Discovery())
	// invalidate the discovery information roughly once per resync interval our API
	// information is *at most* two resync intervals old.
	go custom_metrics.PeriodicallyInvalidate(
		apiVersionsGetter,
		ctx.ComponentConfig.HPAController.HorizontalPodAutoscalerSyncPeriod.Duration,
		ctx.Stop)
// PeriodicallyInvalidate periodically invalidates the preferred version cache until
// told to stop.
func PeriodicallyInvalidate(cache AvailableAPIsGetter, interval time.Duration, stopCh <-chan struct{}) {
	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			cache.Invalidate()
		case <-stopCh:
			return
		}
	}
}
// Invalidate refreshes the preferred version information.
func (d *apiVersionsFromDiscovery) Invalidate() {
	d.mu.Lock()
	defer d.mu.Unlock()

	d.prefVersion = nil
}

```
- 然后这里创建了1个metricsClient，字面上的意思就是获取pod metrics的client
```go
	metricsClient := metrics.NewRESTMetricsClient(
		resourceclient.NewForConfigOrDie(clientConfig),
		custom_metrics.NewForConfig(clientConfig, ctx.RESTMapper, apiVersionsGetter),
		external_metrics.NewForConfigOrDie(clientConfig),
	)
```

### NewRESTMetricsClient 分析
- 首先分析一下三个入参
#### 01 resourceclient.NewForConfigOrDie(clientConfig)
- 代表 资源型的metrics client-config，资源型对应的就是基础的cpu和内存
- 追踪这个resourceclient的构建
```go
// NewForConfigOrDie creates a new MetricsV1beta1Client for the given config and
// panics if there is an error in the config.
func NewForConfigOrDie(c *rest.Config) *MetricsV1beta1Client {
	client, err := NewForConfig(c)
	if err != nil {
		panic(err)
	}
	return client
}
// NewForConfig creates a new MetricsV1beta1Client for the given config.
func NewForConfig(c *rest.Config) (*MetricsV1beta1Client, error) {
	config := *c
	if err := setConfigDefaults(&config); err != nil {
		return nil, err
	}
	client, err := rest.RESTClientFor(&config)
	if err != nil {
		return nil, err
	}
	return &MetricsV1beta1Client{client}, nil
}
```
- 重点在setConfigDefaults中可以看到对应的就是 metrics.k8s.io这个group，版本为v1beta1
```go
func setConfigDefaults(config *rest.Config) error {
	gv := v1beta1.SchemeGroupVersion
	config.GroupVersion = &gv
	config.APIPath = "/apis"
	config.NegotiatedSerializer = scheme.Codecs.WithoutConversion()

	if config.UserAgent == "" {
		config.UserAgent = rest.DefaultKubernetesUserAgent()
	}

	return nil
}
// D:\go_path\src\github.com\kubernetes\kubernetes\staging\src\k8s.io\metrics\pkg\apis\metrics\v1beta1\register.go
// GroupName is the group name use in this package
const GroupName = "metrics.k8s.io"

// SchemeGroupVersion is group version used to register these objects
var SchemeGroupVersion = schema.GroupVersion{Group: GroupName, Version: "v1beta1"}

```
- 我们使用 kubectl get api-service，可以看到其他都是local类型的service， v1beta1.metrics.k8s.io的service来自kube-system/metrics-server
```shell script
[root@k8s-master01 mem]# kubectl get apiservice
NAME                                   SERVICE                      AVAILABLE   AGE

v1beta1.flowcontrol.apiserver.k8s.io   Local                        True        21d
v1beta1.metrics.k8s.io                 kube-system/metrics-server   True        16h
v1beta1.networking.k8s.io              Local                        True        21d
v1beta1.node.k8s.io                    Local                        True        21d
v1beta1.policy                         Local                        True        21d
v1beta1.rbac.authorization.k8s.io      Local                        True        21d
v1beta1.scheduling.k8s.io              Local                        True        21d
v1beta1.storage.k8s.io                 Local                        True        21d
v2beta1.autoscaling                    Local                        True        21d
v2beta2.autoscaling                    Local                        True        21d

```
- 其实这个来自于我们部署 metrics-server时，其中部署了一个名字叫做 v1beta1.metrics.k8s.io的 APIService，对应访问的就是kube-system ns下的metrics-server服务
```yaml
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  labels:
    k8s-app: metrics-server
  name: v1beta1.metrics.k8s.io
spec:
  group: metrics.k8s.io
  groupPriorityMinimum: 100
  insecureSkipTLSVerify: true
  service:
    name: metrics-server
    namespace: kube-system
  version: v1beta1
  versionPriority: 100

```
- 也就是说当我们请求metrics.k8s.io这个group 的v1beta1版本资源时访问的是我们部署的metrics-server服务
```shell script
kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes |python -m json.tool
```


#### 02 custom_metrics.NewForConfig
- 这个代表自定义指标的client
- 这里可以看到构建一个multiClient对象，同时看到newClient是一个方法，
```go
// NewForConfig creates a new custom metrics client which delegates to a client which
// uses the preferred api version.
func NewForConfig(baseConfig *rest.Config, mapper meta.RESTMapper, availableAPIs AvailableAPIsGetter) CustomMetricsClient {
	return &multiClient{
		clients:       make(map[schema.GroupVersion]CustomMetricsClient),
		availableAPIs: availableAPIs,

		newClient: func(ver schema.GroupVersion) (CustomMetricsClient, error) {
			return NewForVersionForConfig(rest.CopyConfig(baseConfig), mapper, ver)
		},
	}
}
```
- 那么追踪这个newClient的调用发现在getPreferredClient方法中，同时getPreferredClient中在头部又调用了PreferredVersion
```go
// getPreferredClient returns a custom metrics client of the preferred api version.
func (c *multiClient) getPreferredClient() (CustomMetricsClient, error) {
	pref, err := c.availableAPIs.PreferredVersion()
	if err != nil {
		return nil, err
	}

	c.mu.RLock()
	client, present := c.clients[pref]
	c.mu.RUnlock()
	if present {
		return client, nil
	}

	c.mu.Lock()
	defer c.mu.Unlock()
	client, err = c.newClient(pref)
	if err != nil {
		return nil, err
	}
	c.clients[pref] = client

	return client, nil
}

```
- PreferredVersion中又调用了fetchVersions，其中会遍历groups.Groups找到custom_metrics group custom.metrics.k8s.io
- 到这里我们知道这个是给custom_metrics 也就是我们后面章节中要讲到的prometheus-adapter项目
```go
func (d *apiVersionsFromDiscovery) PreferredVersion() (schema.GroupVersion, error) {
	groupInfo, err := d.fetchVersions()
}
// fetchVersions fetches the versions, but doesn't try to invalidate on cache misses.
func (d *apiVersionsFromDiscovery) fetchVersions() (*metav1.APIGroup, error) {
	// TODO(directxman12): amend the discovery interface to ask for a particular group (/apis/foo)
	groups, err := d.client.ServerGroups()
	if err != nil {
		return nil, err
	}

	// Determine the preferred version on the server by first finding the custom metrics group
	var apiGroup *metav1.APIGroup
	for _, group := range groups.Groups {
		if group.Name == cmint.GroupName {
			apiGroup = &group
			break
		}
	}

	if apiGroup == nil {
		return nil, fmt.Errorf("no custom metrics API (%s) registered", cmint.GroupName)
	}

	return apiGroup, nil
}

// D:\go_path\src\github.com\kubernetes\kubernetes\staging\src\k8s.io\metrics\pkg\apis\custom_metrics\register.go
// GroupName is the group name use in this package
const GroupName = "custom.metrics.k8s.io"

// SchemeGroupVersion is group version used to register these objects
var SchemeGroupVersion = schema.GroupVersion{Group: GroupName, Version: runtime.APIVersionInternal}

```

#### 03 external_metrics.NewForConfigOrDie
- 代表外部的metrics提供，往下追踪可以发现是 external.metrics.k8s.io
```go

func NewForConfigOrDie(c *rest.Config) ExternalMetricsClient {
	client, err := NewForConfig(c)
	if err != nil {
		panic(err)
	}
	return client
}
func NewForConfig(c *rest.Config) (ExternalMetricsClient, error) {
	configShallowCopy := *c
	if configShallowCopy.RateLimiter == nil && configShallowCopy.QPS > 0 {
		if configShallowCopy.Burst <= 0 {
			return nil, fmt.Errorf("burst is required to be greater than 0 when RateLimiter is not set and QPS is set to greater than 0")
		}
		configShallowCopy.RateLimiter = flowcontrol.NewTokenBucketRateLimiter(configShallowCopy.QPS, configShallowCopy.Burst)
	}
	configShallowCopy.APIPath = "/apis"
	if configShallowCopy.UserAgent == "" {
		configShallowCopy.UserAgent = rest.DefaultKubernetesUserAgent()
	}
	configShallowCopy.GroupVersion = &v1beta1.SchemeGroupVersion
	configShallowCopy.NegotiatedSerializer = scheme.Codecs.WithoutConversion()

	client, err := rest.RESTClientFor(&configShallowCopy)
	if err != nil {
		return nil, err
	}

	return New(client), nil
}
// D:\go_path\src\github.com\kubernetes\kubernetes\staging\src\k8s.io\metrics\pkg\apis\external_metrics\v1beta1\register.go
// GroupName is the group name use in this package
const GroupName = "external.metrics.k8s.io"

// SchemeGroupVersion is group version used to register these objects
var SchemeGroupVersion = schema.GroupVersion{Group: GroupName, Version: "v1beta1"}
```

### 回到hpa控制器启动 startHPAControllerWithMetricsClient解析
- 这里就是典型的控制器的启动模式
- 首先构建hpa client
```go
func startHPAControllerWithMetricsClient(ctx ControllerContext, metricsClient metrics.MetricsClient) (controller.Interface, bool, error) {
	hpaClient := ctx.ClientBuilder.ClientOrDie("horizontal-pod-autoscaler")
	hpaClientConfig := ctx.ClientBuilder.ConfigOrDie("horizontal-pod-autoscaler")

```
- 然后构建scaleClient ，代表就是解析不同资源对象要scale哪类子资源，比如dep scale rs
```go
	// we don't use cached discovery because DiscoveryScaleKindResolver does its own caching,
	// so we want to re-fetch every time when we actually ask for it
	scaleKindResolver := scale.NewDiscoveryScaleKindResolver(hpaClient.Discovery())
	scaleClient, err := scale.NewForConfig(hpaClientConfig, ctx.RESTMapper, dynamic.LegacyAPIPathResolverFunc, scaleKindResolver)
	if err != nil {
		return nil, false, err
	}
``` 
- 最后分两步走，先构建hpa控制器对象，然后执行它的run方法，传入hpascaler 和pod informer
```go
	go podautoscaler.NewHorizontalController(
		hpaClient.CoreV1(),
		scaleClient,
		hpaClient.AutoscalingV1(),
		ctx.RESTMapper,
		metricsClient,
		ctx.InformerFactory.Autoscaling().V1().HorizontalPodAutoscalers(),
		ctx.InformerFactory.Core().V1().Pods(),
		ctx.ComponentConfig.HPAController.HorizontalPodAutoscalerSyncPeriod.Duration,
		ctx.ComponentConfig.HPAController.HorizontalPodAutoscalerDownscaleStabilizationWindow.Duration,
		ctx.ComponentConfig.HPAController.HorizontalPodAutoscalerTolerance,
		ctx.ComponentConfig.HPAController.HorizontalPodAutoscalerCPUInitializationPeriod.Duration,
		ctx.ComponentConfig.HPAController.HorizontalPodAutoscalerInitialReadinessDelay.Duration,
	).Run(ctx.Stop)
```

### 然后来分析一下 NewHorizontalController
- 首先是 event相关
```go
// NewHorizontalController creates a new HorizontalController.
func NewHorizontalController(
	evtNamespacer v1core.EventsGetter,
	scaleNamespacer scaleclient.ScalesGetter,
	hpaNamespacer autoscalingclient.HorizontalPodAutoscalersGetter,
	mapper apimeta.RESTMapper,
	metricsClient metricsclient.MetricsClient,
	hpaInformer autoscalinginformers.HorizontalPodAutoscalerInformer,
	podInformer coreinformers.PodInformer,
	resyncPeriod time.Duration,
	downscaleStabilisationWindow time.Duration,
	tolerance float64,
	cpuInitializationPeriod,
	delayOfInitialReadinessStatus time.Duration,

) *HorizontalController {
	broadcaster := record.NewBroadcaster()
	broadcaster.StartStructuredLogging(0)
	broadcaster.StartRecordingToSink(&v1core.EventSinkImpl{Interface: evtNamespacer.Events("")})
	recorder := broadcaster.NewRecorder(scheme.Scheme, v1.EventSource{Component: "horizontal-pod-autoscaler"})

```
- 然后是构造hpa控制器对象
```go
	hpaController := &HorizontalController{
		eventRecorder:                recorder,
		scaleNamespacer:              scaleNamespacer,
		hpaNamespacer:                hpaNamespacer,
		downscaleStabilisationWindow: downscaleStabilisationWindow,
		queue:                        workqueue.NewNamedRateLimitingQueue(NewDefaultHPARateLimiter(resyncPeriod), "horizontalpodautoscaler"),
		mapper:                       mapper,
		recommendations:              map[string][]timestampedRecommendation{},
		scaleUpEvents:                map[string][]timestampedScaleEvent{},
		scaleDownEvents:              map[string][]timestampedScaleEvent{},
	}
```
- 给hpaInformer添加回调，这里的回调方法都是往队列中塞入hpa对象，都是调用的enqueueHPA
```go
	hpaInformer.Informer().AddEventHandlerWithResyncPeriod(
		cache.ResourceEventHandlerFuncs{
			AddFunc:    hpaController.enqueueHPA,
			UpdateFunc: hpaController.updateHPA,
			DeleteFunc: hpaController.deleteHPA,
		},
		resyncPeriod,
	)
	hpaController.hpaLister = hpaInformer.Lister()
	hpaController.hpaListerSynced = hpaInformer.Informer().HasSynced
// obj could be an *v1.HorizontalPodAutoscaler, or a DeletionFinalStateUnknown marker item.
func (a *HorizontalController) enqueueHPA(obj interface{}) {
	key, err := controller.KeyFunc(obj)
	if err != nil {
		utilruntime.HandleError(fmt.Errorf("couldn't get key for object %+v: %v", obj, err))
		return
	}

	// Requests are always added to queue with resyncPeriod delay.  If there's already
	// request for the HPA in the queue then a new request is always dropped. Requests spend resync
	// interval in queue so HPAs are processed every resync interval.
	a.queue.AddRateLimited(key)
}
```
- 设置pod informer的本地存储
```go
	hpaController.podLister = podInformer.Lister()
	hpaController.podListerSynced = podInformer.Informer().HasSynced
```
- 最后是构造一个计算副本的func，后面用来做scale 副本数量的计算
```go
	replicaCalc := NewReplicaCalculator(
		metricsClient,
		hpaController.podLister,
		tolerance,
		cpuInitializationPeriod,
		delayOfInitialReadinessStatus,
	)
	hpaController.replicaCalc = replicaCalc
```


# 本节重点总结
- 监控 Pod 的负载3种metrics来源
    - 资源型的，来自metrics-server ，metrics.k8s.io这个group 
    - 自定义的，来自prometheus-adapter，custom.metrics.k8s.io这个group
    - 外部的的，来自？，external.metrics.k8s.io这个group
    