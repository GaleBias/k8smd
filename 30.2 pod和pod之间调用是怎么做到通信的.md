# 本机重点总结

- 同一 Node 中 Pod 间通信：
  - Flannel模式： 同一 Node 中 Pod 的默认路由都是 docker0 的地址，由于它们关联在同一个 docker0（cni0）网桥上，地址网段相同，所有它们之间应当是能直接通信的。
  - calico模式：同一个node上的路由转发
- 不同 Node 中 Pod 间通信：
  - Flannel模式： 隧道设备封装/解封数据包实现
  - calico模式：纯三层的实现，因此可以避免与二层方案相关的数据包封装的操作，中间没有任何的NAT

# 不同Pod内的容器通信

## clico 模式

- Calico 项目由三个部分组成：

  - Calico 的 CNI 插件。这是 Calico 与 Kubernetes 对接的部分；
  - Felix。它是一个 DaemonSet，负责在宿主机上插入路由规则以及维护 Calico 所需的网络设备等工作；
  - BIRD。它就是 BGP 的客户端，专门负责在集群里分发路由规则信息。而其他边界网关上的这个小程序，则会对收到的这些数据进行分析，然后将需要的信息添加到自己的路由表里；
- Calico 项目与 Flannel 的 host-gw 模式的不同之处，就是它不会在宿主机上创建任何网桥设备。工作方式如下图：![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1636076058000/09e2f4d8858e4b2b9ece6f4596aa68f4.png)

#### 工作流程分析

- Calico 的 CNI 插件会为每个容器设置一个 Veth Pair 设备，然后把其中的一端放置在宿主机上（没有网桥），在node上执行ip a命令可以看到很多 calixxx的网卡

```shell
[root@k8s-node01 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether fa:fd:fa:59:e6:00 brd ff:ff:ff:ff:ff:ff
    inet 172.20.70.215/24 brd 172.20.70.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::f8fd:faff:fe59:e600/64 scope link 
       valid_lft forever preferred_lft forever
3: caliab299ca0c34: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link 
       valid_lft forever preferred_lft forever
4: vxlan.calico: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default 
    link/ether 66:00:91:ce:05:d5 brd ff:ff:ff:ff:ff:ff
    inet 10.100.85.193/32 scope global vxlan.calico
       valid_lft forever preferred_lft forever
    inet6 fe80::6400:91ff:fece:5d5/64 scope link 
       valid_lft forever preferred_lft forever
15: cali8bac6c0ff3f@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 1
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link 
       valid_lft forever preferred_lft forever
16: cali15c7619fccc@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 6
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link 
       valid_lft forever preferred_lft forever
17: cali11239f98883@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 7
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link 
       valid_lft forever preferred_lft forever
18: cali2ecad0b58db@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 8
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link 
       valid_lft forever preferred_lft forever
19: calie1b5053bbd3@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 11
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link 
       valid_lft forever preferred_lft forever
20: cali95fcb44ab02@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 12
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link 
       valid_lft forever preferred_lft forever
21: cali0432a2c0a3a@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 13
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link 
       valid_lft forever preferred_lft forever
22: calibe4e563fb8a@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 14
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link 
       valid_lft forever preferred_lft forever
23: calid75abf4f5e0@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 15
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link 
```

- 而且会在宿主机上为每个容器的 Veth Pair 设备配置一条路由规则，用于接收传入的 IP 包，在node上执行ip r 命令可以看到相关的路由

```shell
[root@k8s-node01 ~]# ip r
default via 172.20.70.254 dev eth0 
10.100.32.128/26 via 172.20.70.205 dev eth0 proto 80 onlink 
10.100.85.192 dev caliab299ca0c34 scope link 
10.100.85.197 dev cali61e1f9a06fa scope link 
10.100.85.203 dev cali5a4a62eb73c scope link 
10.100.85.204 dev cali8bac6c0ff3f scope link 
10.100.85.205 dev cali15c7619fccc scope link 
10.100.85.206 dev cali11239f98883 scope link 
10.100.85.207 dev cali2ecad0b58db scope link 
10.100.85.208 dev calie1b5053bbd3 scope link 
10.100.85.209 dev cali95fcb44ab02 scope link 
10.100.85.210 dev cali0432a2c0a3a scope link 
10.100.85.211 dev calibe4e563fb8a scope link 
10.100.85.212 dev calid75abf4f5e0 scope link 
10.100.85.213 dev cali1abad8afd57 scope link 
10.100.85.215 dev cali22a5b0c8530 scope link 
10.100.85.223 dev calib0fcb148121 scope link 
10.100.85.228 dev calia1f109c0158 scope link 
10.100.85.229 dev calicdd26318445 scope link 
10.100.85.233 dev cali0761ccbeace scope link 
10.100.85.234 dev cali0d7763386da scope link 
10.100.85.238 dev caliac7cd485d76 scope link 
10.100.85.241 dev cali8284a295f10 scope link 
10.100.85.242 dev cali7b8cb8a0d4e scope link 
10.100.85.243 dev calif57f257da67 scope link 
10.100.85.244 dev cali7e3a1b6756b scope link 
10.100.85.245 dev cali8f8d4b79597 scope link 
10.100.85.251 dev caliedf44567bf4 scope link 
169.254.0.0/16 dev eth0 scope link metric 1002 
172.20.70.0/24 dev eth0 proto kernel scope link src 172.20.70.215 


```

- ip r路由对应的ip就是pod的ip

```shell
[root@k8s-master01 k8s_svc]# kubectl get pod -o wide |grep 10.100.85
grafana-756fb84d84-25vgx                   1/1     Running   0          14d     10.100.85.223   k8s-node01   <none>           <none>
nfs-client-provisioner-78577dfbf6-5vc8k    1/1     Running   1          7d22h   10.100.85.251   k8s-node01   <none>           <none>
nginx-deployment-curl01-5dfbf76b79-wknqh   1/1     Running   125        5d5h    10.100.85.203   k8s-node01   <none>           <none>
nginx-deployment-svc01-5cc6946cb4-4sdq7    1/1     Running   0          5d8h    10.100.85.228   k8s-node01   <none>           <none>
nginx-deployment-svc01-5cc6946cb4-64z5c    1/1     Running   0          5d4h    10.100.85.238   k8s-node01   <none>           <none>
nginx-deployment-svc01-5cc6946cb4-mqb7v    1/1     Running   0          5d4h    10.100.85.229   k8s-node01   <none>           <none>
nginx-deployment-svc05-68684b78bd-dk4wt    1/1     Running   0          4h21m   10.100.85.242   k8s-node01   <none>           <none>
nginx-deployment-svc05-68684b78bd-k2s8b    1/1     Running   0          4h21m   10.100.85.241   k8s-node01   <none>           <none>
nginx-deployment-svc06-6bd95799cf-4hx5h    1/1     Running   0          4h2m    10.100.85.244   k8s-node01   <none>           <none>
nginx-deployment-svc06-6bd95799cf-ljp64    1/1     Running   0          4h2m    10.100.85.243   k8s-node01   <none>           <none>
onepod-multicontiner02                     2/2     Running   0          44m     10.100.85.245   k8s-node01   <none>           <none>
web-0                                      1/1     Running   0          5d4h    10.100.85.234   k8s-node01   <none>           <none>
web-1                                      1/1     Running   0          5d4h    10.100.85.233   k8s-node01   <none>           <none>
```

- 对于发出的IP包，也会设置相应的路由规则，其中，这里最核心的“下一跳”路由规则，就是由 Calico 的 Felix 进程负责维护的。这些路由规则信息，则是通过 BGP 客户端也就是 BIRD 组件，使用 BGP 协议传输而来的。

### 同一个Node上的Pod之间通信

- 如下图就是在同一个node上的路由转发，![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1636076058000/2dcba836d4a4448087467b4a30688fdc.png)
- 链路如下

```shell
pod1的eth0 --> cli-1网卡 --> 路由-->cli-2网卡-->pod2的eth0
```

### 不同Node上的Pod之间通信

- 链路如下

```shell
pod1的eth0 --> cli-1网卡 -->node01的eth0-->node2的eth0-->cli-2网卡-->pod2的eth0
```

## Flannel模式

> 特点

1. 使集群中的不同Node主机创建的Docker容器都具有全集群唯一的虚拟IP地址。
2. 建立一个覆盖网络（overlay network），通过这个覆盖网络，将数据包原封不动的传递到目标容器。覆盖网络是建立在另一个网络之上并由其基础设施支持的虚拟网络。覆盖网络通过将一个分组封装在另一个分组内来将网络服务与底层基础设施分离。在将封装的数据包转发到端点后，将其解封装。
3. 创建一个新的虚拟网卡flannel0接收docker网桥的数据，通过维护路由表，对接收到的数据进行封包和转发（vxlan）。
4. etcd保证了所有node上flanned所看到的配置是一致的。同时每个node上的flanned监听etcd上的数据变化，实时感知集群中node的变化。

### 同一 Node 中 Pod 间通信

- 同一 Node 中 Pod 的默认路由都是 docker0 的地址，由于它们关联在同一个 docker0（cni0）网桥上，地址网段相同，所有它们之间应当是能直接通信的。

![image](https://b3logfile.com/file/2019/09/t2-0540cce4.png?imageView2/2/interlace/1/format/jpg)

### 不同 Node 中 Pod 间通信

- pod中产生数据，根据pod的路由信息，将数据发送到Cni0
- Cni0 根据节点的路由表，将数据发送到隧道设备flannel.1
- Flannel.1查看数据包的目的ip，从flanneld获得对端隧道设备的必要信息，封装数据包。
- Flannel.1将数据包发送到对端设备。对端节点的网卡接收到数据包，发现数据包为overlay数据包，解开外层封装，并发送内层封装到flannel.1设备。
- Flannel.1设备查看数据包，根据路由表匹配，将数据发送给Cni0设备。
- Cni0匹配路由表，发送数据给网桥上对应的端口。![fanel.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1636076058000/74e10fe15e5d49429ea9aaa06053720c.png)

# 本机重点总结

- 同一 Node 中 Pod 间通信：
  - Flannel模式： 同一 Node 中 Pod 的默认路由都是 docker0 的地址，由于它们关联在同一个 docker0（cni0）网桥上，地址网段相同，所有它们之间应当是能直接通信的。
  - calico模式：同一个node上的路由转发
- 不同 Node 中 Pod 间通信：
  - Flannel模式： 隧道设备封装/解封数据包实现
  - calico模式：纯三层的实现，因此可以避免与二层方案相关的数据包封装的操作，中间没有任何的NAT