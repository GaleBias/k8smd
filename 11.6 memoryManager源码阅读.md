# 本节总结:

- 即使不开启Static 策略也一样需要none的MemoryManager做 容器的内存分配和清理工作
  - 只不过没法做numa的优化而已
- 应用01就是 调用GetTopologyHints
  - 拓扑管理器正在调用GetTopologyHints()每个提示提供程序，包括内存管理器。
  - 内存管理器为 Pod 内的每个容器计算所有可能的 NUMA 节点组合，并将提示返回给拓扑管理器。
  - 拓扑管理器Allocate()为每个提示提供程序调用 ，包括内存管理器。
  - 内存管理器根据拓扑管理器选择的提示分配该状态下的内存。
- 应用02就是 在容器运行时启动容器时 ，会调用internalLifecycle.PreStartContainer ，做容器预启动准备的
  - PreStartContainer就是依次调用 cpuManager、memoryManager和topologyManager的 AddContainer方法

# memoryManager 接口定义

- 位置 F:\go_path\src\github.com\kubernetes\kubernetes\pkg\kubelet\cm\memorymanager\memory_manager.go

```go
// Manager interface provides methods for Kubelet to manage pod memory.
type Manager interface {
	// 在kubelet初始化的时候回调用 start启动memoryManager作为 containerManager的一部分
	Start(activePods ActivePodsFunc, sourcesReady config.SourcesReady, podStatusProvider status.PodStatusProvider, containerRuntime runtimeService, initialContainers containermap.ContainerMap) error

	// AddContainer 将请求的requestmemory保存下来
	AddContainer(p *v1.Pod, c *v1.Container, containerID string)

	// Allocate是在pod 准入控制的时候做内存的预分配的
	Allocate(pod *v1.Pod, container *v1.Container) error

	// RemoveContainer 就是删除容器是调用 容器内存清理的
	RemoveContainer(containerID string) error

	// State 返回memoryManager的可读状态
	State() state.Reader

	// GetTopologyHints 是可以感知numa拓扑的方法
	GetTopologyHints(*v1.Pod, *v1.Container) map[string][]topologymanager.TopologyHint

	// GetPodTopologyHints implements the topologymanager.HintProvider Interface
	// and is consulted to achieve NUMA aware resource alignment among this
	// and other resource controllers.
	GetPodTopologyHints(*v1.Pod) map[string][]topologymanager.TopologyHint

	// GetMemoryNUMANodes provides NUMA nodes that are used to allocate the container memory
	// 给容器分配内存的numa 节点
 	GetMemoryNUMANodes(pod *v1.Pod, container *v1.Container) sets.Int

	// GetAllocatableMemory 返回每一个 NUMA node已分配的内存
	GetAllocatableMemory() []state.Block

	// GetMemory 从NUMA nodes获取容器分配的内存信息
	GetMemory(podUID, containerName string) []state.Block
}
```

# memoryManager 的结构体字段

- 位置  F:\go_path\src\github.com\kubernetes\kubernetes\pkg\kubelet\cm\memorymanager\memory_manager.go

```go
type manager struct {
	sync.Mutex
	policy Policy

	// state  存储了guaranteed pods内存分配的信息，那么在kubelet重启的情况下 可以用来恢复有关的信息
	state state.State

	containerRuntime runtimeService

	// activePods 获取activepod的方法
	activePods ActivePodsFunc

	// podStatusProvider provides a method for obtaining pod statuses
	// and the containerID of their containers
	podStatusProvider status.PodStatusProvider

	// containerMap provides a mapping from (pod, container) -> containerID
	// for all containers a pod
	containerMap containermap.ContainerMap

	// sourcesReady provides the readiness of kubelet configuration sources such as apiserver update readiness.
	// We use it to determine when we can purge inactive pods from checkpointed state.
	sourcesReady config.SourcesReady

	// stateFileDirectory holds the directory where the state file for checkpoints is held.
	stateFileDirectory string

	// allocatableMemory holds the allocatable memory for each NUMA node
	allocatableMemory []state.Block

	// pendingAdmissionPod contain the pod during the admission phase
	pendingAdmissionPod *v1.Pod
}

```

# memoryManager 的初始化

- 初始化的入口在 containerManager初始化的时候
  - 这很好理解，在代码结构和设计上，memoryManager和cpuManager一样都是containerManager的一部分
- 位置 F:\go_path\src\github.com\kubernetes\kubernetes\pkg\kubelet\cm\container_manager_linux.go

```go
	if utilfeature.DefaultFeatureGate.Enabled(kubefeatures.MemoryManager) {
		cm.memoryManager, err = memorymanager.NewManager(
			nodeConfig.ExperimentalMemoryManagerPolicy,
			machineInfo,
			cm.GetNodeAllocatableReservation(),
			nodeConfig.ExperimentalMemoryManagerReservedMemory,
			nodeConfig.KubeletRootDir,
			cm.topologyManager,
		)
		if err != nil {
			klog.ErrorS(err, "Failed to initialize memory manager")
			return nil, err
		}
		cm.topologyManager.AddHintProvider(cm.memoryManager)
	}
```

- 可以看到根据是否启用了memory-manager这一特性决定是否开启memory-manager
- 可以看到根据命令行参数 --memory-manager-policy

## memorymanager.NewManager

- 位置 F:\go_path\src\github.com\kubernetes\kubernetes\pkg\kubelet\cm\memorymanager\memory_manager.go

```go
// NewManager returns new instance of the memory manager
func NewManager(policyName string, machineInfo *cadvisorapi.MachineInfo, nodeAllocatableReservation v1.ResourceList, reservedMemory []kubeletconfig.MemoryReservation, stateFileDirectory string, affinity topologymanager.Store) (Manager, error) {
	var policy Policy

	switch policyType(policyName) {

	case policyTypeNone:
		policy = NewPolicyNone()

	case policyTypeStatic:
		systemReserved, err := getSystemReservedMemory(machineInfo, nodeAllocatableReservation, reservedMemory)
		if err != nil {
			return nil, err
		}

		policy, err = NewPolicyStatic(machineInfo, systemReserved, affinity)
		if err != nil {
			return nil, err
		}

	default:
		return nil, fmt.Errorf("unknown policy: \"%s\"", policyName)
	}

	manager := &manager{
		policy:             policy,
		stateFileDirectory: stateFileDirectory,
	}
	manager.sourcesReady = &sourcesReadyStub{}
	return manager, nil
}
```

- 可以看到首先是对policyTypeNone的判断，继而初始化不同的policy

> 我们重点来看下 policyTypeStatic

- 首先根据nodeInfo等信息 获取node上预留的内存信息，这些预留的不能参与memoryManager 为pod的分配中

```go
		systemReserved, err := getSystemReservedMemory(machineInfo, nodeAllocatableReservation, reservedMemory)
		if err != nil {
			return nil, err
		}
```

- 最后获取的 systemReserve类型就是 systemReservedMemory
  - 这是一个双层的map，第一层的key是numa的nodeid，然后ResourceName都是内存，内存的value就是内存的大小
- 定义如下

```go
type systemReservedMemory map[int]map[v1.ResourceName]uint64
```

### 然后初始化NewPolicyStatic

```go
		policy, err = NewPolicyStatic(machineInfo, systemReserved, affinity)
		if err != nil {
			return nil, err
		}
```

- 首先会判断给系统预留的内存是否大于0

```go
	var totalSystemReserved uint64
	for _, node := range reserved {
		if _, ok := node[v1.ResourceMemory]; !ok {
			continue
		}
		totalSystemReserved += node[v1.ResourceMemory]
	}

	// check if we have some reserved memory for the system
	if totalSystemReserved <= 0 {
		return nil, fmt.Errorf("[memorymanager] you should specify the system reserved memory")
	}

```

# memoryManager 的调用

> 上节课提到过内存管理器主要做两件事：

- 向拓扑管理器提供拓扑提示
- 为容器分配内存并更新状态

## 首先沿着准入控制器追踪

- 可以发现在 topologymanager的Admit方法中，遍历pod的容器调用allocateAlignedResources分配资源
- 位置 D:\go_path\src\github.com\kubernetes\kubernetes\pkg\kubelet\cm\topologymanager\scope_pod.go

```go
func (s *podScope) Admit(pod *v1.Pod) lifecycle.PodAdmitResult {
	// Exception - Policy : none
	if s.policy.Name() == PolicyNone {
		return s.admitPolicyNone(pod)
	}

	bestHint, admit := s.calculateAffinity(pod)
	klog.InfoS("Best TopologyHint", "bestHint", bestHint, "pod", klog.KObj(pod))
	if !admit {
		return admission.GetPodAdmitResult(&TopologyAffinityError{})
	}

	for _, container := range append(pod.Spec.InitContainers, pod.Spec.Containers...) {
		klog.InfoS("Topology Affinity", "bestHint", bestHint, "pod", klog.KObj(pod), "containerName", container.Name)
		s.setTopologyHints(string(pod.UID), container.Name, bestHint)

		err := s.allocateAlignedResources(pod, &container)
		if err != nil {
			return admission.GetPodAdmitResult(err)
		}
	}
	return admission.GetPodAdmitResult(nil)
}
```

- 继续追踪allocateAlignedResources，可以发现遍历资源 provider.Allocate的方法

```go
// It would be better to implement this function in topologymanager instead of scope
// but topologymanager do not track providers anymore
func (s *scope) allocateAlignedResources(pod *v1.Pod, container *v1.Container) error {
	for _, provider := range s.hintProviders {
		err := provider.Allocate(pod, container)
		if err != nil {
			return err
		}
	}
	return nil
}

```

- 对应的memoryManager 的Allocate方法如下，可以看到就是调用对应的policy的Allocate方法

```go
// Allocate is called to pre-allocate memory resources during Pod admission.
func (m *manager) Allocate(pod *v1.Pod, container *v1.Container) error {
	// The pod is during the admission phase. We need to save the pod to avoid it
	// being cleaned before the admission ended
	m.setPodPendingAdmission(pod)

	// Garbage collect any stranded resources before allocation
	m.removeStaleState()

	m.Lock()
	defer m.Unlock()

	// Call down into the policy to assign this container memory if required.
	if err := m.policy.Allocate(m.state, pod, container); err != nil {
		klog.ErrorS(err, "Allocate error")
		return err
	}
	return nil
}
```

### staticPolicy 的Allocate方法

- 首先判断只能为guaranteed pods 服务

```go
	// allocate the memory only for guaranteed pods
	if v1qos.GetPodQOS(pod) != v1.PodQOSGuaranteed {
		return nil
	}
```

- 根据poduid和container.Name在缓存中查找MemoryBlocks，如果有说明需要更新本地内存分配缓存

```go
	if blocks := s.GetMemoryBlocks(podUID, container.Name); blocks != nil {
		p.updatePodReusableMemory(pod, container, blocks)

		klog.InfoS("Container already present in state, skipping", "pod", klog.KObj(pod), "containerName", container.Name)
		return nil
	}

```

- 调用拓扑管理器分配 最佳亲和性

```go
	// Call Topology Manager to get the aligned affinity across all hint providers.
	hint := p.affinity.GetAffinity(podUID, container.Name)
	klog.InfoS("Got topology affinity", "pod", klog.KObj(pod), "podUID", pod.UID, "containerName", container.Name, "hint", hint)

```

- 获取容器请求的内存信息

```go
	requestedResources, err := getRequestedResources(container)
	if err != nil {
		return err
	}
```

- 从本地内存缓存中获取node的numa状态

```go
machineState := s.GetMachineState()
```

- 对应的缓存结构体也是一个memoryState结构

```go
type stateMemory struct {
	sync.RWMutex
	assignments  ContainerMemoryAssignments // 对应的是分配给容器的内存信息
	machineState NUMANodeMap // 对应的是节点的numa map
}
```

- 如果numa节点亲和性为空则使用默认的亲和性

```go
	if hint.NUMANodeAffinity == nil {
		defaultHint, err := p.getDefaultHint(machineState, pod, requestedResources)
		if err != nil {
			return err
		}

		if !defaultHint.Preferred && bestHint.Preferred {
			return fmt.Errorf("[memorymanager] failed to find the default preferred hint")
		}
		bestHint = defaultHint
	}

```

- 拓扑管理器返回不完全满足容器请求，我们应该扩展到满足请求

```go
	// topology manager returns the hint that does not satisfy completely the container request
	// we should extend this hint to the one who will satisfy the request and include the current hint
	if !isAffinitySatisfyRequest(machineState, bestHint.NUMANodeAffinity, requestedResources) {
		extendedHint, err := p.extendTopologyManagerHint(machineState, pod, requestedResources, bestHint.NUMANodeAffinity)
		if err != nil {
			return err
		}

		if !extendedHint.Preferred && bestHint.Preferred {
			return fmt.Errorf("[memorymanager] failed to find the extended preferred hint")
		}
		bestHint = extendedHint
	}
```

- 更新容器的内存block和节点的内存状态

```go
	var containerBlocks []state.Block
	maskBits := bestHint.NUMANodeAffinity.GetBits()
	for resourceName, requestedSize := range requestedResources {
		// update memory blocks
		containerBlocks = append(containerBlocks, state.Block{
			NUMAAffinity: maskBits,
			Size:         requestedSize,
			Type:         resourceName,
		})

		podReusableMemory := p.getPodReusableMemory(pod, bestHint.NUMANodeAffinity, resourceName)
		if podReusableMemory >= requestedSize {
			requestedSize = 0
		} else {
			requestedSize -= podReusableMemory
		}

		// Update nodes memory state
		p.updateMachineState(machineState, maskBits, resourceName, requestedSize)
	}
```

- 更新可复用的内存和设置容器的内存block信息等

```go
	p.updatePodReusableMemory(pod, container, containerBlocks)

	s.SetMachineState(machineState)
	s.SetMemoryBlocks(podUID, container.Name, containerBlocks)

```

## 沿着启动容器的Addcontainer追查

- 在容器运行时启动容器时 ，会调用internalLifecycle.PreStartContainer ，做容器预启动准备的
- 位置D:\go_path\src\github.com\kubernetes\kubernetes\pkg\kubelet\kuberuntime\kuberuntime_container.go

```go
func (m *kubeGenericRuntimeManager) startContainer(podSandboxID string, podSandboxConfig *runtimeapi.PodSandboxConfig, spec *startSpec, pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, podIP string, podIPs []string) (string, error) {

err = m.internalLifecycle.PreStartContainer(pod, container, containerID)
}
```

- 在对应的实现中可以看到:PreStartContainer就是依次调用 cpuManager、memoryManager和topologyManager的 AddContainer方法

```go
func (i *internalContainerLifecycleImpl) PreStartContainer(pod *v1.Pod, container *v1.Container, containerID string) error {
	if i.cpuManager != nil {
		i.cpuManager.AddContainer(pod, container, containerID)
	}

	if i.memoryManager != nil {
		i.memoryManager.AddContainer(pod, container, containerID)
	}

	if utilfeature.DefaultFeatureGate.Enabled(kubefeatures.TopologyManager) {
		i.topologyManager.AddContainer(pod, container, containerID)
	}
	return nil
}

```

### memoryManager.AddContainer

- 更新pod map

```go
	m.containerMap.Add(string(pod.UID), container.Name, containerID)

```

- ContainerMap结构如下

```go
// ContainerMap maps (containerID)->(*v1.Pod, *v1.Container)
type ContainerMap map[string]struct {
	podUID        string
	containerName string
}

```

- 删除init容器的的内存信息引用
  - 因为我们知道每个init容器总是在下一个容器启动时之前运行到完成
  - 所以我们可以安全地删除以前已启动初始化容器的引用。这将从这些init容器中释放内存

```go
	for _, initContainer := range pod.Spec.InitContainers {
		if initContainer.Name == container.Name {
			break
		}

		m.policyRemoveContainerByRef(string(pod.UID), initContainer.Name)
	}
```

- policyRemoveContainerByRef 就是调用policyRemoveContainer并从本地map中移除相关引用

```go
func (m *manager) policyRemoveContainerByRef(podUID string, containerName string) {
	m.policy.RemoveContainer(m.state, podUID, containerName)
	m.containerMap.RemoveByContainerRef(podUID, containerName)
}
```

#### RemoveContainer分析 其实就是在更新内存分配的缓存信息

- 首先获取容器申请的内存block信息

```go
	blocks := s.GetMemoryBlocks(podUID, containerName)
	if blocks == nil {
		return
	}

	klog.InfoS("RemoveContainer", "podUID", podUID, "containerName", containerName)
	s.Delete(podUID, containerName)
```

- 对应的内存block信息结构如下

```go
// Block is a data structure used to represent a certain amount of memory
type Block struct {
	// NUMAAffinity contains the string that represents NUMA affinity bitmask
	NUMAAffinity []int           `json:"numaAffinity"` // 代表numa nodeid
	Type         v1.ResourceName `json:"type"`     // 类型
	Size         uint64          `json:"size"`    // 大小
}

```

- 先获取node machineState，遍历block ，遍历numa node id ，--NumberOfAssignments

```go
	// Mutate machine memory state to update free and reserved memory
	machineState := s.GetMachineState()
	for _, b := range blocks {
		releasedSize := b.Size
		for _, nodeID := range b.NUMAAffinity {
			machineState[nodeID].NumberOfAssignments--

```

- 如果预留小于要释放的大小就，使用预留大小释放

```go
			// the reserved memory smaller than the amount of the memory that should be released
			// release as much as possible and move to the next node
			if nodeResourceMemoryState.Reserved < releasedSize {
				releasedSize -= nodeResourceMemoryState.Reserved
				nodeResourceMemoryState.Free += nodeResourceMemoryState.Reserved
				nodeResourceMemoryState.Reserved = 0
				continue
			}
```

- 正常释放内存

```go
			// the reserved memory big enough to satisfy the released memory
			nodeResourceMemoryState.Free += releasedSize
			nodeResourceMemoryState.Reserved -= releasedSize
			releasedSize = 0
```

- 更新机器内存状态

```go
s.SetMachineState(machineState)
```