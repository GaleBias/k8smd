# 本节重点总结
> metrics-server数据采集流程
- 通过kubelet内置的cadvisor /metrics/resource接口 获取node和pod 的cpu/内存指标，保存到本地存储
    - prev 和last两个点的数据
    - 之所以两个点是因为cpu需要 算rate 就是用 (last-prev)/ts_delta
    - 内存数据直接用的last的value
- 通过apiserver的聚合api插件注册metrics.k8s.io 这个group的 node和pod资源供其他组件调用



# metrics-server 项目给出的主要应用场景
- [use case](https://github.com/kubernetes-sigs/metrics-server#use-cases)
```shell script
You can use Metrics Server for:

CPU/Memory based horizontal autoscaling (learn more about Horizontal Autoscaling)
Automatically adjusting/suggesting resources needed by containers (learn more about Vertical Autoscaling)
Don't use Metrics Server when you need:

Non-Kubernetes clusters
An accurate source of resource usage metrics
Horizontal autoscaling based on other resources than CPU/Memory
For unsupported use cases, check out full monitoring solutions like Prometheus.
```
- 从上面已经能清楚的看到，metrics-server的两个主要用途
    - 01 基于CPU/内存的水平自动缩放 hpa
    - 02 基于CPU/内存的垂直缩放 vpa
    
- 同时还给出了一些不建议使用metrics-server的场景
    - 基于非CPU/内存的hpa
    - 非k8s集群
    - 需要使用准确的指标，或者专业的监控需求(建议使用prometheus)
    

# 源码解读
- 下载源码
```shell script
git clone git@github.com:kubernetes-sigs/metrics-server.git
```
## 入口位置
- D:\go_path\src\github.com\kubernetes-sigs\metrics-server\cmd\metrics-server\metrics-server.go
```go
package main

import (
	"flag"
	"os"
	"runtime"

	genericapiserver "k8s.io/apiserver/pkg/server"
	"k8s.io/component-base/logs"

	"sigs.k8s.io/metrics-server/cmd/metrics-server/app"
)

func main() {
	logs.InitLogs()
	defer logs.FlushLogs()

	if len(os.Getenv("GOMAXPROCS")) == 0 {
		runtime.GOMAXPROCS(runtime.NumCPU())
	}

	cmd := app.NewMetricsServerCommand(genericapiserver.SetupSignalHandler())
	cmd.Flags().AddGoFlagSet(flag.CommandLine)
	if err := cmd.Execute(); err != nil {
		panic(err)
	}
}

```
- 可以看到还是经典的cobra cmd入口，那么对应的执行应该在cmd 的run 或者rune中
- 位置 D:\go_path\src\github.com\kubernetes-sigs\metrics-server\cmd\metrics-server\app\start.go
- 经过追踪可以发现主要逻辑应该在这个runCommand中
```go
// NewMetricsServerCommand provides a CLI handler for the metrics server entrypoint
func NewMetricsServerCommand(stopCh <-chan struct{}) *cobra.Command {
	opts := options.NewOptions()

	cmd := &cobra.Command{
		Short: "Launch metrics-server",
		Long:  "Launch metrics-server",
		RunE: func(c *cobra.Command, args []string) error {
			if err := runCommand(opts, stopCh); err != nil {
				return err
			}
			return nil
		},
	}

func runCommand(o *options.Options, stopCh <-chan struct{}) error {
	if o.ShowVersion {
		fmt.Println(version.Get().GitVersion)
		os.Exit(0)
	}

	errors := o.Validate()
	if len(errors) > 0 {
		return errors[0]
	}

	config, err := o.ServerConfig()

	if err != nil {
		return err
	}

	s, err := config.Complete()

	if err != nil {
		return err
	}

	return s.RunUntil(stopCh)
}

```
### config.Complete 构造metrics-server对象
- 位置 D:\go_path\src\github.com\kubernetes-sigs\metrics-server\pkg\server\config.go
- 首先是利用podInformerFactory构造podInformer监听pod资源
```go
func (c Config) Complete() (*server, error) {
	podInformerFactory, err := runningPodMetadataInformer(c.Rest)
	if err != nil {
		return nil, err
	}
	podInformer := podInformerFactory.ForResource(corev1.SchemeGroupVersion.WithResource("pods"))
	informer, err := informerFactory(c.Rest)
	if err != nil {
		return nil, err
	}
```
- 从kubeconfig初始化kubeclient，初始化 nodes代表nodeInformer
```go
	kubeletClient, err := resource.NewForConfig(c.Kubelet)
	if err != nil {
		return nil, fmt.Errorf("unable to construct a client to connect to the kubelets: %v", err)
	}
	nodes := informer.Core().V1().Nodes()
```
- 初始化一个scrape采集器，后面用来采集kubelet上内置的cadvisor pod node指标
```go
	scrape := scraper.NewScraper(nodes.Lister(), kubeletClient, c.ScrapeTimeout)

func NewScraper(nodeLister v1listers.NodeLister, client client.KubeletMetricsGetter, scrapeTimeout time.Duration) *scraper {
	return &scraper{
		nodeLister:    nodeLister,
		kubeletClient: client,
		scrapeTimeout: scrapeTimeout,
	}
}

```
- 初始化metrics-server自身的指标的handler
```go
	metricsHandler, err := c.metricsHandler()
	if err != nil {
		return nil, err
	}
```
- 初始化一个genericServer 处理http请求，并且把上面的metricsHandler注册进去
```go
	genericServer, err := c.Apiserver.Complete(informer).New("metrics-server", genericapiserver.NewEmptyDelegate())
	if err != nil {
		return nil, err
	}
	genericServer.Handler.NonGoRestfulMux.HandleFunc("/metrics", metricsHandler)

```
- 初始化本地内存中存储，用来保存node和pod的指标，观察这个storage发现内部包含一个podStorage和nodeStorage
- 同时这个storage有对应的获取node和pod指标的方法
```go
	store := storage.NewStorage(c.MetricResolution)
// nodeStorage is a thread save nodeStorage for node and pod metrics.
type storage struct {
	mu    sync.RWMutex
	pods  podStorage
	nodes nodeStorage
}

func (s *storage) GetNodeMetrics(nodes ...*corev1.Node) ([]metrics.NodeMetrics, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.nodes.GetMetrics(nodes...)
}

func (s *storage) GetPodMetrics(pods ...*metav1.PartialObjectMetadata) ([]metrics.PodMetrics, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.pods.GetMetrics(pods...)
}

```
- 追踪一下podStorage发现内部的结构为，一个last和prev分别代表当前和前面一个点，内部就是以ns为key，PodMetricsPoint为value的map
- 同时观察到这个PodMetricsPoint也是一个map，key是容器的名字，value是一个MetricsPoint其中有cpu和内存的指标
```go
type podStorage struct {
	// last stores pod metric points from last scrape
	last map[apitypes.NamespacedName]PodMetricsPoint
	// prev stores pod metric points from scrape preceding the last one.
	// Points timestamp should proceed the corresponding points from last and have same start time (no restart between them).
	prev map[apitypes.NamespacedName]PodMetricsPoint
	// scrape period of metrics server
	metricResolution time.Duration
}
// PodMetricsPoint contains the metrics for some pod's containers.
type PodMetricsPoint struct {
	Containers map[string]MetricsPoint
}

// MetricsPoint represents the a set of specific metrics at some point in time.
type MetricsPoint struct {
	// StartTime is the start time of container/node. Cumulative CPU usage at that moment should be equal zero.
	StartTime time.Time
	// Timestamp is the time when metric point was measured. If CPU and Memory was measured at different time it should equal CPU time to allow accurate CPU calculation.
	Timestamp time.Time
	// CumulativeCpuUsed is the cumulative cpu used at Timestamp from the StartTime of container/node. Unit: nano core * seconds.
	CumulativeCpuUsed uint64
	// MemoryUsage is the working set size. Unit: bytes.
	MemoryUsage uint64
}

```
### 回到config.Complete中 下面就是用store 和informer对象 构建metrics.k8s.io API
```go
	if err := api.Install(store, podInformer.Lister(), nodes.Lister(), genericServer); err != nil {
		return nil, err
	}
// Install builds the metrics for the metrics.k8s.io API, and then installs it into the given API metrics-server.
func Install(m MetricsGetter, podMetadataLister cache.GenericLister, nodeLister corev1.NodeLister, server *genericapiserver.GenericAPIServer) error {
	node := newNodeMetrics(metrics.Resource("nodemetrics"), m, nodeLister)
	pod := newPodMetrics(metrics.Resource("podmetrics"), m, podMetadataLister)
	info := Build(pod, node)
	return server.InstallAPIGroup(&info)
}
```
- 从上面可以看出构造了一个 node和pod rest对象，那么追查这个newPodMetrics，可以看到返回的是一个newPodMetrics对象
- 同时这个newPodMetrics对象实现了Kind、List、Get等方法，这些方法都是apiserver中rest api所要求的
```go
func newPodMetrics(groupResource schema.GroupResource, metrics PodMetricsGetter, podLister cache.GenericLister) *podMetrics {
	return &podMetrics{
		groupResource: groupResource,
		metrics:       metrics,
		podLister:     podLister,
	}
}

// Kind implements rest.KindProvider interface
func (m *podMetrics) Kind() string {
	return "PodMetrics"
}

// List implements rest.Lister interface
func (m *podMetrics) List(ctx context.Context, options *metainternalversion.ListOptions) (runtime.Object, error) {
	pods, err := m.pods(ctx, options)
	if err != nil {
		return &metrics.PodMetricsList{}, err
	}
	ms, err := m.getMetrics(pods...)
	if err != nil {
		namespace := genericapirequest.NamespaceValue(ctx)
		klog.ErrorS(err, "Failed reading pods metrics", "namespace", klog.KRef("", namespace))
		return &metrics.PodMetricsList{}, fmt.Errorf("failed reading pods metrics: %w", err)
	}
	return &metrics.PodMetricsList{Items: ms}, nil
}
// Get implements rest.Getter interface
func (m *podMetrics) Get(ctx context.Context, name string, opts *metav1.GetOptions) (runtime.Object, error) {
	namespace := genericapirequest.NamespaceValue(ctx)

	pod, err := m.podLister.ByNamespace(namespace).Get(name)
	if err != nil {
		if errors.IsNotFound(err) {
			// return not-found errors directly
			return &metrics.PodMetrics{}, err
		}
		klog.ErrorS(err, "Failed getting pod", "pod", klog.KRef(namespace, name))
		return &metrics.PodMetrics{}, fmt.Errorf("failed getting pod: %w", err)
	}
	if pod == nil {
		return &metrics.PodMetrics{}, errors.NewNotFound(corev1.Resource("pods"), fmt.Sprintf("%s/%s", namespace, name))
	}

	ms, err := m.getMetrics(pod)
	if err != nil {
		klog.ErrorS(err, "Failed reading pod metrics", "pod", klog.KRef(namespace, name))
		return nil, fmt.Errorf("failed pod metrics: %w", err)
	}
	if len(ms) == 0 {
		return nil, errors.NewNotFound(m.groupResource, fmt.Sprintf("%s/%s", namespace, name))
	}
	return &ms[0], nil
}
```
- 所以上面这些方法就是后面请求 metrics.k8s.io 这个group的资源执行的restful方法\
- 比如我们通过metrics-server获取 kube-system 下的kube-controller-manager 这个pod的资源，那么对应执行的应该是上面的Get方法
```shell script
[root@k8s-master01 ~]# kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/kube-controller-manager-k8s-master01 |python -m json.tool                                   
{
    "apiVersion": "metrics.k8s.io/v1beta1",
    "containers": [
        {
            "name": "kube-controller-manager",
            "usage": {
                "cpu": "34301354n",
                "memory": "81656Ki"
            }
        }
    ],
    "kind": "PodMetrics",
    "metadata": {
        "creationTimestamp": "2021-11-08T03:29:30Z",
        "labels": {
            "component": "kube-controller-manager",
            "tier": "control-plane"
        },
        "name": "kube-controller-manager-k8s-master01",
        "namespace": "kube-system"
    },
    "timestamp": "2021-11-08T03:29:22Z",
    "window": "15s"
}
```
- 那么对于newNodeMetrics也是同理的
- 同时可以看到将pod和node对应传入Build函数构造了一个genericapiserver.APIGroupInfo对象，意思是这个api group为metrics.k8s.io ，版本为v1beta1
```go
// Build constructs APIGroupInfo the metrics.k8s.io API group using the given getters.
func Build(pod, node rest.Storage) genericapiserver.APIGroupInfo {
	apiGroupInfo := genericapiserver.NewDefaultAPIGroupInfo(metrics.GroupName, Scheme, metav1.ParameterCodec, Codecs)
	metricsServerResources := map[string]rest.Storage{
		"nodes": node,
		"pods":  pod,
	}
	apiGroupInfo.VersionedResourcesStorageMap[v1beta1.SchemeGroupVersion.Version] = metricsServerResources

	return apiGroupInfo
}
```
- 同时提供了名为 nodes和pods的资源，这个我们通过curl 可以获取到
```shell script
[root@k8s-master01 ~]# kubectl get --raw /apis/metrics.k8s.io/v1beta1  |python -m json.tool
{
    "apiVersion": "v1",
    "groupVersion": "metrics.k8s.io/v1beta1",
    "kind": "APIResourceList",
    "resources": [
        {
            "kind": "NodeMetrics",
            "name": "nodes",
            "namespaced": false,
            "singularName": "",
            "verbs": [
                "get",
                "list"
            ]
        },
        {
            "kind": "PodMetrics",
            "name": "pods",
            "namespaced": true,
            "singularName": "",
            "verbs": [
                "get",
                "list"
            ]
        }
    ]
}
```
- 最后通过InstallAPIGroup注册
```go
erver.InstallAPIGroup(&info)
```

### config.Complete 中的收尾工作就是初始化server实例，注册探活实例
```go
	s := NewServer(
		nodes.Informer(),
		podInformer.Informer(),
		genericServer,
		store,
		scrape,
		c.MetricResolution,
	)
	err = s.RegisterProbes(podInformerFactory)
	if err != nil {
		return nil, err
	}
	return s, nil
```

## run运行逻辑
- 位置 D:\go_path\src\github.com\kubernetes-sigs\metrics-server\pkg\server\server.go
- run调用了RunUntil，整体的逻辑很清晰
    - 启动node和pod informer
    - 等待informer的数据至少被list到本地
    - runScrape启动定时采集kubelet cadvisor的数据
    - GenericAPIServer运行apiserver供外部调用 获取pod和node的 cpu和内存数据 
- RunUntil整体代码如下
```go
// RunUntil starts background scraping goroutine and runs apiserver serving metrics.
func (s *server) RunUntil(stopCh <-chan struct{}) error {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// Start informers 启动 
	go s.nodes.Run(stopCh)
	go s.pods.Run(stopCh)

	// Ensure cache is up to date
	ok := cache.WaitForCacheSync(stopCh, s.nodes.HasSynced)
	if !ok {
		return nil
	}
	ok = cache.WaitForCacheSync(stopCh, s.pods.HasSynced)
	if !ok {
		return nil
	}

	// Start serving API and scrape loop
	go s.runScrape(ctx)
	return s.GenericAPIServer.PrepareRun().Run(stopCh)
}
```
- 所以经过分析，我们的主要流程就在这个runScrape里面

### runScrape 采集分析
- runScrape中就是启动一个ticker，定时执行 tick方法
- ticker的周期来自于metric-resolution，默认是10秒
```go
func (s *server) runScrape(ctx context.Context) {
	ticker := time.NewTicker(s.resolution)
	defer ticker.Stop()
	s.tick(ctx, time.Now())

	for {
		select {
		case startTime := <-ticker.C:
			s.tick(ctx, startTime)
		case <-ctx.Done():
			return
		}
	}
}
```
- 那么追查一下ticke方法，逻辑也很简单就是执行一下s.scraper.Scrape获取数据
- 然后将数据存储到storage中
```go
func (s *server) tick(ctx context.Context, startTime time.Time) {
	s.tickStatusMux.Lock()
	s.tickLastStart = startTime
	s.tickStatusMux.Unlock()

	ctx, cancelTimeout := context.WithTimeout(ctx, s.resolution)
	defer cancelTimeout()

	klog.V(6).InfoS("Scraping metrics")
	data := s.scraper.Scrape(ctx)

	klog.V(6).InfoS("Storing metrics")
	s.storage.Store(data)

	collectTime := time.Since(startTime)
	tickDuration.Observe(float64(collectTime) / float64(time.Second))
	klog.V(6).InfoS("Scraping cycle complete")
}
```
#### 01 s.scraper.Scrape采集指标分析
- 位置 D:\go_path\src\github.com\kubernetes-sigs\metrics-server\pkg\scraper\scraper.go
- 首先通过nodeLister获取所有的node，这很好理解，既然是请求node的 数据接口，那么总的知道有哪些node吧
- 然后构造一个结果的chan responseChannel 
```go
func (c *scraper) Scrape(baseCtx context.Context) *storage.MetricsBatch {
	nodes, err := c.nodeLister.List(labels.Everything())
	if err != nil {
		// report the error and continue on in case of partial results
		klog.ErrorS(err, "Failed to list nodes")
	}
	klog.V(1).InfoS("Scraping metrics from nodes", "nodeCount", len(nodes))

	responseChannel := make(chan *storage.MetricsBatch, len(nodes))
	defer close(responseChannel)

```
- 根据node数量构造一个延迟启动时间，最长为4秒
```go
	// TODO(serathius): re-evaluate this code -- do we really need to stagger fetches like this?
	delayMs := delayPerSourceMs * len(nodes)
	if delayMs > maxDelayMs {
		delayMs = maxDelayMs
	}

```
- 然后遍历所有node，并发的启动采集任务，动作是collectNode，并将结果写入responseChannel中
- 同时为了避免网络堵塞，先sleep 一段时间后再启动，同时给这个采集任务设置一个超时时间
```go
	for _, node := range nodes {
		go func(node *corev1.Node) {
			// Prevents network congestion.
			sleepDuration := time.Duration(rand.Intn(delayMs)) * time.Millisecond
			time.Sleep(sleepDuration)
			// make the timeout a bit shorter to account for staggering, so we still preserve
			// the overall timeout
			ctx, cancelTimeout := context.WithTimeout(baseCtx, c.scrapeTimeout-sleepDuration)
			defer cancelTimeout()
			klog.V(2).InfoS("Scraping node", "node", klog.KObj(node))
			m, err := c.collectNode(ctx, node)
			if err != nil {
				klog.ErrorS(err, "Failed to scrape node", "node", klog.KObj(node))
			}
			responseChannel <- m
		}(node)
	}

```
##### 那么collectNode中就是调用kubeletClient.GetMetrics获取指标
```go
func (c *scraper) collectNode(ctx context.Context, node *corev1.Node) (*storage.MetricsBatch, error) {
	startTime := myClock.Now()
	defer func() {
		requestDuration.WithLabelValues(node.Name).Observe(float64(myClock.Since(startTime)) / float64(time.Second))
		lastRequestTime.WithLabelValues(node.Name).Set(float64(myClock.Now().Unix()))
	}()
	ms, err := c.kubeletClient.GetMetrics(ctx, node)

	if err != nil {
		requestTotal.WithLabelValues("false").Inc()
		return nil, err
	}
	requestTotal.WithLabelValues("true").Inc()
	return ms, nil
}
```
- 追踪这个kubeletClient的GetMetrics可以发现就是访问的 node节点的/metrics/resource接口获取的数据
```go
// GetMetrics implements client.KubeletMetricsGetter
func (kc *kubeletClient) GetMetrics(ctx context.Context, node *corev1.Node) (*storage.MetricsBatch, error) {
	port := kc.defaultPort
	nodeStatusPort := int(node.Status.DaemonEndpoints.KubeletEndpoint.Port)
	if kc.useNodeStatusPort && nodeStatusPort != 0 {
		port = nodeStatusPort
	}
	addr, err := kc.addrResolver.NodeAddress(node)
	if err != nil {
		return nil, err
	}
	url := url.URL{
		Scheme: kc.scheme,
		Host:   net.JoinHostPort(addr, strconv.Itoa(port)),
		Path:   "/metrics/resource",
	}
	return kc.getMetrics(ctx, url.String(), node.Name)
}


```
- 在getMetric中会发起GET请求，然后调用decodeBatch将结果解析成storage.MetricsBatch对象
```go
func (kc *kubeletClient) getMetrics(ctx context.Context, url, nodeName string) (*storage.MetricsBatch, error) {
	req, err := http.NewRequest("GET", url, nil)
	if err != nil {
		return nil, err
	}
	requestTime := time.Now()
	response, err := kc.client.Do(req.WithContext(ctx))
	if err != nil {
		return nil, err
	}
	defer response.Body.Close()
	if response.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("request failed, status: %q", response.Status)
	}
	b := kc.buffers.Get().([]byte)
	buf := bytes.NewBuffer(b)
	buf.Reset()
	_, err = io.Copy(buf, response.Body)
	if err != nil {
		kc.buffers.Put(b)
		return nil, fmt.Errorf("failed to read response body - %v", err)
	}
	b = buf.Bytes()
	ms := decodeBatch(b, requestTime, nodeName)
	kc.buffers.Put(b)
	return ms, nil
}

```
- kubelet 上的/metrics/resource 数据为prometheus sdk暴露的指标数据，包含4大类
    - container_cpu_usage_seconds_total 代表容器的cpu使用
    - container_memory_working_set_bytes 代表容器的内存使用
    - node_cpu_usage_seconds_total 代表node的cpu使用
    - node_memory_working_set_bytes 代表node的内存使用
- kubelet 上的/metrics/resource 数据样例
```shell script
[root@k8s-master01 ~]# curl -k -s  https://localhost:10250/metrics/resource --header "Authorization: Bearer $TOKEN"       
# HELP container_cpu_usage_seconds_total [ALPHA] Cumulative cpu time consumed by the container in core-seconds
# TYPE container_cpu_usage_seconds_total counter
container_cpu_usage_seconds_total{container="calico-kube-controllers",namespace="calico-system",pod="calico-kube-controllers-7578849648-4zshs"} 5544.31744012 1636344118111
container_cpu_usage_seconds_total{container="calico-node",namespace="calico-system",pod="calico-node-rgbcp"} 89094.728538624 1636344118110
container_cpu_usage_seconds_total{container="calico-typha",namespace="calico-system",pod="calico-typha-846d7f69df-s6bmt"} 5815.287655109 1636344118106
container_cpu_usage_seconds_total{container="coredns",namespace="kube-system",pod="coredns-7d75679df-9vzm2"} 10812.745420053 1636344118107
container_cpu_usage_seconds_total{container="coredns",namespace="kube-system",pod="coredns-7d75679df-wf8wl"} 10912.673693517 1636344118112
container_cpu_usage_seconds_total{container="etcd",namespace="kube-system",pod="etcd-k8s-master01"} 18771.110581454 1636344118113
container_cpu_usage_seconds_total{container="kube-apiserver",namespace="kube-system",pod="kube-apiserver-k8s-master01"} 255530.078627605 1636344118116
container_cpu_usage_seconds_total{container="kube-controller-manager",namespace="kube-system",pod="kube-controller-manager-k8s-master01"} 9530.408635491 1636344118117
container_cpu_usage_seconds_total{container="kube-proxy",namespace="kube-system",pod="kube-proxy-kq4m2"} 1343.866419894 1636344118105
container_cpu_usage_seconds_total{container="kube-rbac-proxy",namespace="monitoring",pod="node-exporter-nv2gf"} 1235.312312281 1636344118115
container_cpu_usage_seconds_total{container="kube-scheduler",namespace="kube-system",pod="kube-scheduler-k8s-master01"} 1927.923362966 1636344118108
container_cpu_usage_seconds_total{container="node-exporter",namespace="monitoring",pod="node-exporter-nv2gf"} 24642.079190415 1636344118118
container_cpu_usage_seconds_total{container="tigera-operator",namespace="tigera-operator",pod="tigera-operator-cf6b69777-nrfng"} 1450.406335595 1636344118114
# HELP container_memory_working_set_bytes [ALPHA] Current working set of the container in bytes
# TYPE container_memory_working_set_bytes gauge
container_memory_working_set_bytes{container="calico-kube-controllers",namespace="calico-system",pod="calico-kube-controllers-7578849648-4zshs"} 4.2999808e+07 1636344118111
container_memory_working_set_bytes{container="calico-node",namespace="calico-system",pod="calico-node-rgbcp"} 1.30260992e+08 1636344118110
container_memory_working_set_bytes{container="calico-typha",namespace="calico-system",pod="calico-typha-846d7f69df-s6bmt"} 2.7947008e+07 1636344118106
container_memory_working_set_bytes{container="coredns",namespace="kube-system",pod="coredns-7d75679df-9vzm2"} 2.3302144e+07 1636344118107
container_memory_working_set_bytes{container="coredns",namespace="kube-system",pod="coredns-7d75679df-wf8wl"} 2.6918912e+07 1636344118112
container_memory_working_set_bytes{container="etcd",namespace="kube-system",pod="etcd-k8s-master01"} 3.73174272e+08 1636344118113
container_memory_working_set_bytes{container="kube-apiserver",namespace="kube-system",pod="kube-apiserver-k8s-master01"} 6.74152448e+08 1636344118116
container_memory_working_set_bytes{container="kube-controller-manager",namespace="kube-system",pod="kube-controller-manager-k8s-master01"} 8.3734528e+07 1636344118117
container_memory_working_set_bytes{container="kube-proxy",namespace="kube-system",pod="kube-proxy-kq4m2"} 2.3719936e+07 1636344118105
container_memory_working_set_bytes{container="kube-rbac-proxy",namespace="monitoring",pod="node-exporter-nv2gf"} 1.6920576e+07 1636344118115
container_memory_working_set_bytes{container="kube-scheduler",namespace="kube-system",pod="kube-scheduler-k8s-master01"} 2.6222592e+07 1636344118108
container_memory_working_set_bytes{container="node-exporter",namespace="monitoring",pod="node-exporter-nv2gf"} 1.9329024e+07 1636344118118
container_memory_working_set_bytes{container="tigera-operator",namespace="tigera-operator",pod="tigera-operator-cf6b69777-nrfng"} 3.1494144e+07 1636344118114
# HELP node_cpu_usage_seconds_total [ALPHA] Cumulative cpu time consumed by the node in core-seconds
# TYPE node_cpu_usage_seconds_total counter
node_cpu_usage_seconds_total 1.004559880575211e+06 1636344112460
# HELP node_memory_working_set_bytes [ALPHA] Current working set of the node in bytes
# TYPE node_memory_working_set_bytes gauge
node_memory_working_set_bytes 7.676104704e+09 1636344112460
# HELP pod_cpu_usage_seconds_total [ALPHA] Cumulative cpu time consumed by the pod in core-seconds
# TYPE pod_cpu_usage_seconds_total counter
pod_cpu_usage_seconds_total{namespace="calico-system",pod="calico-kube-controllers-7578849648-4zshs"} 5544.357926646 1636344107277
pod_cpu_usage_seconds_total{namespace="calico-system",pod="calico-node-rgbcp"} 89098.894754883 1636344116636
pod_cpu_usage_seconds_total{namespace="calico-system",pod="calico-typha-846d7f69df-s6bmt"} 5815.465449939 1636344115996
pod_cpu_usage_seconds_total{namespace="kube-system",pod="coredns-7d75679df-9vzm2"} 10812.779740069 1636344109042
pod_cpu_usage_seconds_total{namespace="kube-system",pod="coredns-7d75679df-wf8wl"} 10912.706754146 1636344114531
pod_cpu_usage_seconds_total{namespace="kube-system",pod="etcd-k8s-master01"} 90970.543557906 1636344105030
pod_cpu_usage_seconds_total{namespace="kube-system",pod="kube-apiserver-k8s-master01"} 255544.800310479 1636344108509
pod_cpu_usage_seconds_total{namespace="kube-system",pod="kube-controller-manager-k8s-master01"} 56999.301296709 1636344112554
pod_cpu_usage_seconds_total{namespace="kube-system",pod="kube-proxy-kq4m2"} 1343.901987299 1636344111004
pod_cpu_usage_seconds_total{namespace="kube-system",pod="kube-scheduler-k8s-master01"} 12138.620725265 1636344114247
pod_cpu_usage_seconds_total{namespace="monitoring",pod="node-exporter-nv2gf"} 25877.344775527 1636344111586
pod_cpu_usage_seconds_total{namespace="tigera-operator",pod="tigera-operator-cf6b69777-nrfng"} 9557.175811859 1636344114519
# HELP pod_memory_working_set_bytes [ALPHA] Current working set of the pod in bytes
# TYPE pod_memory_working_set_bytes gauge
pod_memory_working_set_bytes{namespace="calico-system",pod="calico-kube-controllers-7578849648-4zshs"} 4.3040768e+07 1636344107277
pod_memory_working_set_bytes{namespace="calico-system",pod="calico-node-rgbcp"} 1.63966976e+08 1636344116636
pod_memory_working_set_bytes{namespace="calico-system",pod="calico-typha-846d7f69df-s6bmt"} 2.7987968e+07 1636344115996
pod_memory_working_set_bytes{namespace="kube-system",pod="coredns-7d75679df-9vzm2"} 2.2679552e+07 1636344109042
pod_memory_working_set_bytes{namespace="kube-system",pod="coredns-7d75679df-wf8wl"} 2.6955776e+07 1636344114531
pod_memory_working_set_bytes{namespace="kube-system",pod="etcd-k8s-master01"} 3.8916096e+08 1636344105030
pod_memory_working_set_bytes{namespace="kube-system",pod="kube-apiserver-k8s-master01"} 6.74189312e+08 1636344108509
pod_memory_working_set_bytes{namespace="kube-system",pod="kube-controller-manager-k8s-master01"} 8.3771392e+07 1636344112554
pod_memory_working_set_bytes{namespace="kube-system",pod="kube-proxy-kq4m2"} 2.3760896e+07 1636344111004
pod_memory_working_set_bytes{namespace="kube-system",pod="kube-scheduler-k8s-master01"} 2.6263552e+07 1636344114247
pod_memory_working_set_bytes{namespace="monitoring",pod="node-exporter-nv2gf"} 3.4082816e+07 1636344111586
pod_memory_working_set_bytes{namespace="tigera-operator",pod="tigera-operator-cf6b69777-nrfng"} 4.8492544e+07 1636344114519
# HELP scrape_error [ALPHA] 1 if there was an error while getting container metrics, 0 otherwise
# TYPE scrape_error gauge
scrape_error 0
```
- decodeBatch转换函数解析，首先初始化一些map对象
```go
func decodeBatch(b []byte, defaultTime time.Time, nodeName string) *storage.MetricsBatch {
	res := &storage.MetricsBatch{
		Nodes: make(map[string]storage.MetricsPoint),
		Pods:  make(map[apitypes.NamespacedName]storage.PodMetricsPoint),
	}
	node := &storage.MetricsPoint{}
	pods := make(map[apitypes.NamespacedName]storage.PodMetricsPoint)
```
- 然后调用prometheus的库将传入的 采集结果byte解析成parser
```go
	parser := textparse.New(b, "")
	var (
		err              error
		defaultTimestamp = timestamp.FromTime(defaultTime)
		et               textparse.Entry
	)
```
- 按行遍历，调用parser.Series获得timeseries, maybeTimestamp, value，其中timeseries代表指标的name和标签组，maybeTimestamp代表时间戳，value代表值
```go
	for {
		if et, err = parser.Next(); err != nil {
			if err == io.EOF {
				break
			}
		}
		if et != textparse.EntrySeries {
			continue
		}
		timeseries, maybeTimestamp, value := parser.Series()
		if maybeTimestamp == nil {
			maybeTimestamp = &defaultTimestamp
		}
```
- 然后进行判断，如果是 节点cpu，也就是series匹配node_cpu_usage_seconds_total，那么调用parseNodeCpuUsageMetrics处理
```go
		switch {
		case timeseriesMatchesName(timeseries, nodeCpuUsageMetricName):
			parseNodeCpuUsageMetrics(*maybeTimestamp, value, node)
func parseNodeCpuUsageMetrics(timestamp int64, value float64, node *storage.MetricsPoint) {
	// unit of node_cpu_usage_seconds_total is second, need to convert 	i = bytes.Index(labels, podNameTag)
	node.CumulativeCpuUsed = uint64(value * 1e9)
	// unit of timestamp is millisecond, need to convert to nanosecond
	node.Timestamp = time.Unix(0, timestamp*1e6)
}

```
- 同样的还有节点内存
- 那么对于容器的处理和节点不一样，因为容器的指标要分namespace
- 以容器cpu为例，首先会通过parseContainerLabels解析series中的去掉metric_name的标签组，获得ns和容器的名字标签
- 然后调用parseContainerCpuMetrics把容器的cpu数据按照ns分组同步到pods这个map中，parseContainerCpuMetrics的过程就是判断双层map中的key如果不存在就new对应的value，然后将值塞进去
```go
		case timeseriesMatchesName(timeseries, containerCpuUsageMetricName):
			namespaceName, containerName := parseContainerLabels(timeseries[len(containerCpuUsageMetricName):])
			parseContainerCpuMetrics(namespaceName, containerName, *maybeTimestamp, value, pods)
func parseContainerCpuMetrics(namespaceName apitypes.NamespacedName, containerName string, timestamp int64, value float64, pods map[apitypes.NamespacedName]storage.PodMetricsPoint) {
	if _, findPod := pods[namespaceName]; !findPod {
		pods[namespaceName] = storage.PodMetricsPoint{Containers: make(map[string]storage.MetricsPoint)}
	}
	if _, findContainer := pods[namespaceName].Containers[containerName]; !findContainer {
		pods[namespaceName].Containers[containerName] = storage.MetricsPoint{}
	}
	// unit of node_cpu_usage_seconds_total is second, need to convert to nanosecond
	containerMetrics := pods[namespaceName].Containers[containerName]
	containerMetrics.CumulativeCpuUsed = uint64(value * 1e9)
	// unit of timestamp is millisecond, need to convert to nanosecond
	containerMetrics.Timestamp = time.Unix(0, timestamp*1e6)
	pods[namespaceName].Containers[containerName] = containerMetrics
}
```


##### 回到 s.scraper.Scrape中
- 在上面通过并发请求各个node 拿到了多个了storage.MetricsBatch对象之后，然后这里要merge合并一下
- 首先准备一个合并的结果storage.MetricsBatch对象
```go
	res := &storage.MetricsBatch{
		Nodes: map[string]storage.MetricsPoint{},
		Pods:  map[apitypes.NamespacedName]storage.PodMetricsPoint{},
	}
```
- merge的流程很简单，变量获取到的data，对于node型的数据没有合并的逻辑，只是要判断是否有重复的node
- 对于pod的数据，根据他们的key 也就是 namespace/podName做合并
```go
	for range nodes {
		srcBatch := <-responseChannel
		if srcBatch == nil {
			continue
		}
		for nodeName, nodeMetricsPoint := range srcBatch.Nodes {
			if _, nodeFind := res.Nodes[nodeName]; nodeFind {
				klog.ErrorS(nil, "Got duplicate node point", "node", klog.KRef("", nodeName))
				continue
			}
			res.Nodes[nodeName] = nodeMetricsPoint
		}
		for podRef, podMetricsPoint := range srcBatch.Pods {
			if _, podFind := res.Pods[podRef]; podFind {
				klog.ErrorS(nil, "Got duplicate pod point", "pod", klog.KRef(podRef.Namespace, podRef.Name))
				continue
			}
			res.Pods[podRef] = podMetricsPoint
		}
	}

```
#### 02 storage.Store存储采集的到数据
- 从Store的定义中可以看到就是先执行nodes的Store再执行pod的Store
```go
func (s *storage) Store(batch *MetricsBatch) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.nodes.Store(batch)
	s.pods.Store(batch)
}

```
##### node的Store
- 位置 D:\go_path\src\github.com\kubernetes-sigs\metrics-server\pkg\storage\node.go
- 首先构造一个lastNodes 和prevNodes用来临时存放前一个和当前点，然后遍历这次采集到node数据，塞入lastNodes中
```go
func (s *nodeStorage) Store(batch *MetricsBatch) {
	lastNodes := make(map[string]MetricsPoint, len(batch.Nodes))
	prevNodes := make(map[string]MetricsPoint, len(batch.Nodes))
	for nodeName, newPoint := range batch.Nodes {
		if _, exists := lastNodes[nodeName]; exists {
			klog.ErrorS(nil, "Got duplicate node point", "node", klog.KRef("", nodeName))
			continue
		}
		lastNodes[nodeName] = newPoint

```
- 然后去存储中查找last的map中是否有这个node的数据，如果有并且 存储中的数据比这次数据时间要早，那么说明正常，将这个缓存中的最新点放到临时存储上一个点的prevNodes中
```go
		if lastNode, found := s.last[nodeName]; found {
			// If new point is different then one already stored
			if newPoint.Timestamp.After(lastNode.Timestamp) {
				// Move stored point to previous
				prevNodes[nodeName] = lastNode
```
- 如果newPoint比缓存中的prev中的数据新，那么将prevPoint塞入prevNodes中
```go
			} else if prevPoint, found := s.prev[nodeName]; found {
				if prevPoint.Timestamp.Before(newPoint.Timestamp) {
					// Keep previous point
					prevNodes[nodeName] = prevPoint
```
- 走到这里说明本次的数据时间戳是旧的，drop调
```go
 else {
					klog.V(2).InfoS("Found new node metrics point is older than stored previous, drop previous",
						"node", nodeName,
						"previousTimestamp", prevPoint.Timestamp,
						"timestamp", newPoint.Timestamp)
				}
```
- 最后做map的 reinit 的替换
```go
	s.last = lastNodes
	s.prev = prevNodes

	// Only count last for which metrics can be returned.
	pointsStored.WithLabelValues("node").Set(float64(len(prevNodes)))
```

##### pod 的Store 和node原理一致，不过要处理namespace会更复杂一点
- 这里要说一下 pod中启动多个容器的 指标结果问题，我这里的onepod-multicontiner02 其中启动了一个 nginx 容器和curl容器
```shell script
[root@k8s-master01 ~]# kubectl get pod onepod-multicontiner02
NAME                     READY   STATUS    RESTARTS   AGE
onepod-multicontiner02   2/2     Running   304        12d
[root@k8s-master01 ~]# kubectl describe  pod onepod-multicontiner02   
Name:         onepod-multicontiner02
Namespace:    default
Priority:     0
Node:         k8s-node01/172.20.70.215
Start Time:   Tue, 26 Oct 2021 19:29:59 +0800
Labels:       <none>
Annotations:  cni.projectcalico.org/podIP: 
              cni.projectcalico.org/podIPs: 
Status:       Running
IP:           10.100.85.245
IPs:
  IP:  10.100.85.245
Containers:
  curl:
    Container ID:  containerd://83b14c661a0c408bf540a2b3d2533743df5d7e6f3f5448e558506f70fcb9bf96
    Image:         yauritux/busybox-curl
    Image ID:      docker.io/yauritux/busybox-curl@sha256:e67b94a5abb6468169218a0940e757ebdfd8ee370cf6901823ecbf4098f2bb65
    Port:          80/TCP
    Host Port:     0/TCP
    Command:
      sleep
      3600
    State:          Running
      Started:      Mon, 08 Nov 2021 12:10:45 +0800
    Last State:     Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Mon, 08 Nov 2021 11:10:43 +0800
      Finished:     Mon, 08 Nov 2021 12:10:43 +0800
    Ready:          True
    Restart Count:  304
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-h5vhn (ro)
  nginx:
    Container ID:   containerd://a137cc4c46c6c21891b6cbae7fd69aaa1b6be30d2e4d85c45091bed26b9d862a
    Image:          nginx:1.8
    Image ID:       sha256:90251a12242eabcbaa3ffe1da13ae4095f8d53dbb8dc6894a7731818b802494c
    Port:           80/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Tue, 26 Oct 2021 19:30:02 +0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-h5vhn (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  kube-api-access-h5vhn:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason   Age                  From     Message
  ----    ------   ----                 ----     -------
  Normal  Pulling  32m (x310 over 12d)  kubelet  Pulling image "yauritux/busybox-curl"
  Normal  Created  32m (x305 over 12d)  kubelet  Created container curl
  Normal  Started  32m (x305 over 12d)  kubelet  Started container curl
  Normal  Pulled   32m                  kubelet  Successfully pulled image "yauritux/busybox-curl" in 2.282959457s
```
- 然后metrics-server会返回这个pod中的多个容器的指标
```go
[root@k8s-master01 ~]# kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/default/pods/onepod-multicontiner02 |python -m json.tool
{
    "apiVersion": "metrics.k8s.io/v1beta1",
    "containers": [
        {
            "name": "curl",
            "usage": {
                "cpu": "0",
                "memory": "36Ki"
            }
        },
        {
            "name": "nginx",
            "usage": {
                "cpu": "0",
                "memory": "1360Ki"
            }
        }
    ],
    "kind": "PodMetrics",
    "metadata": {
        "creationTimestamp": "2021-11-08T04:43:35Z",
        "name": "onepod-multicontiner02",
        "namespace": "default"
    },
    "timestamp": "2021-11-08T04:43:22Z",
    "window": "15s"
}
```

## 通过metrics-server获取指标分析
- 上面提到了应该是调用Store的GetPodMetrics方法

- 位置D:\go_path\src\github.com\kubernetes-sigs\metrics-server\pkg\storage\storage.go
```go
func (s *storage) GetPodMetrics(pods ...*metav1.PartialObjectMetadata) ([]metrics.PodMetrics, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.pods.GetMetrics(pods...)
}
```
- GetMetrics首先就是 要根据传入pod的name和namespace 在store中查找lastPod和prevPod数据
- 然后遍历lastPod.Containers，如果对应的容器在prevPod.Containers没找到说明 pod的容器指标丢失了一个点无法计算
```go
func (s *podStorage) GetMetrics(pods ...*metav1.PartialObjectMetadata) ([]metrics.PodMetrics, error) {
	results := make([]metrics.PodMetrics, 0, len(pods))
	for _, pod := range pods {
		lastPod, found := s.last[apitypes.NamespacedName{Name: pod.Name, Namespace: pod.Namespace}]
		if !found {
			continue
		}

		prevPod, found := s.prev[apitypes.NamespacedName{Name: pod.Name, Namespace: pod.Namespace}]
		if !found {
			continue
		}

		var (
			cms              = make([]metrics.ContainerMetrics, 0, len(lastPod.Containers))
			earliestTimeInfo api.TimeInfo
		)
		allContainersPresent := true
		for container, lastContainer := range lastPod.Containers {
			prevContainer, found := prevPod.Containers[container]
			if !found {
				allContainersPresent = false
				break
			}
```
- 然后调用resourceUsage方法计算使用率，这里传入的就是lastContainer, prevContainer，从计算方法中可以看到就是
- (last-prev)/ts_delta ，看到这里我们就明白了为什么缓存要保留一个prev和last数据，原来是用两个点算利用率的
```go
			usage, ti, err := resourceUsage(lastContainer, prevContainer)
			if err != nil {
				klog.ErrorS(err, "Skipping container usage metric", "container", container, "pod", klog.KRef(pod.Namespace, pod.Name))
				continue
			}
func resourceUsage(last, prev MetricsPoint) (corev1.ResourceList, api.TimeInfo, error) {
	if last.CumulativeCpuUsed < prev.CumulativeCpuUsed {
		return corev1.ResourceList{}, api.TimeInfo{}, fmt.Errorf("unexpected decrease in cumulative CPU usage value")
	}
	window := last.Timestamp.Sub(prev.Timestamp)
	cpuUsage := float64(last.CumulativeCpuUsed-prev.CumulativeCpuUsed) / window.Seconds()
	return corev1.ResourceList{
			corev1.ResourceCPU:    uint64Quantity(uint64(cpuUsage), resource.DecimalSI, -9),
			corev1.ResourceMemory: uint64Quantity(last.MemoryUsage, resource.BinarySI, 0),
		}, api.TimeInfo{
			Timestamp: last.Timestamp,
			Window:    window,
		}, nil
}
```

# 本节重点总结
> metrics-server数据采集流程
- 通过kubelet内置的cadvisor /metrics/resource接口 获取node和pod 的cpu/内存指标，保存到本地存储
    - prev 和last两个点的数据
    - 之所以两个点是因为cpu需要 算rate 就是用 (last-prev)/ts_delta
    - 内存数据直接用的last的value
- 通过apiserver的聚合api插件注册metrics.k8s.io 这个group的 node和pod资源供其他组件调用

