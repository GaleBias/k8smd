# 本节重点总结

> HPA 和scale的关系

- 在前面的学习中我们使用用一个 kubectl scale 命令可以来实现 Pod 的扩缩容功能，但是这个毕竟是完全手动操作的
- 要应对线上的各种复杂情况，我们需要能够做到自动化去感知业务，来自动进行扩缩容
- 为此，Kubernetes 也为我们提供了这样的一个资源对象：Horizontal Pod Autoscaling（Pod 水平自动伸缩），简称HPA
- HPA 通过监控分析一些控制器控制的所有 Pod 的负载变化情况来确定是否需要调整 Pod 的副本数量，这是 HPA 最基本的原理：![hpa01.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1636076280000/9da6136b5b7c43ab8815fea5fcb41096.png)

> 部署metrics-server和基于CPU的hpa测试

- 修改metrics-server的启动命令和镜像地址
- 基于cpu的hpa测试

# HPA 和scale

- 在前面的学习中我们使用用一个 kubectl scale 命令可以来实现 Pod 的扩缩容功能，但是这个毕竟是完全手动操作的
- 要应对线上的各种复杂情况，我们需要能够做到自动化去感知业务，来自动进行扩缩容
- 为此，Kubernetes 也为我们提供了这样的一个资源对象：Horizontal Pod Autoscaling（Pod 水平自动伸缩），简称HPA
- HPA 通过监控分析一些控制器控制的所有 Pod 的负载变化情况来确定是否需要调整 Pod 的副本数量，这是 HPA 最基本的原理：![hpa01.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1636076280000/4d30b178edaf4b6d98a796b48dbc57d8.png)

# 部署一个HPA

## 01 安装 Metrics Server

- 在 HPA 的第一个版本中，我们需要 Heapster 提供 CPU 和内存指标，在 HPA v2 过后就需要安装 Metrcis Server 了，Metrics Server 可以通过标准的 Kubernetes API 把监控数据暴露出来
  - 有了 Metrics Server 之后，我们就完全可以通过标准的 Kubernetes API 来访问我们想要获取的监控数据了：
- [metrics-server项目地址](https://github.com/kubernetes-sigs/metrics-server)
- 安装步骤 ，直接使用项目提供的 components.yaml

```shell
wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.5.0/components.yaml
```

- 修改 metrics-server 启动参数
  - metrics-server 会请求每台节点的 kubelet 接口来获取监控数据，接口通过 HTTPS 暴露
  - 但kubeadm安装节点的 kubelet 使用的是自签证书，若 metrics-server 直接请求 kubelet 接口，将产生证书校验失败的错误
  - 因此需要在 components.yaml 文件中加上 --kubelet-insecure-tls 启动参数。
- 并且默认的k8s.gcr.io ，国内可能无法直接拉取，需要修改为国内缓存
- 修改后的容器段如下

```yaml
containers:
      - args:
        - --cert-dir=/tmp
        - --secure-port=443
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s
        - --kubelet-insecure-tls # 加上该启动参数
        image: ccr.ccs.tencentyun.com/mirrors/metrics-server:v0.5.0 # 国内集群，请替换成这个镜像
```

- 部署后检查 pod

```shell
[root@k8s-master01 hpa]# kubectl get pod -n kube-system | grep metrics-server
metrics-server-c44f75469-sf27q                1/1     Running   0          4m24s
```

- 使用kubelet get这个restapi的path 可以看到内部的resources kind有两个 NodeMetrics和PodMetrics

```shell
[root@k8s-master01 hpa]# kubectl get --raw /apis/metrics.k8s.io/v1beta1   |python -m json.tool
{
    "apiVersion": "v1",
    "groupVersion": "metrics.k8s.io/v1beta1",
    "kind": "APIResourceList",
    "resources": [
        {
            "kind": "NodeMetrics",
            "name": "nodes",
            "namespaced": false,
            "singularName": "",
            "verbs": [
                "get",
                "list"
            ]
        },
        {
            "kind": "PodMetrics",
            "name": "pods",
            "namespaced": true,
            "singularName": "",
            "verbs": [
                "get",
                "list"
            ]
        }
    ]
}
```

- 比如我们可以使用下面的get 获取一个ns下面一个pod 的指标

```shell
[root@k8s-master01 hpa]# kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/kube-state-metrics-647444dd74-rwwqk |python -m json.tool
{
    "apiVersion": "metrics.k8s.io/v1beta1",
    "containers": [
        {
            "name": "kube-state-metrics",
            "usage": {
                "cpu": "1398820n",
                "memory": "29556Ki"
            }
        }
    ],
    "kind": "PodMetrics",
    "metadata": {
        "creationTimestamp": "2021-11-01T11:47:11Z",
        "labels": {
            "app.kubernetes.io/name": "kube-state-metrics",
            "app.kubernetes.io/version": "v1.9.7",
            "pod-template-hash": "647444dd74"
        },
        "name": "kube-state-metrics-647444dd74-rwwqk",
        "namespace": "kube-system"
    },
    "timestamp": "2021-11-01T11:47:07Z",
    "window": "15s"
}
```

- 或者获取node级别的指标

```shell
[root@k8s-master01 hpa]# kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes |python -m json.tool
{
    "apiVersion": "metrics.k8s.io/v1beta1",
    "items": [
        {
            "metadata": {
                "creationTimestamp": "2021-11-01T11:48:37Z",
                "labels": {
                    "beta.kubernetes.io/arch": "amd64",
                    "beta.kubernetes.io/os": "linux",
                    "kubernetes.io/arch": "amd64",
                    "kubernetes.io/hostname": "k8s-master01",
                    "kubernetes.io/os": "linux",
                    "node-role.kubernetes.io/control-plane": "",
                    "node-role.kubernetes.io/master": "",
                    "node.kubernetes.io/exclude-from-external-load-balancers": ""
                },
                "name": "k8s-master01"
            },
            "timestamp": "2021-11-01T11:48:21Z",
            "usage": {
                "cpu": "492230133n",
                "memory": "8151448Ki"
            },
            "window": "20s"
        },
        {
            "metadata": {
                "creationTimestamp": "2021-11-01T11:48:37Z",
                "labels": {
                    "beta.kubernetes.io/arch": "amd64",
                    "beta.kubernetes.io/os": "linux",
                    "kubernetes.io/arch": "amd64",
                    "kubernetes.io/hostname": "k8s-node01",
                    "kubernetes.io/os": "linux"
                },
                "name": "k8s-node01"
            },
            "timestamp": "2021-11-01T11:48:17Z",
            "usage": {
                "cpu": "1227180417n",
                "memory": "6272672Ki"
            },
            "window": "11s"
        }
    ],
    "kind": "NodeMetricsList",
    "metadata": {}
}
```

- 或者我们使用 top 查看 node和pod

```shell
[root@k8s-master01 hpa]# kubectl top pod -n kube-system
W1101 19:49:53.180979   14600 top_pod.go:140] Using json format to get metrics. Next release will switch to protocol-buffers, switch early by passing --use-protocol-buffers flag
NAME                                          CPU(cores)   MEMORY(bytes)   
coredns-7d75679df-9vzm2                       4m           22Mi      
coredns-7d75679df-wf8wl                       4m           24Mi      
etcd-k8s-master01                             38m          332Mi     
kube-apiserver-k8s-master01                   141m         580Mi     
kube-controller-manager-k8s-master01          21m          80Mi      
kube-proxy-6czbx                              1m           24Mi      
kube-proxy-kq4m2                              1m           22Mi      
kube-scheduler-k8s-master01                   5m           29Mi      
kube-state-metrics-647444dd74-rwwqk           1m           29Mi      
metrics-server-c44f75469-sf27q                5m           18Mi      
nginx-svc09-5dfcb54f88-f94qq                  0m           1Mi       
nginx-svc09-5dfcb54f88-nnrqj                  0m           1Mi       
prometheus-0                                  10m          612Mi     
traefik-ingress-controller-54d6b8df8d-r858j   7m           18Mi      
[root@k8s-master01 hpa]# kubectl top node
W1101 19:49:55.802347   14691 top_node.go:119] Using json format to get metrics. Next release will switch to protocol-buffers, switch early by passing --use-protocol-buffers flag
NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
k8s-master01   449m         4%     7955Mi          50%   
k8s-node01     1203m        12%    6150Mi          38%   
[root@k8s-master01 hpa]# 
```

## 02 基于 CPU设置一个HPA

- 首先是一个nginx 的dep，如果要想让 HPA 生效，对应的 Pod 资源必须添加 requests 资源声明
- 并且创建一个svc指向这个dep后端的pod

```yaml

apiVersion: v1
kind: Service
metadata:
  name: nginx-hpa-demo01
spec:
  selector:
    app: nginx-hpa-demo01 # 选择我们上面创建dep中的nginx pod，
  ports:
    - protocol: TCP
      port: 8085  # service对外暴露的端口
      targetPort: 80 # 代表目标容器的端口是80
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hpa-demo01
spec:
  selector:
    matchLabels:
      app: nginx-hpa-demo01
  template:
    metadata:
      labels:
        app: nginx-hpa-demo01
    spec:
      containers:
      - name: nginx
        image: nginx:1.8
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: 50Mi
            cpu: 50m
```

- 部署这个dep
- 现在我们来创建一个 HPA 资源对象，可以使用kubectl autoscale命令来创建：

```shell
 kubectl autoscale deployment hpa-demo01 --cpu-percent=10 --min=1 --max=10
```

- 此命令创建了一个关联资源 hpa-demo01 的 HPA，最小的 Pod 副本数为1，最大为10。HPA 会根据设定的 cpu 使用率（10%）动态的增加或者减少 Pod 数量。

```shell
[root@k8s-master01 hpa]# kubectl get hpa
NAME         REFERENCE               TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
hpa-demo01   Deployment/hpa-demo01   <unknown>/10%   1         10        0          7s
[root@k8s-master01 hpa]# 
[root@k8s-master01 hpa]# kubectl describe hpa 
Name:                                                  hpa-demo01
Namespace:                                             default
Labels:                                                <none>
Annotations:                                           <none>
CreationTimestamp:                                     Mon, 01 Nov 2021 19:54:24 +0800
Reference:                                             Deployment/hpa-demo01
Metrics:                                               ( current / target )
  resource cpu on pods  (as a percentage of request):  <unknown> / 10%
Min replicas:                                          1
Max replicas:                                          10
Deployment pods:                                       0 current / 0 desired
Events:                                                <none>
```

- 我们来创建一个 busybox 的 Pod，并且死循环curl 这个svc的端口，对应访问 Pod中nginx容器

```shell
[root@k8s-master01 hpa]# kubectl get pod  -o wide  |grep hpa
hpa-demo01-5f65595656-k6dxl                1/1     Running            0          5m12s   10.100.85.226   k8s-node01   <none>           <none>


kubectl run -it --image yauritux/busybox-curl curl-hpa-01 --restart=Never --rm /bin/sh 


while true; do curl -s nginx-hpa-demo01:8085 >/dev/null; done
```

- 观察hpa的结果 ，我们可以看到已经自动拉起了很多新的 Pod，最后定格在了我们上面设置的 9 个 Pod，

```shell
[root@k8s-master01 hpa]# kubectl get hpa -w
NAME         REFERENCE               TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
hpa-demo01   Deployment/hpa-demo01   <unknown>/10%   1         10        0          5s
hpa-demo01   Deployment/hpa-demo01   0%/10%          1         10        1          15s
hpa-demo01   Deployment/hpa-demo01   66%/10%         1         10        1          45s
hpa-demo01   Deployment/hpa-demo01   68%/10%         1         10        4          60s
hpa-demo01   Deployment/hpa-demo01   16%/10%         1         10        7          75s
hpa-demo01   Deployment/hpa-demo01   12%/10%         1         10        7          90s
hpa-demo01   Deployment/hpa-demo01   11%/10%         1         10        9          105s
hpa-demo01   Deployment/hpa-demo01   10%/10%         1         10        9          2m
hpa-demo01   Deployment/hpa-demo01   9%/10%          1         10        9          2m15s

```

- 这是因为到了9个pod时我们一个curl已经压不上去了，此时我们再启动一个curl进行压测，发现副本已经被补到了10个

```shell
hpa-demo01   Deployment/hpa-demo01   10%/10%         1         10        9          4m
hpa-demo01   Deployment/hpa-demo01   13%/10%         1         10        9          5m15s
hpa-demo01   Deployment/hpa-demo01   17%/10%         1         10        10         5m30s
```

- 此时停止我们两个压测的pod，过段时间再观察hpa的结果

```shell
hpa-demo01   Deployment/hpa-demo01   0%/10%          1         10        1          11m
```

- 从 Kubernetes v1.12 版本开始我们可以通过设置 kube-controller-manager 组件的--horizontal-pod-autoscaler-downscale-stabilization 参数来设置一个持续时间，用于指定在当前操作完成后，HPA 必须等待多长时间才能执行另一次缩放操作。默认为5分钟，也就是默认需要等待5分钟后才会开始自动缩放。
- 思考一下为什么这么设计？

# 本节重点总结

> HPA 和scale的关系

- 在前面的学习中我们使用用一个 kubectl scale 命令可以来实现 Pod 的扩缩容功能，但是这个毕竟是完全手动操作的
- 要应对线上的各种复杂情况，我们需要能够做到自动化去感知业务，来自动进行扩缩容
- 为此，Kubernetes 也为我们提供了这样的一个资源对象：Horizontal Pod Autoscaling（Pod 水平自动伸缩），简称HPA
- HPA 通过监控分析一些控制器控制的所有 Pod 的负载变化情况来确定是否需要调整 Pod 的副本数量，这是 HPA 最基本的原理：![hpa01.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1636076280000/3f21327076cd41d6b65c36402c0499aa.png)

> 部署metrics-server和基于CPU的hpa测试

- 修改metrics-server的启动命令和镜像地址
- 基于cpu的hpa测试