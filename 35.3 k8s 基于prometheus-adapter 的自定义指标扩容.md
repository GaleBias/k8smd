# 本节重点总结

- 基于prometheus-adapter自定义指标的hpa扩容

# 接上回

- 现在我们的业务pod ：login-pod 已经部署好了，而且可以访问到 /login 和/metrics接口
- 同时prometheus已经采集到对应指标了，下面我们创建prometheus-adapter的rule

# 编写prometheus-adapter rule

- vim custom-metrics-config-map.yaml ，编辑prometheus-adapter的配置文件
- 添加我们的规则

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: adapter-config
  namespace: custom-metrics
data:
  config.yaml: |
    rules:
    - seriesQuery: 'my_golang_app_http_req_login_total'
      resources:
        overrides:
          kubernetes_namespace:
            resource: namespace
          kubernetes_pod_name:
            resource: pod
      name:
        matches: "^(.*)_total"
        as: "${1}_per_second"
      metricsQuery: (sum(rate(<<.Series>>{<<.LabelMatchers>>}[1m])) by (<<.GroupBy>>))

```

## 规则解读

- seriesQuery：查询 Prometheus 的语句，通过这个查询语句查询到的所有指标都可以用于 HPA
- seriesFilters：查询到的指标可能会存在不需要的，可以通过它过滤掉。
- resources：通过 seriesQuery 查询到的只是指标

  - 如果需要查询某个 Pod 的指标，肯定要将它的名称和所在的命名空间作为指标的标签进行查询
  - resources 就是将指标的标签和 k8s 的资源类型关联起来，最常用的就是 pod 和 namespace
  - 有两种添加标签的方式，一种是 overrides，另一种是 template。
    - overrides：它会将指标中的标签和 k8s 资源关联起来
      - 上面示例中就是将指标中的 pod 和 namespace 标签和 k8s 中的 pod 和 namespace 关联起来，因为 pod 和 namespace 都属于核心 api 组，所以不需要指定 api 组
      - 当我们查询某个 pod 的指标时，它会自动将 pod 的名称和名称空间作为标签加入到查询条件中
      - 比如 nginx: {group: "apps", resource: "deployment"} 这么写表示的就是将指标中 nginx 这个标签和 apps 这个 api 组中的 deployment 资源关联起来；
    - template：通过 go 模板的形式。比如template: "kube_<<.Group>>_<<.Resource>>" 这么写表示
      - 假如 <<.Group>> 为 apps，<<.Resource>> 为 deployment
      - 那么它就是将指标中 kube_apps_deployment 标签和 deployment 资源关联起来。
- name：用来给指标重命名的，之所以要给指标重命名是因为有些指标是只增的

  - 比如以 total 结尾的指标。这些指标拿来做 HPA 是没有意义的，我们一般计算它的速率，以速率作为值
  - 那么此时的名称就不能以 total 结尾了，所以要进行重命名。
- matches：通过正则表达式来匹配指标名，可以进行分组
- as：默认值为 $1，也就是第一个分组。as 为空就是使用默认值的意思。
- metricsQuery：这就是 Prometheus 的查询语句了，前面的 seriesQuery 查询是获得 HPA 指标

  - 当我们要查某个指标的值时就要通过它指定的查询语句进行了
  - 可以看到查询语句使用了速率和分组，这就是解决上面提到的只增指标的问题。
- Series：表示指标名称
- LabelMatchers：附加的标签，目前只有 pod 和 namespace 两种，因此我们要在之前使用 resources 进行关联
- GroupBy：就是 pod 名称，同样需要使用 resources 进行关联。

## 规则解读完之后重新部署prometheus-adapter

```shell
kubectl apply -f custom-metrics-apiserver-deployment.yaml
kubectl delete -f custom-metrics-apiserver-deployment.yaml
kubectl create -f custom-metrics-apiserver-deployment.yaml
```

- 部署完成之后检查，这时 /apis/custom.metrics.k8s.io/v1beta1就已经有我们的 my_golang_app_http_req_login_per_second指标了

```shell
[root@k8s-master01 manifests]# kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1"  |python -m json.tool                                                            
{
    "apiVersion": "v1",
    "groupVersion": "custom.metrics.k8s.io/v1beta1",
    "kind": "APIResourceList",
    "resources": [
        {
            "kind": "MetricValueList",
            "name": "namespaces/my_golang_app_http_req_login_per_second",
            "namespaced": false,
            "singularName": "",
            "verbs": [
                "get"
            ]
        },
        {
            "kind": "MetricValueList",
            "name": "pods/my_golang_app_http_req_login_per_second",
            "namespaced": true,
            "singularName": "",
            "verbs": [
                "get"
            ]
        }
    ]
}
```

- 然后请求 这个查看这个指标的详情，发现现在的value是0，这是正常的，因为这个指标的类型是counter，这里算的是rate 也就是qps，现在没有人访问login-pod所以对应的qps就是0

```shell
[root@k8s-master01 manifests]# kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/*/my_golang_app_http_req_login_per_second"   |python -m json.tool
{
    "apiVersion": "custom.metrics.k8s.io/v1beta1",
    "items": [
        {
            "describedObject": {
                "apiVersion": "/v1",
                "kind": "Pod",
                "name": "login-pod-deployment-65f574799c-vd55p",
                "namespace": "default"
            },
            "metricName": "my_golang_app_http_req_login_per_second",
            "selector": null,
            "timestamp": "2021-11-03T07:51:33Z",
            "value": "0"
        }
    ],
    "kind": "MetricValueList",
    "metadata": {
        "selfLink": "/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/%2A/my_golang_app_http_req_login_per_second"
    }
}

```

- 我们手动访问几次 login-pod服务，用我们之前的svc地址。然后再去get这个指标的qps发现已经是 230m了

```shell

[root@k8s-master01 login-pod]# kubectl get svc |grep login  
login-pod-svc       ClusterIP   10.96.249.88    <none>        8000/TCP         30m
[root@k8s-master01 login-pod]# curl 10.96.249.88:8000/login   
Hello World[root@k8s-master01 login-pod]# curl 10.96.249.88:8000/login
Hello World[root@k8s-master01 login-pod]# curl 10.96.249.88:8000/login
Hello World[root@k8s-master01 login-pod]# curl 10.96.249.88:8000/login
Hello World[root@k8s-master01 login-pod]# curl 10.96.249.88:8000/login
Hello World[root@k8s-master01 login-pod]# curl 10.96.249.88:8000/login
Hello World[root@k8s-master01 login-pod]# curl 10.96.249.88:8000/login

[root@k8s-master01 manifests]# kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/*/my_golang_app_http_req_login_per_second"   |python -m json.tool


{
    "apiVersion": "custom.metrics.k8s.io/v1beta1",
    "items": [
        {
            "describedObject": {
                "apiVersion": "/v1",
                "kind": "Pod",
                "name": "login-pod-deployment-65f574799c-vd55p",
                "namespace": "default"
            },
            "metricName": "my_golang_app_http_req_login_per_second",
            "selector": null,
            "timestamp": "2021-11-03T07:53:22Z",
            "value": "230m"
        }
    ],
    "kind": "MetricValueList",
    "metadata": {
        "selfLink": "/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/%2A/my_golang_app_http_req_login_per_second"
    }
}
```

- 到这里说明一切正常

# 编写hpa规则

- 如果请求数超过每秒10个，则将对应用进行扩容。直接创建上面的资源对象：

```yaml

apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: loginpod-custom-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: login-pod-deployment
  minReplicas: 1
  maxReplicas: 5
  metrics:
  - type: Pods
    pods:
      metricName: my_golang_app_http_req_login_per_second
      targetAverageValue: 10
```

- 部署这个hpa之后，-w一直观察

```shell
[root@k8s-master01 login-pod]# kubectl get hpa loginpod-custom-hpa -w
NAME                  REFERENCE                         TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
loginpod-custom-hpa   Deployment/login-pod-deployment   0/10      1         5         1          17s

```

- 接下来我们同样对应用进行压测：

```shell
while true; do curl  10.96.249.88:8000/login >/dev/null; done
```

- 然后可以看到hpa确实驱动了 pod的扩容

```shell
[root@k8s-master01 login-pod]# kubectl get hpa loginpod-custom-hpa -w
NAME                  REFERENCE                         TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
loginpod-custom-hpa   Deployment/login-pod-deployment   0/10      1         5         1          113s
loginpod-custom-hpa   Deployment/login-pod-deployment   73002m/10   1         5         1          2m30s
loginpod-custom-hpa   Deployment/login-pod-deployment   101303m/10   1         5         4          2m45s
loginpod-custom-hpa   Deployment/login-pod-deployment   76866m/10    1         5         5          3m

```

- describe这个hpa也能看到对应的扩容事件 SuccessfulRescale

```shell
[root@k8s-master01 manifests]# kubectl describe hpa loginpod-custom-hpa
Name:                                                 loginpod-custom-hpa
Namespace:                                            default
Labels:                                               <none>
Annotations:                                          <none>
CreationTimestamp:                                    Wed, 03 Nov 2021 15:58:57 +0800
Reference:                                            Deployment/login-pod-deployment
Metrics:                                              ( current / target )
  "my_golang_app_http_req_login_per_second" on pods:  0 / 10
Min replicas:                                         1
Max replicas:                                         5
Deployment pods:                                      5 current / 5 desired
Conditions:
  Type            Status  Reason               Message
  ----            ------  ------               -------
  AbleToScale     True    ScaleDownStabilized  recent recommendations were higher than current one, applying the highest recent recommendation
  ScalingActive   True    ValidMetricFound     the HPA was able to successfully calculate a replica count from pods metric my_golang_app_http_req_login_per_second
  ScalingLimited  True    TooManyReplicas      the desired replica count is more than the maximum replica count
Events:
  Type    Reason             Age   From                       Message
  ----    ------             ----  ----                       -------
  Normal  SuccessfulRescale  109s  horizontal-pod-autoscaler  New size: 4; reason: pods metric my_golang_app_http_req_login_per_second above target
  Normal  SuccessfulRescale  94s   horizontal-pod-autoscaler  New size: 5; reason: pods metric my_golang_app_http_req_login_per_second above target
[root@k8s-master01 manifests]# 
```

- 同时在prometheus也能看到这个 指标的rate变化情况
- ![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1636076351000/7500e8da080549658c0aece638539947.png)
- ![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/908/1636076351000/c06adb27b5b149bd856399f9eb2a045b.png)

# 本节重点总结

- 基于prometheus-adapter自定义指标的hpa扩容