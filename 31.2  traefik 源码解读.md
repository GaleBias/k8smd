# 本节重点总结：

> 生产者
- kubernetes ingress的provider 中会创建多个informer监听 ingress等资源的变化情况，相当于实现了controller
- 同时添加了塞入eventCh 的回调，这个eventCh中的数据经过辗转，会由loadMessage消费，遍历调用Listener回调执行更新 

> 消费者
- 在初始化服务的时候的setupServer中会添加几个回调函数Listener
- 第一个Listener就是  Server Transports代表就是更新 traefik和后端upstream之间通信的对象
- 第二个Listener就是 更新路由的方法

> http server
- 负责处理用户请求，根据ingress rule转发给后端的众多svc上去
- 可以等同于反向代理的nginx

# traefik 的k8s provider模式
- traefik提供 的k8s provider模式和crd模式，这里我们分析第一种


# 启动入口
- 在cmd中 ，位置 D:\go_path\src\github.com\traefik\traefik\cmd\traefik\traefik.go
```go
func main() {
	// traefik config inits
	tConfig := cmd.NewTraefikConfiguration()

	loaders := []cli.ResourceLoader{&tcli.FileLoader{}, &tcli.FlagLoader{}, &tcli.EnvLoader{}}

	cmdTraefik := &cli.Command{
		Name: "traefik",
		Description: `Traefik is a modern HTTP reverse proxy and load balancer made to deploy microservices with ease.
Complete documentation is available at https://traefik.io`,
		Configuration: tConfig,
		Resources:     loaders,
		Run: func(_ []string) error {
			return runCmd(&tConfig.Configuration)
		},
	}
```
- 这里看到调用的runCmd，runCmd我们关注setupServer
```go
func runCmd(staticConfiguration *static.Configuration) error {
	svr, err := setupServer(staticConfiguration)
	if err != nil {
		return err
	}
}
```

## setupServer 构建server解析
- 这里首先关注 创建了一个Watcher，用来监听ingress 变化
```go
func setupServer(staticConfiguration *static.Configuration) (*server.Server, error) {
	// Watcher

	watcher := server.NewConfigurationWatcher(
		routinesPool,
		providerAggregator,
		time.Duration(staticConfiguration.Providers.ProvidersThrottleDuration),
		getDefaultsEntrypoints(staticConfiguration),
		"internal",
	)
}
```
- watcher中有我们关注的ingress规则监听队列 configurationChan 
```go
type ConfigurationWatcher struct {
	provider provider.Provider

	defaultEntryPoints []string

	providersThrottleDuration time.Duration

	currentConfigurations safe.Safe

	configurationChan          chan dynamic.Message
	configurationValidatedChan chan dynamic.Message
	providerConfigUpdateMap    map[string]chan dynamic.Message

	requiredProvider       string
	configurationListeners []func(dynamic.Configuration)

	routinesPool *safe.Pool
}
```
- 然后会给watcher添加几个重要的Listener回调方法
###  第一个Listener就是  Server Transports代表就是更新 traefik和后端upstream之间通信的对象
```go
	// Server Transports
	watcher.AddListener(func(conf dynamic.Configuration) {
		roundTripperManager.Update(conf.HTTP.ServersTransports)
	})
```
- 在roundTripperManager更新方法中可以看到核心就是 创建http.RoundTripper
```go
// Update updates the roundtrippers configurations.
func (r *RoundTripperManager) Update(newConfigs map[string]*dynamic.ServersTransport) {
	r.rtLock.Lock()
	defer r.rtLock.Unlock()
    // 对比configs 本地数据和newConfigs数据，进行更新
	for configName, config := range r.configs {
		newConfig, ok := newConfigs[configName]
		if !ok {
            // 如果旧的有，新的没有说明是删掉了
			
			delete(r.configs, configName)
			delete(r.roundTrippers, configName)
			continue
		}
        // 相同不处理
		if reflect.DeepEqual(newConfig, config) {
			continue
		}

		var err error
		// 创建新的HttpTripper
		r.roundTrippers[configName], err = createRoundTripper(newConfig)
		if err != nil {
			log.WithoutContext().Errorf("Could not configure HTTP Transport %s, fallback on default transport: %v", configName, err)
			r.roundTrippers[configName] = http.DefaultTransport
		}
	}

	for newConfigName, newConfig := range newConfigs {
		if _, ok := r.configs[newConfigName]; ok {
			continue
		}

		var err error
		r.roundTrippers[newConfigName], err = createRoundTripper(newConfig)
		if err != nil {
			log.WithoutContext().Errorf("Could not configure HTTP Transport %s, fallback on default transport: %v", newConfigName, err)
			r.roundTrippers[newConfigName] = http.DefaultTransport
		}
	}

	r.configs = newConfigs
}

```
###  第二个Listener就是 路由
```go
	// Switch router
	watcher.AddListener(switchRouter(routerFactory, serverEntryPointsTCP, serverEntryPointsUDP, aviator))
```
- 底层的更新方法就是更新更新替换路由，对应就是路由的map
```go
func switchRouter(routerFactory *server.RouterFactory, serverEntryPointsTCP server.TCPEntryPoints, serverEntryPointsUDP server.UDPEntryPoints, aviator *pilot.Pilot) func(conf dynamic.Configuration) {
	return func(conf dynamic.Configuration) {
		rtConf := runtime.NewConfig(conf)

		routers, udpRouters := routerFactory.CreateRouters(rtConf)

		if aviator != nil {
			aviator.SetDynamicConfiguration(conf)
		}

		serverEntryPointsTCP.Switch(routers)
		serverEntryPointsUDP.Switch(udpRouters)
	}
}

```
 
 
## 然后就是 启动svr.Start(ctx)
- 位置  D:\go_path\src\github.com\traefik\traefik\pkg\server\server.go
```go

// Start starts the server and Stop/Close it when context is Done.
func (s *Server) Start(ctx context.Context) {
	go func() {
		<-ctx.Done()
		logger := log.FromContext(ctx)
		logger.Info("I have to go...")
		logger.Info("Stopping server gracefully")
		s.Stop()
	}()

	s.tcpEntryPoints.Start()
	s.udpEntryPoints.Start()
	s.watcher.Start()

	s.routinesPool.GoCtx(s.listenSignals)
}
```
- 在start中可以看到 s.tcpEntryPoints.Start() 代表启动tcp 的server，其实就是启动traefix tcp的服务，可以理解为启动nginx
- s.udpEntryPoints.Start()代表启动监听udp端口的服务
- s.watcher.Start()代表启动监听资源变化的服务，往下看发现是调用currentProvider.Provide方法
```go
// Start the configuration watcher.
func (c *ConfigurationWatcher) Start() {
	c.routinesPool.GoCtx(c.listenProviders)
	c.routinesPool.GoCtx(c.listenConfigurations)
	c.startProvider()
}
func (c *ConfigurationWatcher) startProvider() {
	logger := log.WithoutContext()

	jsonConf, err := json.Marshal(c.provider)
	if err != nil {
		logger.Debugf("Unable to marshal provider configuration %T: %v", c.provider, err)
	}

	logger.Infof("Starting provider %T %s", c.provider, jsonConf)
	currentProvider := c.provider

	safe.Go(func() {
		err := currentProvider.Provide(c.configurationChan, c.routinesPool)
		if err != nil {
			logger.Errorf("Error starting provider %T: %s", currentProvider, err)
		}
	})
}

```

### 这里我们关注 kubernetes ingress的provider
- 位置 D:\go_path\src\github.com\traefik\traefik\pkg\provider\kubernetes\ingress\kubernetes.go
- 首先可以看到新建了一个和k8s集群通信的k8sClient
```go
func (p *Provider) Provide(configurationChan chan<- dynamic.Message, pool *safe.Pool) error {
	ctxLog := log.With(context.Background(), log.Str(log.ProviderName, "kubernetes"))
	logger := log.FromContext(ctxLog)

	k8sClient, err := p.newK8sClient(ctxLog)
	if err != nil {
		return err
	}
```
#### 通过k8sClient.WatchAll 监听对应的资源变化，
```go
			eventsChan, err := k8sClient.WatchAll(p.Namespaces, ctxPool.Done())
			if err != nil {
				logger.Errorf("Error watching kubernetes events: %v", err)
				timer := time.NewTimer(1 * time.Second)
				select {
				case <-timer.C:
					return err
				case <-ctxPool.Done():
					return nil
				}
			}
```
- k8sClient.WatchAll 内部就是通过多个informer对象 listAndWatch指定资源的变化
```go
	for _, ns := range namespaces {
		factoryIngress := informers.NewSharedInformerFactoryWithOptions(c.clientset, resyncPeriod, informers.WithNamespace(ns), informers.WithTweakListOptions(matchesLabelSelector))

		if supportsNetworkingV1Ingress(serverVersion) {
			factoryIngress.Networking().V1().Ingresses().Informer().AddEventHandler(eventHandler)
		} else {
			factoryIngress.Networking().V1beta1().Ingresses().Informer().AddEventHandler(eventHandler)
		}

		c.factoriesIngress[ns] = factoryIngress

		factoryKube := informers.NewSharedInformerFactoryWithOptions(c.clientset, resyncPeriod, informers.WithNamespace(ns))
		factoryKube.Core().V1().Services().Informer().AddEventHandler(eventHandler)
		factoryKube.Core().V1().Endpoints().Informer().AddEventHandler(eventHandler)
		c.factoriesKube[ns] = factoryKube

		factorySecret := informers.NewSharedInformerFactoryWithOptions(c.clientset, resyncPeriod, informers.WithNamespace(ns), informers.WithTweakListOptions(notOwnedByHelm))
		factorySecret.Core().V1().Secrets().Informer().AddEventHandler(eventHandler)
		c.factoriesSecret[ns] = factorySecret
	}

	for _, ns := range namespaces {
		c.factoriesIngress[ns].Start(stopCh)
		c.factoriesKube[ns].Start(stopCh)
		c.factoriesSecret[ns].Start(stopCh)
	}
```
- 同时新建了一个eventCh，用这个eventCh构造的eventHandler作为informer 资源变化的回调，可以追踪ResourceEventHandler的OnAdd就是将obj塞入eventCh
```go
	eventCh := make(chan interface{}, 1)
	eventHandler := &k8s.ResourceEventHandler{Ev: eventCh}
// ResourceEventHandler handles Add, Update or Delete Events for resources.
type ResourceEventHandler struct {
	Ev chan<- interface{}
}

// OnAdd is called on Add Events.
func (reh *ResourceEventHandler) OnAdd(obj interface{}) {
	eventHandlerFunc(reh.Ev, obj)
}
func eventHandlerFunc(events chan<- interface{}, obj interface{}) {
	select {
	case events <- obj:
	default:
	}
}
```
- 所以到这里我们知道k8sClient.WatchAll返回的eventCh就是Ingress等资源的变化情况



#### 回到 kubernetes ingress的provider中
- 位置 D:\go_path\src\github.com\traefik\traefik\pkg\provider\kubernetes\ingress\kubernetes.go
- 追踪eventch中的数据会构造dynamic.Message塞入configurationChan中
```go
			for {
				select {
				case <-ctxPool.Done():
					return nil
				case event := <-eventsChan:
					// Note that event is the *first* event that came in during this
					// throttling interval -- if we're hitting our throttle, we may have
					// dropped events. This is fine, because we don't treat different
					// event types differently. But if we do in the future, we'll need to
					// track more information about the dropped events.
					conf := p.loadConfigurationFromIngresses(ctxLog, k8sClient)

					confHash, err := hashstructure.Hash(conf, nil)
					switch {
					case err != nil:
						logger.Error("Unable to hash the configuration")
					case p.lastConfiguration.Get() == confHash:
						logger.Debugf("Skipping Kubernetes event kind %T", event)
					default:
						p.lastConfiguration.Set(confHash)
						configurationChan <- dynamic.Message{
							ProviderName:  "kubernetes",
							Configuration: conf,
						}
					}

```
- 而 configurationChan作为入参来自ConfigurationWatcher的configurationChan
```go
// 位置D:\go_path\src\github.com\traefik\traefik\pkg\server\configurationwatcher.go
func (c *ConfigurationWatcher) startProvider() {
	logger := log.WithoutContext()

	jsonConf, err := json.Marshal(c.provider)
	if err != nil {
		logger.Debugf("Unable to marshal provider configuration %T: %v", c.provider, err)
	}

	logger.Infof("Starting provider %T %s", c.provider, jsonConf)
	currentProvider := c.provider

	safe.Go(func() {
		err := currentProvider.Provide(c.configurationChan, c.routinesPool)
		if err != nil {
			logger.Errorf("Error starting provider %T: %s", currentProvider, err)
		}
	})
}
```
- 追踪谁会消费 c.configurationChan中的主句发现是 ConfigurationWatcher的listenProviders
```go
func (c *ConfigurationWatcher) listenProviders(ctx context.Context) {
	for {
		select {
		case <-ctx.Done():
			return
		case configMsg, ok := <-c.configurationChan:
			if !ok {
				return
			}

			if configMsg.Configuration == nil {
				log.WithoutContext().WithField(log.ProviderName, configMsg.ProviderName).
					Debug("Received nil configuration from provider, skipping.")
				return
			}

			c.preLoadConfiguration(configMsg)
		}
	}
}

```
- preLoadConfiguration中又会传给  c.configurationValidatedChan
```go
func (c *ConfigurationWatcher) preLoadConfiguration(configMsg dynamic.Message) {
	logger := log.WithoutContext().WithField(log.ProviderName, configMsg.ProviderName)
	if log.GetLevel() == logrus.DebugLevel {
		copyConf := configMsg.Configuration.DeepCopy()
		if copyConf.TLS != nil {
			copyConf.TLS.Certificates = nil

			if copyConf.TLS.Options != nil {
				cleanedOptions := make(map[string]tls.Options, len(copyConf.TLS.Options))
				for name, option := range copyConf.TLS.Options {
					option.ClientAuth.CAFiles = []tls.FileOrContent{}
					cleanedOptions[name] = option
				}

				copyConf.TLS.Options = cleanedOptions
			}

			for k := range copyConf.TLS.Stores {
				st := copyConf.TLS.Stores[k]
				st.DefaultCertificate = nil
				copyConf.TLS.Stores[k] = st
			}
		}

		if copyConf.HTTP != nil {
			for _, transport := range copyConf.HTTP.ServersTransports {
				transport.Certificates = tls.Certificates{}
				transport.RootCAs = []tls.FileOrContent{}
			}
		}

		jsonConf, err := json.Marshal(copyConf)
		if err != nil {
			logger.Errorf("Could not marshal dynamic configuration: %v", err)
			logger.Debugf("Configuration received from provider %s: [struct] %#v", configMsg.ProviderName, copyConf)
		} else {
			logger.Debugf("Configuration received from provider %s: %s", configMsg.ProviderName, string(jsonConf))
		}
	}

	if isEmptyConfiguration(configMsg.Configuration) {
		logger.Infof("Skipping empty Configuration for provider %s", configMsg.ProviderName)
		return
	}

	providerConfigUpdateCh, ok := c.providerConfigUpdateMap[configMsg.ProviderName]
	if !ok {
		providerConfigUpdateCh = make(chan dynamic.Message)
		c.providerConfigUpdateMap[configMsg.ProviderName] = providerConfigUpdateCh
		c.routinesPool.GoCtx(func(ctxPool context.Context) {
			c.throttleProviderConfigReload(ctxPool, c.providersThrottleDuration, c.configurationValidatedChan, providerConfigUpdateCh)
		})
	}

	providerConfigUpdateCh <- configMsg
}
```
- 继续追踪发现在ConfigurationWatcher的listenConfigurations中会消费c.configurationValidatedChan的数据，调用loadMessage
```go
func (c *ConfigurationWatcher) listenConfigurations(ctx context.Context) {
	for {
		select {
		case <-ctx.Done():
			return
		case configMsg, ok := <-c.configurationValidatedChan:
			if !ok || configMsg.Configuration == nil {
				return
			}
			c.loadMessage(configMsg)
		}
	}
}

```
- loadMessage中会遍历之前在setUpserver中添加的回调函数更新 loadMessage和route达到热更新 代理配置的目的
```go
func (c *ConfigurationWatcher) loadMessage(configMsg dynamic.Message) {

	// We wait for first configuration of the require provider before applying configurations.
	if _, ok := newConfigurations[c.requiredProvider]; c.requiredProvider == "" || ok {
		for _, listener := range c.configurationListeners {
			listener(conf)
		}
	}
}
```

# 本节重点总结：

> 生产者
- kubernetes ingress的provider 中会创建多个informer监听 ingress等资源的变化情况，相当于实现了controller
- 同时添加了塞入eventCh 的回调，这个eventCh中的数据经过辗转，会由loadMessage消费，遍历调用Listener回调执行更新 

> 消费者
- 在初始化服务的时候的setupServer中会添加几个回调函数Listener
- 第一个Listener就是  Server Transports代表就是更新 traefik和后端upstream之间通信的对象
- 第二个Listener就是 更新路由的方法

> http server
- 负责处理用户请求，根据ingress rule转发给后端的众多svc上去
- 可以等同于反向代理的nginx