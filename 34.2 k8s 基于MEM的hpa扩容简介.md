# 本节重点总结

- tmpfs是一个临时文件系统，驻留在内存中，所以/dev/shm/这个目录不在硬盘上，而是在内存里
- dd：用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。
- 基于内存的hpa实验

# 基于内存的HPA

- HorizontalPodAutoscaler 是 Kubernetes autoscaling API 组的资源，在当前稳定版本 autoscaling/v1 中只支持基于 CPU 指标的缩放
- 在 Beta 版本 autoscaling/v2beta2，引入了基于内存和自定义指标的缩放。所以我们这里需要使用 Beta 版本的 API。

# 内存压测的原理

## tmpfs 是什么

- 使用df命令，可以看到一个tmpfs大小是7.8G, 大小和内存相比，约为内存的一半。

```shell
[root@k8s-master01 memory]# free -g      
              total        used        free      shared  buff/cache   available
Mem:             15           2           1           0          11          11
Swap:             0           0           0
[root@k8s-master01 memory]# df -h |grep tmpfs |grep -v kubelet
tmpfs           7.8G     0  7.8G   0% /dev/shm
```

- tmpfs是什么呢? 其实是一个临时文件系统，驻留在内存中，所以/dev/shm/这个目录不在硬盘上，而是在内存里
- 因为是在内存里，所以读写非常快，可以提供较高的访问速度。linux下，tmpfs默认最大为内存的一半大小
- 但是因为数据是在内存里，所以断电后文件会丢失，内存数据不会和硬盘中数据一样可以永久保存
- 了解了tmpfs这个特性可以用来提高服务器性能，把一些对读写性能要求较高，但是数据又可以丢失的这样的数据保存在/dev/shm中，来提高访问速度。

## dd 命令产生数据

- 在/tmp下创建目录并且挂载一个大小40M 类型为tmpfs的文件系统

```shell
mkdir /tmp/memory 
mount -t tmpfs -o size=40M tmpfs /tmp/memory 
```

- dd：用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。
  - bs=bytes：同时设置读入/输出的块大小为bytes个字节。
  - if=文件名：输入文件名，缺省为标准输入。即指定源文件。< if=input file >
  - of=文件名：输出文件名，缺省为标准输出。即指定目的文件。< of=output file >
  - count=blocks：仅拷贝blocks个块，块大小等于ibs指定的字节数。
  - /dev/zero，是一个输入设备，你可你用它来初始化文件。该设备无穷尽地提供0，可以使用任何你需要的数目——设备提供的要多的多。他可以用于向设备或文件写入字符串0。
- 所以使用下面的命令可以产生100M的文件，报错是因为我们这个 /tmp/memory文件系统只有40M的大小，所以最后的数据只能是40M

```shell
[root@k8s-master01 memory]# dd if=/dev/zero of=/tmp/memory/block  bs=1M count=100
dd: error writing ‘/tmp/memory/block’: No space left on device
41+0 records in
40+0 records out
41943040 bytes (42 MB) copied, 0.0367995 s, 1.1 GB/s
[root@k8s-master01 memory]#

[root@k8s-master01 memory]# ll -h
total 40M
-rw-r--r-- 1 root root 40M Nov  1 20:30 block
[root@k8s-master01 memory]# 
```

- 也就是说往 tmpfs目录中写入文件就是占用内存

# 创建挂载脚本的nginx-dep

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hpa-mem-demo01
spec:
  selector:
    matchLabels:
      app: nginx-hpa-mem-demo01
  template:
    metadata:
      labels:
        app: nginx-hpa-mem-demo01
    spec:
      volumes:
      - name: increase-mem-script
        configMap:
          name: increase-mem-config
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
        volumeMounts:
        - name: increase-mem-script
          mountPath: /etc/script
        resources:
          requests:
            memory: 50Mi
            cpu: 50m
        securityContext:
          privileged: true
```

- 我们将一个名为 increase-mem-config 的 ConfigMap 资源对象挂载到了容器中，该配置文件是用于后面增加容器内存占用的脚本，配置文件如下所示：（increase-mem-cm.yaml）

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: increase-mem-config
data:
  increase-mem.sh: |
    #!/bin/bash  
    mkdir /tmp/memory  
    mount -t tmpfs -o size=40M tmpfs /tmp/memory  
    dd if=/dev/zero of=/tmp/memory/block  
    sleep 60 
    rm /tmp/memory/block  
    umount /tmp/memory  
    rmdir /tmp/memory
```

- 解读一下，这个脚本就是我们开头说的 使用dd命令往tmpfs中写入文件达到消耗内存的目的
- 由于这里增加内存的脚本需要使用到 mount 命令，这需要声明为特权模式，所以我们在pod中添加了 securityContext.privileged=true 这个配置。现在我们直接创建上面的资源对象即可：
- 查看pod

```shell
[root@k8s-master01 mem]# kubectl get pod -l  app=nginx-hpa-mem-demo01
NAME                             READY   STATUS    RESTARTS   AGE
hpa-mem-demo01-cf66bf74d-7kvwj   1/1     Running   0          8m33s
[root@k8s-master01 mem]# 
```

- 然后部署一个基于内存的HPA ，targetAverageUtilization代表使用率

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-hpa-mem01
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: hpa-mem-demo01
  minReplicas: 1
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: memory
      targetAverageUtilization: 60
```

- 这里使用的 apiVersion 是 autoscaling/v2beta1，然后 metrics 属性里面指定的是内存的配置，部署之后查看hpa

```shell
[root@k8s-master01 mem]# kubectl get hpa |grep mem
nginx-hpa-mem01   Deployment/hpa-mem-demo01   <unknown>/60%   1         5         0          15s
[root@k8s-master01 mem]# kubectl describe hpa nginx-hpa-mem01 
Name:                                                     nginx-hpa-mem01
Namespace:                                                default
Labels:                                                   <none>
Annotations:                                              <none>
CreationTimestamp:                                        Tue, 02 Nov 2021 11:13:01 +0800
Reference:                                                Deployment/hpa-mem-demo01
Metrics:                                                  ( current / target )
  resource memory on pods  (as a percentage of request):  12% (6791168) / 60%
Min replicas:                                             1
Max replicas:                                             5
Deployment pods:                                          1 current / 1 desired
Conditions:
  Type            Status  Reason              Message
  ----            ------  ------              -------
  AbleToScale     True    ReadyForNewScale    recommended size matches current size
  ScalingActive   True    ValidMetricFound    the HPA was able to successfully calculate a replica count from memory resource utilization (percentage of request)
  ScalingLimited  False   DesiredWithinRange  the desired count is within the acceptable range
Events:           <none>
```

- 接下来我们对应用进行压测，将内存压上去，直接执行上面我们挂载到容器中的 increase-mem.sh 脚本即可：

```shell
[root@k8s-master01 memory]# kubectl exec hpa-mem-demo01-cf66bf74d-7kvwj -ti -- /bin/bash
root@hpa-mem-demo01-cf66bf74d-7kvwj:/# ls /etc/script 
increase-mem.sh
root@hpa-mem-demo01-cf66bf74d-7kvwj:/# source /etc/script/increase-mem.sh 
dd: writing to '/tmp/memory/block': No space left on device
81921+0 records in
81920+0 records out
41943040 bytes (42 MB, 40 MiB) copied, 0.121283 s, 346 MB/s


```

- 同时-w 一直观察这个mem的hpa变化情况：可以看到内存使用已经超过了我们设定的 60% 这个阈值了，HPA 资源对象也已经触发了自动扩容，变成了两个副本了

```shell
[root@k8s-master01 mem]# kubectl get  hpa nginx-hpa-mem01 -w
NAME              REFERENCE                   TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
nginx-hpa-mem01   Deployment/hpa-mem-demo01   13%/60%   1         5         1          4m16s
nginx-hpa-mem01   Deployment/hpa-mem-demo01   94%/60%   1         5         1          4m31s
nginx-hpa-mem01   Deployment/hpa-mem-demo01   94%/60%   1         5         2          4m46s
nginx-hpa-mem01   Deployment/hpa-mem-demo01   53%/60%   1         5         2          5m1s
nginx-hpa-mem01   Deployment/hpa-mem-demo01   13%/60%   1         5         2          5m31s

```

- 过一分钟后内存使用率又会下降，这是因为我们的脚本中写了sleep 60秒后会删除tmpfs中的block文件，也就是释放了40MB内存，但是hpa还是需要过5分钟才将副本数缩为1个，

```shell
nginx-hpa-mem01   Deployment/hpa-mem-demo01   13%/60%   1         5         2          5m31s

```

# 本节重点总结

- tmpfs是一个临时文件系统，驻留在内存中，所以/dev/shm/这个目录不在硬盘上，而是在内存里
- dd：用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。
- 基于内存的hpa实验